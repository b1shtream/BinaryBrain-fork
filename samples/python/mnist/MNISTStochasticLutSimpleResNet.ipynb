{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23333029-0162-4a33-ab9f-98ae75cb2e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import binarybrain as bb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75d98589-ca90-4f5d-9145-4ed2390642bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define resnet block\n",
    "def ResidualXorBlock(lut1, lut2):\n",
    "    main_path= bb.Sequential([\n",
    "        bb.Convolution2d(lut1, filter_size=(3,3)),\n",
    "        bb.Convolution2d(lut2, filter_size=(3,3))\n",
    "    ])\n",
    "\n",
    "    return bb.Xor([\n",
    "        main_path, #output of conv layers\n",
    "        bb.PassThrough()  #identity skip connection\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61e12388-4775-4bb3-8063-283f558cb19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "net_name              = 'MnistStochasticLutResnet'\n",
    "data_path             = os.path.join('./data/', net_name)\n",
    "rtl_sim_path          = '../../verilog/mnist'\n",
    "rtl_module_name       = 'MnistLutResnet'\n",
    "output_velilog_file   = os.path.join(data_path, net_name + '.v')\n",
    "sim_velilog_file      = os.path.join(rtl_sim_path, rtl_module_name + '.v')\n",
    "epochs                = 4\n",
    "mini_batch_size       = 32\n",
    "\n",
    "# dataset\n",
    "dataset_path = './data/'\n",
    "dataset_train = torchvision.datasets.MNIST(root=dataset_path, train=True, transform=transforms.ToTensor(), download=True)\n",
    "dataset_test  = torchvision.datasets.MNIST(root=dataset_path, train=False, transform=transforms.ToTensor(), download=True)\n",
    "loader_train = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=mini_batch_size, shuffle=True, num_workers=2)\n",
    "loader_test  = torch.utils.data.DataLoader(dataset=dataset_test,  batch_size=mini_batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cc269eb-68e3-43df-9027-cf52750762cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'in1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m\n\u001b[1;32m     16\u001b[0m lut_layer4_1 \u001b[38;5;241m=\u001b[39m bb\u001b[38;5;241m.\u001b[39mDifferentiableLut([\u001b[38;5;241m420\u001b[39m], batch_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, binarize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m lut_layer4_2 \u001b[38;5;241m=\u001b[39m bb\u001b[38;5;241m.\u001b[39mDifferentiableLut([\u001b[38;5;241m70\u001b[39m], batch_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, binarize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 21\u001b[0m out1 \u001b[38;5;241m=\u001b[39m lut_layer0_0\u001b[38;5;241m.\u001b[39mforward(\u001b[43min1\u001b[49m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#xor_result = ResidualXorBlock(lut_layer0_0, lut_layer1_0)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m'''net = bb.Sequential([\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m            bb.Sequential([\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m                bb.Convolution2d(bb.Sequential([lut_layer0_0, lut_layer0_1]), filter_size=(3, 3)),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m        ])\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m        '''\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'in1' is not defined"
     ]
    }
   ],
   "source": [
    "# define residual network(resnet)\n",
    "\n",
    "lut_layer0_0 = bb.DifferentiableLut([192], batch_norm=False, binarize=False)\n",
    "lut_layer0_1 = bb.DifferentiableLut([32], batch_norm=False, binarize=False)\n",
    "\n",
    "lut_layer1_0 = bb.DifferentiableLut([192], batch_norm=False, binarize=False)\n",
    "lut_layer1_1 = bb.DifferentiableLut([32], batch_norm=False, binarize=False)\n",
    "\n",
    "lut_layer2_0 = bb.DifferentiableLut([256], batch_norm=False, binarize=False)\n",
    "lut_layer2_1 = bb.DifferentiableLut([64], batch_norm=False, binarize=False)\n",
    "\n",
    "lut_layer3_0 = bb.DifferentiableLut([256], batch_norm=False, binarize=False)\n",
    "lut_layer3_1 = bb.DifferentiableLut([64], batch_norm=False, binarize=False)\n",
    "\n",
    "lut_layer4_0 = bb.DifferentiableLut([1024], batch_norm=False, binarize=False)\n",
    "lut_layer4_1 = bb.DifferentiableLut([420], batch_norm=False, binarize=False)\n",
    "lut_layer4_2 = bb.DifferentiableLut([70], batch_norm=False, binarize=False)\n",
    "\n",
    "\n",
    "\n",
    "out1 = lut_layer0_0.forward(in1, train=True)\n",
    "\n",
    "\n",
    "#xor_result = ResidualXorBlock(lut_layer0_0, lut_layer1_0)\n",
    "\n",
    "'''net = bb.Sequential([\n",
    "            bb.Sequential([\n",
    "                bb.Convolution2d(bb.Sequential([lut_layer0_0, lut_layer0_1]), filter_size=(3, 3)),\n",
    "                bb.Convolution2d(bb.Sequential([lut_layer1_0, lut_layer1_1]), filter_size=(3, 3)),\n",
    "                bb.StochasticMaxPooling(filter_size=(2, 2)),\n",
    "            ]),\n",
    "            bb.Sequential([\n",
    "                bb.Convolution2d(bb.Sequential([lut_layer2_0, lut_layer2_1]), filter_size=(3, 3)),\n",
    "                bb.Convolution2d(bb.Sequential([lut_layer3_0, lut_layer3_1]), filter_size=(3, 3)),\n",
    "                bb.StochasticMaxPooling(filter_size=(2, 2)),\n",
    "            ]),\n",
    "            bb.Sequential([\n",
    "                bb.Convolution2d(bb.Sequential([lut_layer4_0, lut_layer4_1, lut_layer4_2]),\n",
    "                                    filter_size=(4, 4)),\n",
    "            ]),\n",
    "            bb.Reduce([10])\n",
    "        ])\n",
    "        '''\n",
    "\n",
    "\n",
    "net.set_input_shape([1, 28, 28])\n",
    "\n",
    "net.send_command(\"binary false\")      \n",
    "net.send_command(\"lut_binarize true\")  \n",
    "\n",
    "#print(net.get_info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baf036e5-7f52-4984-af8b-5e542075dc24",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m metrics   \u001b[38;5;241m=\u001b[39m bb\u001b[38;5;241m.\u001b[39mMetricsCategoricalAccuracy()\n\u001b[1;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m bb\u001b[38;5;241m.\u001b[39mOptimizerAdam()\n\u001b[0;32m----> 8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mset_variables(\u001b[43mnet\u001b[49m\u001b[38;5;241m.\u001b[39mget_parameters(), net\u001b[38;5;241m.\u001b[39mget_gradients())\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     11\u001b[0m     loss\u001b[38;5;241m.\u001b[39mclear()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "#bb.load_networks(data_path, net)\n",
    "\n",
    "# learning\n",
    "loss      = bb.LossSoftmaxCrossEntropy()\n",
    "metrics   = bb.MetricsCategoricalAccuracy()\n",
    "optimizer = bb.OptimizerAdam()\n",
    "\n",
    "optimizer.set_variables(net.get_parameters(), net.get_gradients())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss.clear()\n",
    "    metrics.clear()\n",
    "\n",
    "    # learning\n",
    "    with tqdm(loader_train) as t:\n",
    "        for images, labels in t:\n",
    "            x_buf = bb.FrameBuffer.from_numpy(np.array(images).astype(np.float32))\n",
    "            t_buf = bb.FrameBuffer.from_numpy(np.identity(10)[np.array(labels)].astype(np.float32))\n",
    "            \n",
    "            y_buf = net.forward(x_buf, train=True)\n",
    "            \n",
    "            dy_buf = loss.calculate(y_buf, t_buf)\n",
    "\n",
    "            metrics.calculate(y_buf, t_buf)\n",
    "            net.backward(dy_buf)\n",
    "            \n",
    "            optimizer.update()\n",
    "\n",
    "            t.set_postfix(loss=loss.get(), acc=metrics.get())\n",
    "    \n",
    "    # test\n",
    "    loss.clear()\n",
    "    metrics.clear()\n",
    "    for images, labels in loader_test:\n",
    "        x_buf = bb.FrameBuffer.from_numpy(np.array(images).astype(np.float32))\n",
    "        t_buf = bb.FrameBuffer.from_numpy(np.identity(10)[np.array(labels)].astype(np.float32))\n",
    "\n",
    "        y_buf = net.forward(x_buf, train=False)\n",
    "\n",
    "        loss.calculate(y_buf, t_buf)\n",
    "        metrics.calculate(y_buf, t_buf)\n",
    "\n",
    "    bb.save_networks(data_path, net)\n",
    "\n",
    "    print('epoch[%d] : loss=%f accuracy=%f' % (epoch, loss.get(), metrics.get()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f2b9e6c-82d0-4d6b-9d87-d1ae92af4947",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_velilog_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m`timescale 1ns / 1ps\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(bb\u001b[38;5;241m.\u001b[39mmake_verilog_lut_cnv_layers(rtl_module_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCnv0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mnet\u001b[49m[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m      5\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(bb\u001b[38;5;241m.\u001b[39mmake_verilog_lut_cnv_layers(rtl_module_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCnv1\u001b[39m\u001b[38;5;124m'\u001b[39m, net[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m      6\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(bb\u001b[38;5;241m.\u001b[39mmake_verilog_lut_cnv_layers(rtl_module_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCnv2\u001b[39m\u001b[38;5;124m'\u001b[39m, net[\u001b[38;5;241m2\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "# export verilog\n",
    "with open(output_velilog_file, 'w') as f:\n",
    "    f.write('\\n`timescale 1ns / 1ps\\n\\n\\n')\n",
    "    f.write(bb.make_verilog_lut_cnv_layers(rtl_module_name + 'Cnv0', net[0]))\n",
    "    f.write(bb.make_verilog_lut_cnv_layers(rtl_module_name + 'Cnv1', net[1]))\n",
    "    f.write(bb.make_verilog_lut_cnv_layers(rtl_module_name + 'Cnv2', net[2]))\n",
    "\n",
    "# Simulation用ファイルに上書きコピー\n",
    "shutil.copyfile(output_velilog_file, sim_velilog_file)\n",
    "\n",
    "# Simulationで使う画像の生成\n",
    "def img_geneator():\n",
    "    for data in dataset_test:\n",
    "        yield data[0] # 画像とラベルの画像の方を返す\n",
    "\n",
    "img = (bb.make_image_tile(480//28+1, 640//28+1, img_geneator())*255).astype(np.uint8)\n",
    "bb.write_ppm(os.path.join(rtl_sim_path, 'mnist_test_160x120.ppm'), img[:,:120,:160])\n",
    "bb.write_ppm(os.path.join(rtl_sim_path, 'mnist_test_640x480.ppm'), img[:,:480,:640])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37c92bfc-227a-4347-b96b-c145c0cf2b2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 学習したモデルを読み込み(念のため)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m bb\u001b[38;5;241m.\u001b[39mload_networks(data_path, \u001b[43mnet\u001b[49m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# LUTモデルは BIT型を使ってメモリ節約が可能\u001b[39;00m\n\u001b[1;32m      5\u001b[0m bin_dtype \u001b[38;5;241m=\u001b[39m bb\u001b[38;5;241m.\u001b[39mDType\u001b[38;5;241m.\u001b[39mBIT  \u001b[38;5;66;03m# bb.DType.BIT or bb.DType.FP32\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "# 学習したモデルを読み込み(念のため)\n",
    "bb.load_networks(data_path, net)\n",
    "\n",
    "# LUTモデルは BIT型を使ってメモリ節約が可能\n",
    "bin_dtype = bb.DType.BIT  # bb.DType.BIT or bb.DType.FP32\n",
    "\n",
    "# 同一形状のバイナリLUTを生成\n",
    "bin_lut0_0 = bb.BinaryLut.from_sparse_model(lut_layer0_0, fw_dtype=bin_dtype)\n",
    "bin_lut0_1 = bb.BinaryLut.from_sparse_model(lut_layer0_1, fw_dtype=bin_dtype)\n",
    "bin_lut1_0 = bb.BinaryLut.from_sparse_model(lut_layer1_0, fw_dtype=bin_dtype)\n",
    "bin_lut1_1 = bb.BinaryLut.from_sparse_model(lut_layer1_1, fw_dtype=bin_dtype)\n",
    "bin_lut2_0 = bb.BinaryLut.from_sparse_model(lut_layer2_0, fw_dtype=bin_dtype)\n",
    "bin_lut2_1 = bb.BinaryLut.from_sparse_model(lut_layer2_1, fw_dtype=bin_dtype)\n",
    "bin_lut3_0 = bb.BinaryLut.from_sparse_model(lut_layer3_0, fw_dtype=bin_dtype)\n",
    "bin_lut3_1 = bb.BinaryLut.from_sparse_model(lut_layer3_1, fw_dtype=bin_dtype)\n",
    "bin_lut4_0 = bb.BinaryLut.from_sparse_model(lut_layer4_0, fw_dtype=bin_dtype)\n",
    "bin_lut4_1 = bb.BinaryLut.from_sparse_model(lut_layer4_1, fw_dtype=bin_dtype)\n",
    "bin_lut4_2 = bb.BinaryLut.from_sparse_model(lut_layer4_2, fw_dtype=bin_dtype)\n",
    "\n",
    "# テスト用ネットワーク構築\n",
    "frame_modulation_size = 7\n",
    "\n",
    "test_net = bb.Sequential([\n",
    "                bb.RealToBinary(frame_modulation_size=frame_modulation_size, bin_dtype=bin_dtype),\n",
    "                bb.Convolution2d(bb.Sequential([bin_lut0_0, bin_lut0_1]), filter_size=(3, 3), fw_dtype=bin_dtype),\n",
    "                bb.Convolution2d(bb.Sequential([bin_lut1_0, bin_lut1_1]), filter_size=(3, 3), fw_dtype=bin_dtype),\n",
    "                bb.MaxPooling(filter_size=(2, 2), fw_dtype=bin_dtype),\n",
    "                bb.Convolution2d(bb.Sequential([bin_lut2_0, bin_lut2_1]), filter_size=(3, 3), fw_dtype=bin_dtype),\n",
    "                bb.Convolution2d(bb.Sequential([bin_lut3_0, bin_lut3_1]), filter_size=(3, 3), fw_dtype=bin_dtype),\n",
    "                bb.MaxPooling(filter_size=(2, 2), fw_dtype=bin_dtype),\n",
    "                bb.Convolution2d(bb.Sequential([bin_lut4_0, bin_lut4_1, bin_lut4_2]), filter_size=(4, 4), fw_dtype=bin_dtype),\n",
    "                bb.Reduce([10], fw_dtype=bin_dtype),\n",
    "                bb.BinaryToReal(frame_modulation_size=frame_modulation_size)\n",
    "            ])\n",
    "test_net.set_input_shape([1, 28, 28])\n",
    "\n",
    "#print(test_net.get_info())\n",
    "\n",
    "# 推論評価\n",
    "test_loss    = bb.LossSoftmaxCrossEntropy()\n",
    "test_metrics = bb.MetricsCategoricalAccuracy()\n",
    "\n",
    "loss.clear()\n",
    "metrics.clear()\n",
    "for images, labels in tqdm(loader_test):\n",
    "    x_buf = bb.FrameBuffer.from_numpy(np.array(images).astype(np.float32))\n",
    "    t_buf = bb.FrameBuffer.from_numpy(np.identity(10)[np.array(labels)].astype(np.float32))\n",
    "    y_buf = test_net.forward(x_buf, train=False)\n",
    "    test_loss.calculate(y_buf, t_buf)\n",
    "    test_metrics.calculate(y_buf, t_buf)\n",
    "\n",
    "print('Binary LUT test : loss=%f accuracy=%f' % (test_loss.get(), test_metrics.get()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99dc0a2-d64b-401c-83f7-bf4c7d6db408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
