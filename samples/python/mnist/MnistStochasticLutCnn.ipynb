{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StochasticモデルによるMNISTのCNN学習\n",
    "\n",
    "ネットワーク全体に Stochastic性が成り立つ前提で Stochasticモデルに基づくLUT回路学習を行います。<br> \n",
    "Stochastic計算については[こちら](https://en.wikipedia.org/wiki/Stochastic_computing)などを参照ください。\n",
    "\n",
    "本来、ネットワーク内では次々に信号間に相関ができていくため、厳密なStochastic性は失われていくと考えられますが、それでもこの方法もある程度の認識率は出ることが分かります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 事前準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import binarybrain as bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットは PyTorch の torchvision を使います。\n",
    "\n",
    "今回はバイナリ化は行わずに、多値を尤度値として扱います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "net_name              = 'MnistStochasticLutCnn'\n",
    "data_path             = os.path.join('./data/', net_name)\n",
    "rtl_sim_path          = '../../verilog/mnist'\n",
    "rtl_module_name       = 'MnistLutCnn'\n",
    "output_velilog_file   = os.path.join(data_path, net_name + '.v')\n",
    "sim_velilog_file      = os.path.join(rtl_sim_path, rtl_module_name + '.v')\n",
    "epochs                = 4\n",
    "mini_batch_size       = 32\n",
    "\n",
    "# dataset\n",
    "dataset_path = './data/'\n",
    "dataset_train = torchvision.datasets.MNIST(root=dataset_path, train=True, transform=transforms.ToTensor(), download=True)\n",
    "dataset_test  = torchvision.datasets.MNIST(root=dataset_path, train=False, transform=transforms.ToTensor(), download=True)\n",
    "loader_train = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=mini_batch_size, shuffle=True, num_workers=2)\n",
    "loader_test  = torch.utils.data.DataLoader(dataset=dataset_test,  batch_size=mini_batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワークの構築\n",
    "\n",
    "DifferentiableLut の BatchNormalization や Binarize を無効化することで Stochastic 演算モデルとなります。\n",
    "\n",
    "MaxPooling もデジタルにおける OR 演算を Stochastic計算に置き換えたものを使います。\n",
    "\n",
    "最後はシミュレーション時の他のネットワークとの互換性も加味して7倍の出力を Reduce していますが実際には不要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network\n",
    "\n",
    "lut_layer0_0 = bb.DifferentiableLut([6*36], batch_norm=False, binarize=False)\n",
    "lut_layer0_1 = bb.DifferentiableLut([36], batch_norm=False, binarize=False)\n",
    "\n",
    "lut_layer1_0 = bb.DifferentiableLut([2*6*36], batch_norm=False, binarize=False)\n",
    "lut_layer1_1 = bb.DifferentiableLut([2*36], batch_norm=False, binarize=False)\n",
    "\n",
    "lut_layer2_0 = bb.DifferentiableLut([2*6*36], batch_norm=False, binarize=False)\n",
    "lut_layer2_1 = bb.DifferentiableLut([2*36], batch_norm=False, binarize=False)\n",
    "\n",
    "lut_layer3_0 = bb.DifferentiableLut([4*6*36], batch_norm=False, binarize=False)\n",
    "lut_layer3_1 = bb.DifferentiableLut([4*36], batch_norm=False, binarize=False)\n",
    "\n",
    "lut_layer4_0 = bb.DifferentiableLut([6*128], batch_norm=False, binarize=False)\n",
    "lut_layer4_0 = bb.DifferentiableLut([128], batch_norm=False, binarize=False)\n",
    "lut_layer4_1 = bb.DifferentiableLut([6*6*10], batch_norm=False, binarize=False)\n",
    "lut_layer4_1 = bb.DifferentiableLut([6*10], batch_norm=False, binarize=False)\n",
    "lut_layer4_2 = bb.DifferentiableLut([10], batch_norm=False, binarize=False)\n",
    "\n",
    "\n",
    "net = bb.Sequential([\n",
    "            bb.Sequential([\n",
    "                bb.Convolution2d(bb.Sequential([lut_layer0_0, lut_layer0_1]), filter_size=(3, 3)),\n",
    "                bb.Convolution2d(bb.Sequential([lut_layer1_0, lut_layer1_1]), filter_size=(3, 3)),\n",
    "                bb.StochasticMaxPooling(filter_size=(2, 2)),\n",
    "            ]),\n",
    "            bb.Sequential([\n",
    "                bb.Convolution2d(bb.Sequential([lut_layer2_0, lut_layer2_1]), filter_size=(3, 3)),\n",
    "                bb.Convolution2d(bb.Sequential([lut_layer3_0, lut_layer3_1]), filter_size=(3, 3)),\n",
    "                bb.StochasticMaxPooling(filter_size=(2, 2)),\n",
    "            ]),\n",
    "            bb.Sequential([\n",
    "                bb.Convolution2d(bb.Sequential([lut_layer4_0, lut_layer4_1, lut_layer4_2]),\n",
    "                                    filter_size=(4, 4)),\n",
    "            ]),\n",
    "            bb.Reduce([10])\n",
    "        ])\n",
    "\n",
    "net.set_input_shape([1, 28, 28])\n",
    "\n",
    "net.send_command(\"binary false\")       # バイナリ化しない(念のため)\n",
    "net.send_command(\"lut_binarize true\")  # LUTテーブル自体はバイナリ化する\n",
    "\n",
    "# print(net.get_info())  # ネットワークの表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の実施\n",
    "\n",
    "load_networks/save_networks で途中結果を保存/復帰可能できます。ネットワークの構造が変わると正常に読み込めなくなるので注意ください。\n",
    "(その場合は新しいネットをsave_networksするまで一度load_networks をコメントアウトください)\n",
    "\n",
    "tqdm などを使うと学習過程のプログレス表示ができて便利です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e3d471f97e4f3f86756c6798a2909c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[0] : loss=1.690379 accuracy=0.705100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb8fa17741841218634557531fa0003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[1] : loss=1.641709 accuracy=0.790355\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91af33951907406ea2c7109c902221ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[2] : loss=1.607153 accuracy=0.856208\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40608de4a181479e91f0cdfe1ba51cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[3] : loss=1.600336 accuracy=0.852217\n"
     ]
    }
   ],
   "source": [
    "#bb.load_networks(data_path, net)\n",
    "\n",
    "# learning\n",
    "loss      = bb.LossSoftmaxCrossEntropy()\n",
    "metrics   = bb.MetricsCategoricalAccuracy()\n",
    "optimizer = bb.OptimizerAdam()\n",
    "\n",
    "optimizer.set_variables(net.get_parameters(), net.get_gradients())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss.clear()\n",
    "    metrics.clear()\n",
    "\n",
    "    # learning\n",
    "    with tqdm(loader_train) as t:\n",
    "        for images, labels in t:\n",
    "            x_buf = bb.FrameBuffer.from_numpy(np.array(images).astype(np.float32))\n",
    "            t_buf = bb.FrameBuffer.from_numpy(np.identity(10)[np.array(labels)].astype(np.float32))\n",
    "            \n",
    "            y_buf = net.forward(x_buf, train=True)\n",
    "            \n",
    "            dy_buf = loss.calculate(y_buf, t_buf)\n",
    "\n",
    "            metrics.calculate(y_buf, t_buf)\n",
    "            net.backward(dy_buf)\n",
    "            \n",
    "            optimizer.update()\n",
    "\n",
    "            t.set_postfix(loss=loss.get(), acc=metrics.get())\n",
    "    \n",
    "    # test\n",
    "    loss.clear()\n",
    "    metrics.clear()\n",
    "    for images, labels in loader_test:\n",
    "        x_buf = bb.FrameBuffer.from_numpy(np.array(images).astype(np.float32))\n",
    "        t_buf = bb.FrameBuffer.from_numpy(np.identity(10)[np.array(labels)].astype(np.float32))\n",
    "\n",
    "        y_buf = net.forward(x_buf, train=False)\n",
    "\n",
    "        loss.calculate(y_buf, t_buf)\n",
    "        metrics.calculate(y_buf, t_buf)\n",
    "\n",
    "    bb.save_networks(data_path, net)\n",
    "\n",
    "    print('epoch[%d] : loss=%f accuracy=%f' % (epoch, loss.get(), metrics.get()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FPGA用RTL(Verilog)出力\n",
    "\n",
    "FPGA合成の為のVerilogを出力します。\n",
    "\n",
    "現状変換可能なのが、stride=1 の畳み込み層の連続＋最後に一個だけ MaxPooling という単位なので3つに分けて変換しています。<br>\n",
    "返還後の Verilog はそれぞれ Xilinx の AXI4-Stream Video 規格に準じています(frame start で tuser がアサートされるビデオ信号)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export verilog\n",
    "with open(output_velilog_file, 'w') as f:\n",
    "    f.write('\\n`timescale 1ns / 1ps\\n\\n\\n')\n",
    "    f.write(bb.make_verilog_lut_cnv_layers(rtl_module_name + 'Cnv0', net[0]))\n",
    "    f.write(bb.make_verilog_lut_cnv_layers(rtl_module_name + 'Cnv1', net[1]))\n",
    "    f.write(bb.make_verilog_lut_cnv_layers(rtl_module_name + 'Cnv2', net[2]))\n",
    "\n",
    "# Simulation用ファイルに上書きコピー\n",
    "shutil.copyfile(output_velilog_file, sim_velilog_file)\n",
    "\n",
    "# Simulationで使う画像の生成\n",
    "def img_geneator():\n",
    "    for data in dataset_test:\n",
    "        yield data[0] # 画像とラベルの画像の方を返す\n",
    "\n",
    "img = (bb.make_image_tile(480//28+1, 640//28+1, img_geneator())*255).astype(np.uint8)\n",
    "bb.write_ppm(os.path.join(rtl_sim_path, 'mnist_test_160x120.ppm'), img[:,:120,:160])\n",
    "bb.write_ppm(os.path.join(rtl_sim_path, 'mnist_test_640x480.ppm'), img[:,:480,:640])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの検証\n",
    "\n",
    "今回のモデルは Stochastic 性がある前提で学習しています。そこで本当にそのままLUTにマップして認識能力があるか確認します。\n",
    "\n",
    "BinaryBrain には BinaryLut という単なるバイナリテーブルを引くだけのモデルがあります。<br>\n",
    "ここに学習結果をマッピングしてネットワークを作り認識可能か確認します。\n",
    "\n",
    "なお、この際に前後に RealToBinary と BinaryToReal を挟んでバイナリ変調を施しています。<br>\n",
    "閾値を変えることで多値の入力を確率的な0と1の配列に変えることで一般的な画像に対して Stochastic性を与えています<br>\n",
    "\n",
    "これは実用的にはハイフレームレート(オーバーサンプリング)でノイズのある画像入力を直接または疑似的に用意すれば機能することを示しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a859fbd76ed46519decedf829d04305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary LUT test : loss=1.618383 accuracy=0.806430\n"
     ]
    }
   ],
   "source": [
    "# 学習したモデルを読み込み(念のため)\n",
    "bb.load_networks(data_path, net)\n",
    "\n",
    "# LUTモデルは BIT型を使ってメモリ節約が可能\n",
    "bin_dtype = bb.DType.BIT  # bb.DType.BIT or bb.DType.FP32\n",
    "\n",
    "# 同一形状のバイナリLUTを生成\n",
    "bin_lut0_0 = bb.BinaryLut.from_sparse_model(lut_layer0_0, fw_dtype=bin_dtype)\n",
    "bin_lut0_1 = bb.BinaryLut.from_sparse_model(lut_layer0_1, fw_dtype=bin_dtype)\n",
    "bin_lut1_0 = bb.BinaryLut.from_sparse_model(lut_layer1_0, fw_dtype=bin_dtype)\n",
    "bin_lut1_1 = bb.BinaryLut.from_sparse_model(lut_layer1_1, fw_dtype=bin_dtype)\n",
    "bin_lut2_0 = bb.BinaryLut.from_sparse_model(lut_layer2_0, fw_dtype=bin_dtype)\n",
    "bin_lut2_1 = bb.BinaryLut.from_sparse_model(lut_layer2_1, fw_dtype=bin_dtype)\n",
    "bin_lut3_0 = bb.BinaryLut.from_sparse_model(lut_layer3_0, fw_dtype=bin_dtype)\n",
    "bin_lut3_1 = bb.BinaryLut.from_sparse_model(lut_layer3_1, fw_dtype=bin_dtype)\n",
    "bin_lut4_0 = bb.BinaryLut.from_sparse_model(lut_layer4_0, fw_dtype=bin_dtype)\n",
    "bin_lut4_1 = bb.BinaryLut.from_sparse_model(lut_layer4_1, fw_dtype=bin_dtype)\n",
    "bin_lut4_2 = bb.BinaryLut.from_sparse_model(lut_layer4_2, fw_dtype=bin_dtype)\n",
    "\n",
    "# テスト用ネットワーク構築\n",
    "frame_modulation_size = 7\n",
    "\n",
    "test_net = bb.Sequential([\n",
    "                bb.RealToBinary(frame_modulation_size=frame_modulation_size, bin_dtype=bin_dtype),\n",
    "                bb.Convolution2d(bb.Sequential([bin_lut0_0, bin_lut0_1]), filter_size=(3, 3), fw_dtype=bin_dtype),\n",
    "                bb.Convolution2d(bb.Sequential([bin_lut1_0, bin_lut1_1]), filter_size=(3, 3), fw_dtype=bin_dtype),\n",
    "                bb.MaxPooling(filter_size=(2, 2), fw_dtype=bin_dtype),\n",
    "                bb.Convolution2d(bb.Sequential([bin_lut2_0, bin_lut2_1]), filter_size=(3, 3), fw_dtype=bin_dtype),\n",
    "                bb.Convolution2d(bb.Sequential([bin_lut3_0, bin_lut3_1]), filter_size=(3, 3), fw_dtype=bin_dtype),\n",
    "                bb.MaxPooling(filter_size=(2, 2), fw_dtype=bin_dtype),\n",
    "                bb.Convolution2d(bb.Sequential([bin_lut4_0, bin_lut4_1, bin_lut4_2]), filter_size=(4, 4), fw_dtype=bin_dtype),\n",
    "                bb.Reduce([10], bin_dtype=bin_dtype),\n",
    "                bb.BinaryToReal(frame_integration_size=frame_modulation_size)\n",
    "            ])\n",
    "test_net.set_input_shape([1, 28, 28])\n",
    "\n",
    "#print(test_net.get_info())\n",
    "\n",
    "# 推論評価\n",
    "test_loss    = bb.LossSoftmaxCrossEntropy()\n",
    "test_metrics = bb.MetricsCategoricalAccuracy()\n",
    "\n",
    "loss.clear()\n",
    "metrics.clear()\n",
    "for images, labels in tqdm(loader_test):\n",
    "    x_buf = bb.FrameBuffer.from_numpy(np.array(images).astype(np.float32))\n",
    "    t_buf = bb.FrameBuffer.from_numpy(np.identity(10)[np.array(labels)].astype(np.float32))\n",
    "    y_buf = test_net.forward(x_buf, train=False)\n",
    "    test_loss.calculate(y_buf, t_buf)\n",
    "    test_metrics.calculate(y_buf, t_buf)\n",
    "\n",
    "print('Binary LUT test : loss=%f accuracy=%f' % (test_loss.get(), test_metrics.get()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
