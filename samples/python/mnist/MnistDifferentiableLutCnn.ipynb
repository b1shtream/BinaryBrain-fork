{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 微分可能LUTモデルによるCNNでのMNIST学習\n",
    "\n",
    "Differentiable LUTモデルで畳み込み層を形成して、一般的なデータに対してCNNによる回路学習を行います。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import binarybrain as bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセット\n",
    "\n",
    "データセットの準備には torchvision を使います"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "net_name              = 'MnistDifferentiableLutCnn'\n",
    "data_path             = os.path.join('./data/', net_name)\n",
    "rtl_sim_path          = '../../verilog/mnist/tb_mnist_lut_cnn'\n",
    "rtl_module_name       = 'MnistLutCnn'\n",
    "output_velilog_file   = os.path.join(data_path, rtl_module_name + '.v')\n",
    "sim_velilog_file      = os.path.join(rtl_sim_path, rtl_module_name + '.v')\n",
    "\n",
    "bin_mode              = True\n",
    "frame_modulation_size = 7\n",
    "epochs                = 8\n",
    "mini_batch_size       = 64\n",
    "\n",
    "\n",
    "# dataset\n",
    "dataset_path = './data/'\n",
    "dataset_train = torchvision.datasets.MNIST(root=dataset_path, train=True, transform=transforms.ToTensor(), download=True)\n",
    "dataset_test  = torchvision.datasets.MNIST(root=dataset_path, train=False, transform=transforms.ToTensor(), download=True)\n",
    "loader_train = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=mini_batch_size, shuffle=True, num_workers=2)\n",
    "loader_test  = torch.utils.data.DataLoader(dataset=dataset_test,  batch_size=mini_batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワーク構築\n",
    "\n",
    "Convolution2d を使って畳み込み層を作ります。<br>\n",
    "Convolution2d は指定した層を im2col と col2im で挟み込んで Lowering による畳み込みをサポートします。<br>\n",
    "DenseAffine を Lowering すると一般にCNNで知られる畳み込み層になりますが、LUT-Network では\n",
    "ここに DifferentiableLut を組み合わせて作った層を設定することでDenseAffineとは異なる効率の良い畳み込み層を実現します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バイナリ時は BIT型を使えばメモリ削減可能\n",
    "bin_dtype = bb.DType.BIT if bin_mode else bb.DType.FP32\n",
    "\n",
    "# define network\n",
    "net = bb.Sequential([\n",
    "            bb.RealToBinary(frame_modulation_size=frame_modulation_size, bin_dtype=bin_dtype),\n",
    "            bb.Sequential([\n",
    "                bb.Convolution2d(\n",
    "                    bb.Sequential([\n",
    "                        bb.DifferentiableLut([36*6], connection='random', bin_dtype=bin_dtype),\n",
    "                        bb.AverageLut([36], connection='serial', bin_dtype=bin_dtype),\n",
    "                    ]),\n",
    "                    filter_size=(3, 3),\n",
    "                    fw_dtype=bin_dtype),\n",
    "                bb.Convolution2d(\n",
    "                    bb.Sequential([\n",
    "                        bb.DifferentiableLut([2*36*6], connection='random', bin_dtype=bin_dtype),\n",
    "                        bb.AverageLut([2*36], connection='serial', bin_dtype=bin_dtype),\n",
    "                    ]),\n",
    "                    filter_size=(3, 3),\n",
    "                    fw_dtype=bin_dtype),\n",
    "                bb.MaxPooling(filter_size=(2, 2), fw_dtype=bin_dtype),\n",
    "            ]),\n",
    "            bb.Sequential([\n",
    "                bb.Convolution2d(\n",
    "                    bb.Sequential([\n",
    "                        bb.DifferentiableLut([2*36*6], connection='random', bin_dtype=bin_dtype),\n",
    "                        bb.AverageLut([2*36], connection='serial', bin_dtype=bin_dtype),\n",
    "                    ]),\n",
    "                    filter_size=(3, 3),\n",
    "                    fw_dtype=bin_dtype),\n",
    "                bb.Convolution2d(\n",
    "                    bb.Sequential([\n",
    "                        bb.DifferentiableLut([4*36*6], connection='random', bin_dtype=bin_dtype),\n",
    "                        bb.AverageLut([4*36], connection='serial', bin_dtype=bin_dtype),\n",
    "                    ]),\n",
    "                    filter_size=(3, 3),\n",
    "                    fw_dtype=bin_dtype),\n",
    "                bb.MaxPooling(filter_size=(2, 2), fw_dtype=bin_dtype),\n",
    "            ]),\n",
    "            bb.Sequential([\n",
    "                bb.Convolution2d(\n",
    "                    bb.Sequential([\n",
    "                        bb.DifferentiableLut([6*128], connection='random', bin_dtype=bin_dtype),\n",
    "                        bb.AverageLut([128], connection='serial', bin_dtype=bin_dtype),\n",
    "                        \n",
    "                        bb.DifferentiableLut([6*6*10], connection='random', bin_dtype=bin_dtype),\n",
    "                        bb.DifferentiableLut([6*10], connection='serial', bin_dtype=bin_dtype),\n",
    "                        bb.AverageLut([10], connection='serial', bin_dtype=bin_dtype),\n",
    "                    ]),\n",
    "                    filter_size=(4, 4),\n",
    "                    fw_dtype=bin_dtype),\n",
    "            ]),\n",
    "            bb.BinaryToReal(frame_integration_size=frame_modulation_size, bin_dtype=bin_dtype)\n",
    "        ])\n",
    "\n",
    "net.set_input_shape([1, 28, 28])\n",
    "\n",
    "if bin_mode:\n",
    "    net.send_command(\"binary true\")\n",
    "\n",
    "#   print(net.get_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習実施\n",
    "\n",
    "学習を行います"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b7bf9c506e64fd09a04f00653595a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[0] : loss=1.516309 accuracy=0.948200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9e23f6c02c4e78bf5ee929cde73a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[1] : loss=1.506356 accuracy=0.965500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0921ffdf904900b5a3528f06f6b2b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[2] : loss=1.508160 accuracy=0.964700\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2467286784246d983a772ea123d0f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[3] : loss=1.505680 accuracy=0.970700\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1c651ad5f34310a39b8f8d9b89a06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[4] : loss=1.507609 accuracy=0.969300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e61878cca6a49ff97708e233b18839c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[5] : loss=1.506179 accuracy=0.963500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33b032d7c0f4eeba363600e2f178b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[6] : loss=1.500575 accuracy=0.970100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236ccc9cbb25460193e5ea68dfc610bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[7] : loss=1.505316 accuracy=0.969100\n"
     ]
    }
   ],
   "source": [
    "# 前の学習結果があれば読み込む\n",
    "#bb.load_networks(data_path, net)\n",
    "\n",
    "# learning\n",
    "loss      = bb.LossSoftmaxCrossEntropy()\n",
    "metrics   = bb.MetricsCategoricalAccuracy()\n",
    "optimizer = bb.OptimizerAdam()\n",
    "\n",
    "optimizer.set_variables(net.get_parameters(), net.get_gradients())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss.clear()\n",
    "    metrics.clear()\n",
    "\n",
    "    # learning\n",
    "    with tqdm(loader_train) as t:\n",
    "        for images, labels in t:\n",
    "            x_buf = bb.FrameBuffer.from_numpy(np.array(images).astype(np.float32))\n",
    "            t_buf = bb.FrameBuffer.from_numpy(np.identity(10)[np.array(labels)].astype(np.float32))\n",
    "\n",
    "            y_buf = net.forward(x_buf, train=True)\n",
    "\n",
    "            dy_buf = loss.calculate(y_buf, t_buf)\n",
    "            metrics.calculate(y_buf, t_buf)\n",
    "            net.backward(dy_buf)\n",
    "\n",
    "            optimizer.update()\n",
    "\n",
    "            t.set_postfix(loss=loss.get(), acc=metrics.get())\n",
    "\n",
    "    # test\n",
    "    loss.clear()\n",
    "    metrics.clear()\n",
    "    for images, labels in loader_test:\n",
    "        x_buf = bb.FrameBuffer.from_numpy(np.array(images).astype(np.float32))\n",
    "        t_buf = bb.FrameBuffer.from_numpy(np.identity(10)[np.array(labels)].astype(np.float32))\n",
    "\n",
    "        y_buf = net.forward(x_buf, train=False)\n",
    "\n",
    "        loss.calculate(y_buf, t_buf)\n",
    "        metrics.calculate(y_buf, t_buf)\n",
    "\n",
    "    bb.save_networks(data_path, net)\n",
    "\n",
    "    print('epoch[%d] : loss=%f accuracy=%f' % (epoch, loss.get(), metrics.get()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RTL(Verilog)変換\n",
    "\n",
    "FPGA化するために Verilog に変換します。インターフェースはXilinx社のAXI4 Stream Video 仕様(フレームスタートでtuserが立つ)となります。\n",
    "MaxPooling の単位で画像サイズが縮小されてしまうので、現状、この単位でしか変換できないため3つに分けて出力しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export verilog\n",
    "with open(output_velilog_file, 'w') as f:\n",
    "    f.write('`timescale 1ns / 1ps\\n\\n')\n",
    "    bb.dump_verilog_lut_cnv_layers(f, rtl_module_name + 'Cnv0', net[1])\n",
    "    bb.dump_verilog_lut_cnv_layers(f, rtl_module_name + 'Cnv1', net[2])\n",
    "    bb.dump_verilog_lut_cnv_layers(f, rtl_module_name + 'Cnv2', net[3])\n",
    "\n",
    "# Simulation用ファイルに上書きコピー\n",
    "shutil.copyfile(output_velilog_file, sim_velilog_file)\n",
    "\n",
    "# Simulationで使う画像の生成\n",
    "def img_geneator():\n",
    "    for data in dataset_test:\n",
    "        yield data[0] # 画像とラベルの画像の方を返す\n",
    "\n",
    "img = (bb.make_image_tile(720//28+1, 1280//28+1, img_geneator())*255).astype(np.uint8)\n",
    "bb.write_ppm(os.path.join(rtl_sim_path, 'mnist_test_160x120.ppm'), img[:,:120,:160])\n",
    "bb.write_ppm(os.path.join(rtl_sim_path, 'mnist_test_640x480.ppm'), img[:,:480,:640])\n",
    "bb.write_ppm(os.path.join(rtl_sim_path, 'mnist_test_1280x720.ppm'), img[:,:720,:1280])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
