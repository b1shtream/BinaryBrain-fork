{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 微分可能LUTモデルによるMobileNetライクなMNIST学習\n",
    "\n",
    "Differentiable LUTモデルでMobileNet風の畳み込み層を形成して、一般的なデータに対してCNNによる回路学習を行います。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import binarybrain as bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセット\n",
    "\n",
    "データセットの準備には torchvision を使います"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "net_name              = 'MnistDifferentiableLutMobileNet'\n",
    "data_path             = os.path.join('./data/', net_name)\n",
    "rtl_sim_path          = '../../verilog/mnist/tb_mnist_lut_cnn'\n",
    "rtl_module_name       = 'MnistLutCnn'\n",
    "output_velilog_file   = os.path.join(data_path, rtl_module_name + '.v')\n",
    "sim_velilog_file      = os.path.join(rtl_sim_path, rtl_module_name + '.v')\n",
    "\n",
    "bin_mode              = True\n",
    "frame_modulation_size = 7\n",
    "epochs                = 4\n",
    "mini_batch_size       = 64\n",
    "\n",
    "\n",
    "# dataset\n",
    "dataset_path = './data/'\n",
    "dataset_train = torchvision.datasets.MNIST(root=dataset_path, train=True, transform=transforms.ToTensor(), download=True)\n",
    "dataset_test  = torchvision.datasets.MNIST(root=dataset_path, train=False, transform=transforms.ToTensor(), download=True)\n",
    "loader_train = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=mini_batch_size, shuffle=True, num_workers=2)\n",
    "loader_test  = torch.utils.data.DataLoader(dataset=dataset_test,  batch_size=mini_batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワーク構築\n",
    "\n",
    "make_conv_layer にて pointwise-depthwise-pointwise の畳み込みを組み合わせた層を作ります。\n",
    "\n",
    "Convolution2d は指定したモデルを im2col とcol2im で挟み込んで畳み込み層を生成します。\n",
    "\n",
    "pointwise はフィルタサイズが1x1の通常のConv層です<br>\n",
    "depthwise は畳み込み内部に持つ DifferentiableLut に同一チャネル内での接続のみを指定して構成します。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バイナリ時は BIT型を使えばメモリ削減可能\n",
    "bin_dtype = bb.DType.BIT if bin_mode else bb.DType.FP32\n",
    "\n",
    "def make_conv_layer(output_ch, hidden_ch, padding='valid', bin_dtype=bb.DType.BIT):\n",
    "    return bb.Sequential([\n",
    "                # input(pointwise)\n",
    "                bb.Convolution2d(\n",
    "                    bb.Sequential([\n",
    "                        bb.DifferentiableLut([hidden_ch*6, 1, 1], bin_dtype=bin_dtype),\n",
    "                        bb.DifferentiableLut([hidden_ch,   1, 1], connection='serial', bin_dtype=bin_dtype),\n",
    "                    ]),\n",
    "                    filter_size=(1, 1),\n",
    "                    fw_dtype=bin_dtype),\n",
    "\n",
    "                # hidden(depthwise)\n",
    "                bb.Convolution2d(\n",
    "                    bb.Sequential([\n",
    "                        bb.DifferentiableLut([hidden_ch, 1, 1], connection='depthwise', bin_dtype=bin_dtype),\n",
    "                    ]),\n",
    "                    filter_size=(3, 3), padding=padding,\n",
    "                    fw_dtype=bin_dtype),\n",
    "                \n",
    "                # output(pointwise)\n",
    "                bb.Convolution2d(\n",
    "                    bb.Sequential([\n",
    "                        bb.DifferentiableLut([output_ch*6, 1, 1], connection='serial', bin_dtype=bin_dtype),\n",
    "                        bb.DifferentiableLut([output_ch,   1, 1], connection='serial', bin_dtype=bin_dtype),\n",
    "                    ]),\n",
    "                    filter_size=(1, 1),\n",
    "                    fw_dtype=bin_dtype),\n",
    "            ])\n",
    "\n",
    "# define network\n",
    "net = bb.Sequential([\n",
    "            bb.RealToBinary(frame_modulation_size=frame_modulation_size, bin_dtype=bin_dtype),\n",
    "            bb.Sequential([\n",
    "                make_conv_layer(36, 36, bin_dtype=bin_dtype),  # 28x28 -> 26x26\n",
    "                make_conv_layer(2*36, 36, bin_dtype=bin_dtype),  # 26x26 -> 24x24\n",
    "                bb.MaxPooling(filter_size=(2, 2), fw_dtype=bin_dtype),  # 24x24 -> 12x12\n",
    "            ]),\n",
    "            bb.Sequential([\n",
    "                make_conv_layer(2*36, 72, bin_dtype=bin_dtype),  # 12x12 -> 10x10\n",
    "                make_conv_layer(4*36, 72, bin_dtype=bin_dtype),  # 10x10 -> 4x4\n",
    "                bb.MaxPooling(filter_size=(2, 2), fw_dtype=bin_dtype),\n",
    "            ]),\n",
    "            bb.Sequential([\n",
    "                bb.Convolution2d(\n",
    "                    bb.Sequential([\n",
    "                        bb.DifferentiableLut([6*128], bin_dtype=bin_dtype),\n",
    "                        bb.DifferentiableLut([128], bin_dtype=bin_dtype),\n",
    "                        bb.DifferentiableLut([10*6*6], bin_dtype=bin_dtype),\n",
    "                        bb.DifferentiableLut([10*6], bin_dtype=bin_dtype),\n",
    "                        bb.DifferentiableLut([10], bin_dtype=bin_dtype),\n",
    "                    ]),\n",
    "                    filter_size=(4, 4),\n",
    "                    fw_dtype=bin_dtype),\n",
    "            ]),\n",
    "            bb.BinaryToReal(frame_integration_size=frame_modulation_size, bin_dtype=bin_dtype)\n",
    "        ])\n",
    "\n",
    "net.set_input_shape([1, 28, 28])\n",
    "\n",
    "if bin_mode:\n",
    "    net.send_command(\"binary true\")\n",
    "\n",
    "# print(net.get_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習実施\n",
    "\n",
    "学習を行います"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bb.load_networks(data_path, net)\n",
    "\n",
    "# learning\n",
    "loss      = bb.LossSoftmaxCrossEntropy()\n",
    "metrics   = bb.MetricsCategoricalAccuracy()\n",
    "optimizer = bb.OptimizerAdam()\n",
    "\n",
    "optimizer.set_variables(net.get_parameters(), net.get_gradients())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss.clear()\n",
    "    metrics.clear()\n",
    "\n",
    "    # learning\n",
    "    with tqdm(loader_train) as t:\n",
    "        for images, labels in t:\n",
    "            x_buf = bb.FrameBuffer.from_numpy(np.array(images).astype(np.float32))\n",
    "            t_buf = bb.FrameBuffer.from_numpy(np.identity(10)[np.array(labels)].astype(np.float32))\n",
    "\n",
    "            y_buf = net.forward(x_buf, train=True)\n",
    "\n",
    "            dy_buf = loss.calculate(y_buf, t_buf)\n",
    "            metrics.calculate(y_buf, t_buf)\n",
    "            net.backward(dy_buf)\n",
    "\n",
    "            optimizer.update()\n",
    "\n",
    "            t.set_postfix(loss=loss.get(), acc=metrics.get())\n",
    "\n",
    "    # test\n",
    "    loss.clear()\n",
    "    metrics.clear()\n",
    "    for images, labels in loader_test:\n",
    "        x_buf = bb.FrameBuffer.from_numpy(np.array(images).astype(np.float32))\n",
    "        t_buf = bb.FrameBuffer.from_numpy(np.identity(10)[np.array(labels)].astype(np.float32))\n",
    "\n",
    "        y_buf = net.forward(x_buf, train=False)\n",
    "\n",
    "        loss.calculate(y_buf, t_buf)\n",
    "        metrics.calculate(y_buf, t_buf)\n",
    "\n",
    "    bb.save_networks(data_path, net)\n",
    "\n",
    "    print('epoch[%d] : loss=%f accuracy=%f' % (epoch, loss.get(), metrics.get()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RTL(Verilog)変換\n",
    "\n",
    "FPGA化するために Verilog に変換します。インターフェースはXilinx社のAXI4 Stream Video 仕様(フレームスタートでtuserが立つ)となります。\n",
    "MaxPooling の単位で画像サイズが縮小されてしまうので、現状、この単位でしか変換できないため3つに分けて出力しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export verilog\n",
    "with open(output_velilog_file, 'w') as f:\n",
    "    f.write('`timescale 1ns / 1ps\\n\\n')\n",
    "    bb.dump_verilog_lut_cnv_layers(f, rtl_module_name + 'Cnv0', net[1])\n",
    "    bb.dump_verilog_lut_cnv_layers(f, rtl_module_name + 'Cnv1', net[2])\n",
    "    bb.dump_verilog_lut_cnv_layers(f, rtl_module_name + 'Cnv2', net[3])\n",
    "\n",
    "# Simulation用ファイルに上書きコピー\n",
    "shutil.copyfile(output_velilog_file, sim_velilog_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
