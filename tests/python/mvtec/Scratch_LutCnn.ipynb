{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import binarybrain as bb\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像読み込み\n",
    "imgs = []\n",
    "masks = []\n",
    "for i in range(23):\n",
    "    img = cv2.imread('./data/metal_nut/test/scratch/%03d.png'%i)\n",
    "    mask = cv2.imread('./data/metal_nut/ground_truth/scratch/%03d_mask.png'%i, 0)\n",
    "    img = img.transpose(2, 0, 1).astype(np.float32) / 255.0\n",
    "    mask = mask.reshape(1, 700, 700).astype(np.float32) / 255.0\n",
    "    imgs.append(img)\n",
    "    masks.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習用とテスト用に分ける\n",
    "train_imgs  = np.array(imgs[0:20])\n",
    "train_masks = np.array(masks[0:20])\n",
    "test_imgs  = np.array(imgs[20:23])\n",
    "test_masks = np.array(masks[20:23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_image(imgs, masks, h, w, margin):\n",
    "    '''タイル状に分割'''\n",
    "    img_w = imgs[0].shape[2]\n",
    "    img_h = imgs[0].shape[1]\n",
    "    stride_h = h-margin\n",
    "    stride_w = w-margin\n",
    "    split_imgs  = []\n",
    "    split_masks = []\n",
    "    for img, msk, in zip(imgs, masks):\n",
    "        for y in range(0, img_h-h, stride_h):\n",
    "            for x in range(0, img_w-w, stride_w):\n",
    "                blk_img = img[:,y:y+src_h,x:x+src_w]\n",
    "                blk_msk = msk[:,y:y+src_h,x:x+src_w]\n",
    "                if margin > 0:\n",
    "                    blk_msk = blk_msk[:,margin:-margin,margin:-margin]\n",
    "                split_imgs.append(blk_img)\n",
    "                split_masks.append(blk_msk)\n",
    "    return split_imgs, split_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_mode = True\n",
    "frame_modulation_size = 3\n",
    "depth_modulation_size = 15\n",
    "\n",
    "epochs          = 32\n",
    "mini_batch_size = 32\n",
    "\n",
    "depth  = 4\n",
    "margin = depth\n",
    "src_w = 64\n",
    "src_h = 64\n",
    "dst_w = src_w - 2*margin\n",
    "dst_h = src_h - 2*margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_t = split_image(train_imgs, train_masks, src_w, src_h, margin)\n",
    "test_x, test_t = split_image(test_imgs, test_masks, src_w, src_h, margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDatasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, source_imgs, teaching_imgs, batch_size, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.source_imgs = source_imgs\n",
    "        self.teaching_imgs = teaching_imgs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.source_imgs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        source_img = self.source_imgs[index]\n",
    "        teaching_img = self.teaching_imgs[index]\n",
    "        if self.transforms:\n",
    "            source_img, teaching_img = self.transforms(source_img, teaching_img)\n",
    "        return source_img, teaching_img\n",
    "\n",
    "\n",
    "my_dataset_train = MyDatasets(train_x, train_t, mini_batch_size)\n",
    "my_dataset_test  = MyDatasets(test_x, test_t, mini_batch_size)\n",
    "loader_train = torch.utils.data.DataLoader(dataset=my_dataset_train, batch_size=mini_batch_size, shuffle=True)\n",
    "loader_test  = torch.utils.data.DataLoader(dataset=my_dataset_test, batch_size=mini_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_dtype = bb.DType.BIT if bin_mode else bb.DType.FP32\n",
    "\n",
    "def make_conv_layer(batch_norm=True, filter_size=(3,3), padding='valid', bin_dtype=bin_dtype):\n",
    "       return bb.Convolution2d(\n",
    "               bb.Sequential([\n",
    "                   bb.DifferentiableLut([256],  connection='random', bin_dtype=bin_dtype),\n",
    "                   bb.DifferentiableLut([36*6], batch_norm=batch_norm, connection='serial', bin_dtype=bin_dtype),\n",
    "                   bb.DifferentiableLut([36],   batch_norm=batch_norm, connection='serial', bin_dtype=bin_dtype),\n",
    "               ]), padding=padding, filter_size=filter_size, fw_dtype=bin_dtype)\n",
    "\n",
    "# ネット定義\n",
    "core_net = bb.Sequential([])\n",
    "for i in range(depth-1):\n",
    "    core_net.append(make_conv_layer(batch_norm=True, bin_dtype=bin_dtype))\n",
    "core_net.append(make_conv_layer(batch_norm=True, bin_dtype=bin_dtype))\n",
    "\n",
    "#core_net.append(make_conv_layer([1], bin_dtype=bin_dtype))\n",
    "\n",
    "if bin_mode:\n",
    "    net = bb.Sequential([\n",
    "            bb.RealToBinary(frame_modulation_size=frame_modulation_size, depth_modulation_size=depth_modulation_size, bin_dtype=bin_dtype),\n",
    "            core_net,\n",
    "            bb.BinaryToReal(frame_modulation_size=frame_modulation_size, bin_dtype=bin_dtype),\n",
    "            bb.Reduce([1, dst_h, dst_w]),\n",
    "            bb.Sigmoid(),\n",
    "        ])\n",
    "else:\n",
    "    net = bb.Sequential([\n",
    "            core_net,\n",
    "            bb.Reduce([1, dst_h, dst_w]),\n",
    "            bb.Sigmoid(),\n",
    "        ])\n",
    "    \n",
    "\n",
    "net.set_input_shape([3, src_h, src_w])\n",
    "\n",
    "print(net.get_info(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning\n",
    "net.set_input_shape([3, src_h, src_w])\n",
    "\n",
    "bb.load_networks('.data/Scratch_LutCnn', net)\n",
    "\n",
    "loss      = bb.LossMeanSquaredError()\n",
    "optimizer = bb.OptimizerAdam()\n",
    "\n",
    "optimizer.set_variables(net.get_parameters(), net.get_gradients())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # training\n",
    "    loss.clear()\n",
    "    with tqdm(loader_train) as tqdm_loadr:\n",
    "        for x_imgs, t_imgs in tqdm_loadr:\n",
    "            x_buf = bb.FrameBuffer.from_numpy(np.array(x_imgs).astype(np.float32))\n",
    "            t_buf = bb.FrameBuffer.from_numpy(np.array(t_imgs).astype(np.float32))\n",
    "            \n",
    "            y_buf = net.forward(x_buf, train=True)\n",
    "            dy_buf = loss.calculate(y_buf, t_buf)\n",
    "            \n",
    "            net.backward(dy_buf)\n",
    "            optimizer.update()\n",
    "            \n",
    "            tqdm_loadr.set_postfix(loss=loss.get())\n",
    "    train_loss = loss.get()\n",
    "    \n",
    "    # test\n",
    "    loss.clear()\n",
    "    for x_imgs, t_imgs in loader_test:\n",
    "        x_buf = bb.FrameBuffer.from_numpy(np.array(x_imgs).astype(np.float32))\n",
    "        t_buf = bb.FrameBuffer.from_numpy(np.array(t_imgs).astype(np.float32))\n",
    "\n",
    "        y_buf = net.forward(x_buf, train=False)\n",
    "\n",
    "        loss.calculate(y_buf, t_buf)\n",
    "    test_loss = loss.get()\n",
    "    \n",
    "    bb.save_networks('.data/Scratch_LutCnn', net)\n",
    "\n",
    "    print('epoch[%d] : train_loss=%f test_loss=%f' % (epoch, train_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_net = bb.Sequential([\n",
    "                bb.RealToBinary(frame_modulation_size=frame_modulation_size, depth_modulation_size=depth_modulation_size, bin_dtype=bin_dtype),\n",
    "                core_net,\n",
    "                bb.BinaryToReal(frame_modulation_size=frame_modulation_size, bin_dtype=bin_dtype),\n",
    "                bb.Reduce([1, 700-2*margin, 700-2*margin]),\n",
    "                bb.Sigmoid(),\n",
    "            ])\n",
    "    \n",
    "valid_net.set_input_shape([3, 700,700])\n",
    "\n",
    "for i in range(3):\n",
    "    x_buf = bb.FrameBuffer.from_numpy(test_imgs[i:i+1])\n",
    "    t_buf = bb.FrameBuffer.from_numpy(test_masks[i:i+1])\n",
    "    y_buf = valid_net.forward(x_buf, train=False)\n",
    "    plt.subplot(131)\n",
    "    plt.title('image')\n",
    "    plt.imshow(x_buf.numpy()[0].transpose(1, 2, 0))    \n",
    "    plt.subplot(132)\n",
    "    plt.title('inference')\n",
    "    plt.imshow(y_buf.numpy()[0][0] > 0.7)\n",
    "    plt.subplot(133)\n",
    "    plt.title('ground truth')\n",
    "    plt.imshow(t_buf.numpy()[0][0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7.4",
   "language": "python",
   "name": "python3.7.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
