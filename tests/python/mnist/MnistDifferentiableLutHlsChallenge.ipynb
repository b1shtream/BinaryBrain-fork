{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 微分可能LUTモデルによるMNIST学習\n",
    "\n",
    "Stochasticモデルに BatchNormalization や Binarize(backward時はHard-Tanh)を加えることで、より一般的なデータに対してLUT回路学習を行います。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 事前準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import binarybrain as bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1660 SUPER\n"
     ]
    }
   ],
   "source": [
    "#bb.set_host_only(True)\n",
    "print(bb.get_device_name(0))\n",
    "bb.set_device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "異なる閾値で2値化した画像でフレーム数を水増ししながら学習させます。この水増しをバイナリ変調と呼んでいます。\n",
    "\n",
    "ここではフレーム方向の水増し量を frame_modulation_size で指定しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "data_path             = './data/'\n",
    "net_name              = 'MnistDifferentiableLutHlsChallenge'\n",
    "data_path             = os.path.join('./data/', net_name)\n",
    "rtl_sim_path          = '../../verilog/mnist/tb_mnist_lut_simple'\n",
    "rtl_module_name       = 'MnistLutSimple'\n",
    "output_velilog_file   = os.path.join(data_path, net_name + '.v')\n",
    "sim_velilog_file      = os.path.join(rtl_sim_path, rtl_module_name + '.v')\n",
    "\n",
    "epochs                = 32\n",
    "mini_batch_size       = 64*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(rtl_sim_path, exist_ok=True)\n",
    "os.makedirs(data_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットは PyTorch の torchvision を使います。ミニバッチのサイズも DataLoader で指定しています。\n",
    "BinaryBrainではミニバッチをフレーム数として FrameBufferオブジェクトで扱います。\n",
    "バイナリ変調で計算中にフレーム数が変わるためデータセットの準備観点でのミニバッチと呼び分けています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "dataset_path = './data/'\n",
    "dataset_train = torchvision.datasets.MNIST(root=dataset_path, train=True, transform=transforms.ToTensor(), download=True)\n",
    "dataset_test  = torchvision.datasets.MNIST(root=dataset_path, train=False, transform=transforms.ToTensor(), download=True)\n",
    "loader_train = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=mini_batch_size, shuffle=True, num_workers=2)\n",
    "loader_test  = torch.utils.data.DataLoader(dataset=dataset_test,  batch_size=mini_batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワークの構築\n",
    "\n",
    "DifferentiableLut に特に何もオプションをつけなければOKです。<br>\n",
    "バイナリ変調を施すためにネットの前後に RealToBinary層とBinaryToReal層を入れています。<br>\n",
    "send_command で \"binary true\" を送ることで、DifferentiableLut の内部の重み係数が 0.0-1.0 の間に拘束されます。\n",
    "\n",
    "接続数がLUTの物理構成に合わせて、1ノード当たり6個なので層間で6倍以上ノード数が違うと接続されないノードが発生するので、注意してネットワーク設計が必要です。\n",
    "最終段は各クラス7個の結果を出して Reduce で足し合わせています。こうすることで若干の改善がみられるとともに、加算結果が INT3 相当になるために若干尤度を数値的に見ることができるようです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "[Sequential] \n",
      " input  shape : [1, 28, 28] output shape : [10]\n",
      "  --------------------------------------------------------------------\n",
      "  [Binarize] \n",
      "   input  shape : {1, 28, 28} output shape : {1, 28, 28}\n",
      "  --------------------------------------------------------------------\n",
      "  [DifferentiableLut6] \n",
      "   input  shape : {1, 28, 28} output shape : {1024}\n",
      "   binary : 1   batch_norm : 1\n",
      "  --------------------------------------------------------------------\n",
      "  [DifferentiableLut6] \n",
      "   input  shape : {1024} output shape : {512}\n",
      "   binary : 1   batch_norm : 1\n",
      "  --------------------------------------------------------------------\n",
      "  [DifferentiableLut6] \n",
      "   input  shape : {512} output shape : {256}\n",
      "   binary : 1   batch_norm : 1\n",
      "  --------------------------------------------------------------------\n",
      "  [DifferentiableLut6] \n",
      "   input  shape : {256} output shape : {256}\n",
      "   binary : 1   batch_norm : 1\n",
      "  --------------------------------------------------------------------\n",
      "  [DifferentiableLut6] \n",
      "   input  shape : {256} output shape : {128}\n",
      "   binary : 1   batch_norm : 1\n",
      "  --------------------------------------------------------------------\n",
      "  [DifferentiableLut6] \n",
      "   input  shape : {128} output shape : {360}\n",
      "   binary : 1   batch_norm : 1\n",
      "  --------------------------------------------------------------------\n",
      "  [AverageLut] \n",
      "   input  shape : {360} output shape : {60}\n",
      "  --------------------------------------------------------------------\n",
      "  [Reduce] \n",
      "   input  shape : {60} output shape : {10}\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define network\n",
    "if False:\n",
    "    net = bb.Sequential([\n",
    "                bb.Binarize(binary_th=0.5, binary_low=0.0, binary_high=1.0),\n",
    "                bb.DifferentiableLut([256]),\n",
    "                bb.DifferentiableLut([64*6]),\n",
    "                bb.AverageLut([64], connection='serial'),\n",
    "                bb.DifferentiableLut([60*6]),\n",
    "                bb.AverageLut([60], connection='serial'),\n",
    "                bb.Reduce([10]),\n",
    "            ])\n",
    "#\n",
    "\n",
    "net = bb.Sequential([\n",
    "            bb.Binarize(binary_th=0.5, binary_low=0.0, binary_high=1.0),\n",
    "            bb.DifferentiableLut([1024]),\n",
    "            bb.DifferentiableLut([512]),\n",
    "            bb.DifferentiableLut([256]),\n",
    "            bb.DifferentiableLut([256]),\n",
    "            bb.DifferentiableLut([128]),\n",
    "            bb.DifferentiableLut([60*6]),\n",
    "            bb.AverageLut([60]),\n",
    "#           bb.AverageLut([60], connection='serial'),\n",
    "            bb.Reduce([10]),\n",
    "        ])\n",
    "\n",
    "net.set_input_shape([1, 28, 28])\n",
    "\n",
    "net.send_command(\"binary true\")\n",
    "\n",
    "loss      = bb.LossSoftmaxCrossEntropy()\n",
    "metrics   = bb.MetricsCategoricalAccuracy()\n",
    "optimizer = bb.OptimizerAdam(learning_rate=0.0001)\n",
    "\n",
    "net.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bb.load_networks(data_path, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=64*4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の実施\n",
    "\n",
    "load_networks/save_networks で途中結果を保存/復帰可能できます。ネットワークの構造が変わると正常に読み込めなくなるので注意ください。\n",
    "(その場合は新しいネットをsave_networksするまで一度load_networks をコメントアウトください)\n",
    "\n",
    "tqdm などを使うと学習過程のプログレス表示ができて便利です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[0] : loss=1.258996 accuracy=0.737800\n",
      "epoch[1] : loss=1.130509 accuracy=0.834800\n",
      "epoch[2] : loss=1.070093 accuracy=0.872600\n",
      "epoch[3] : loss=1.056846 accuracy=0.884800\n",
      "epoch[4] : loss=1.039391 accuracy=0.884900\n",
      "epoch[5] : loss=1.021478 accuracy=0.888300\n",
      "epoch[6] : loss=1.048017 accuracy=0.881900\n",
      "epoch[7] : loss=1.039668 accuracy=0.882500\n",
      "epoch[8] : loss=1.024815 accuracy=0.896300\n",
      "epoch[9] : loss=1.016340 accuracy=0.899300\n",
      "epoch[10] : loss=1.010772 accuracy=0.900000\n",
      "epoch[11] : loss=1.008850 accuracy=0.899300\n",
      "epoch[12] : loss=1.005124 accuracy=0.894800\n",
      "epoch[13] : loss=1.016559 accuracy=0.895300\n",
      "epoch[14] : loss=1.007699 accuracy=0.903200\n",
      "epoch[15] : loss=1.020140 accuracy=0.894800\n",
      "epoch[16] : loss=1.003123 accuracy=0.897600\n",
      "epoch[17] : loss=1.013102 accuracy=0.899000\n",
      "epoch[18] : loss=1.031602 accuracy=0.896000\n",
      "epoch[19] : loss=1.003892 accuracy=0.908200\n",
      "epoch[20] : loss=0.992965 accuracy=0.908200\n",
      "epoch[21] : loss=1.004521 accuracy=0.902200\n",
      "epoch[22] : loss=0.996291 accuracy=0.900000\n",
      "epoch[23] : loss=0.994509 accuracy=0.908700\n",
      "epoch[24] : loss=1.001110 accuracy=0.904200\n",
      "epoch[25] : loss=1.008149 accuracy=0.898900\n",
      "epoch[26] : loss=0.991668 accuracy=0.910000\n",
      "epoch[27] : loss=0.999480 accuracy=0.906200\n",
      "epoch[28] : loss=0.997874 accuracy=0.908400\n",
      "epoch[29] : loss=1.001418 accuracy=0.903100\n",
      "epoch[30] : loss=1.001723 accuracy=0.896800\n",
      "epoch[31] : loss=0.992020 accuracy=0.909700\n",
      "epoch[32] : loss=0.984803 accuracy=0.910800\n",
      "epoch[33] : loss=0.989894 accuracy=0.914400\n",
      "epoch[34] : loss=1.006918 accuracy=0.896800\n",
      "epoch[35] : loss=1.000620 accuracy=0.898400\n",
      "epoch[36] : loss=0.983831 accuracy=0.910600\n",
      "epoch[37] : loss=0.990445 accuracy=0.909200\n",
      "epoch[38] : loss=0.992747 accuracy=0.905000\n",
      "epoch[39] : loss=0.978530 accuracy=0.915800\n",
      "epoch[40] : loss=0.993708 accuracy=0.899500\n",
      "epoch[41] : loss=0.998207 accuracy=0.911900\n",
      "epoch[42] : loss=0.996070 accuracy=0.905100\n",
      "epoch[43] : loss=0.988152 accuracy=0.903000\n",
      "epoch[44] : loss=0.982794 accuracy=0.906600\n",
      "epoch[45] : loss=1.001315 accuracy=0.899800\n",
      "epoch[46] : loss=1.007627 accuracy=0.897900\n",
      "epoch[47] : loss=0.980736 accuracy=0.909300\n",
      "epoch[48] : loss=0.981919 accuracy=0.913400\n",
      "epoch[49] : loss=1.008306 accuracy=0.901500\n",
      "epoch[50] : loss=0.982152 accuracy=0.909500\n",
      "epoch[51] : loss=1.012356 accuracy=0.892400\n",
      "epoch[52] : loss=0.994073 accuracy=0.905300\n",
      "epoch[53] : loss=0.975826 accuracy=0.916900\n",
      "epoch[54] : loss=0.986947 accuracy=0.906800\n",
      "epoch[55] : loss=1.011848 accuracy=0.889700\n",
      "epoch[56] : loss=0.977017 accuracy=0.909700\n",
      "epoch[57] : loss=0.991697 accuracy=0.911700\n",
      "epoch[58] : loss=0.998093 accuracy=0.910200\n",
      "epoch[59] : loss=0.977541 accuracy=0.917000\n",
      "epoch[60] : loss=0.980538 accuracy=0.915500\n",
      "epoch[61] : loss=0.985967 accuracy=0.916600\n",
      "epoch[62] : loss=1.010721 accuracy=0.888300\n",
      "epoch[63] : loss=0.984488 accuracy=0.907700\n",
      "epoch[64] : loss=0.982853 accuracy=0.911400\n",
      "epoch[65] : loss=0.984672 accuracy=0.913800\n",
      "epoch[66] : loss=0.979778 accuracy=0.915500\n",
      "epoch[67] : loss=0.988622 accuracy=0.908600\n",
      "epoch[68] : loss=0.995230 accuracy=0.907900\n",
      "epoch[69] : loss=0.989311 accuracy=0.908700\n",
      "epoch[70] : loss=0.979366 accuracy=0.915200\n",
      "epoch[71] : loss=0.987968 accuracy=0.912900\n",
      "epoch[72] : loss=0.993697 accuracy=0.911500\n",
      "epoch[73] : loss=0.975630 accuracy=0.913900\n",
      "epoch[74] : loss=0.987314 accuracy=0.906900\n",
      "epoch[75] : loss=0.985250 accuracy=0.914700\n",
      "epoch[76] : loss=0.984307 accuracy=0.912300\n",
      "epoch[77] : loss=0.987063 accuracy=0.909300\n",
      "epoch[78] : loss=0.997535 accuracy=0.904100\n",
      "epoch[79] : loss=0.990263 accuracy=0.908100\n",
      "epoch[80] : loss=0.981052 accuracy=0.909700\n",
      "epoch[81] : loss=0.986611 accuracy=0.908200\n",
      "epoch[82] : loss=0.990886 accuracy=0.909500\n",
      "epoch[83] : loss=0.970571 accuracy=0.917800\n",
      "epoch[84] : loss=0.994432 accuracy=0.903300\n",
      "epoch[85] : loss=0.989103 accuracy=0.904200\n",
      "epoch[86] : loss=0.982871 accuracy=0.911400\n",
      "epoch[87] : loss=0.976746 accuracy=0.911700\n",
      "epoch[88] : loss=1.000053 accuracy=0.901600\n",
      "epoch[89] : loss=0.988391 accuracy=0.910100\n",
      "epoch[90] : loss=0.982349 accuracy=0.911900\n",
      "epoch[91] : loss=0.984550 accuracy=0.911900\n",
      "epoch[92] : loss=0.989365 accuracy=0.903200\n",
      "epoch[93] : loss=0.981268 accuracy=0.917100\n",
      "epoch[94] : loss=0.978267 accuracy=0.914300\n",
      "epoch[95] : loss=0.971893 accuracy=0.914300\n",
      "epoch[96] : loss=0.994260 accuracy=0.908100\n",
      "epoch[97] : loss=0.982347 accuracy=0.912200\n",
      "epoch[98] : loss=0.992339 accuracy=0.904600\n",
      "epoch[99] : loss=0.982023 accuracy=0.908900\n",
      "epoch[100] : loss=0.974793 accuracy=0.914000\n",
      "epoch[101] : loss=0.998998 accuracy=0.908200\n",
      "epoch[102] : loss=0.985388 accuracy=0.913600\n",
      "epoch[103] : loss=0.986422 accuracy=0.904400\n",
      "epoch[104] : loss=0.979581 accuracy=0.914400\n",
      "epoch[105] : loss=0.989230 accuracy=0.903100\n",
      "epoch[106] : loss=0.990520 accuracy=0.905400\n",
      "epoch[107] : loss=0.979097 accuracy=0.917100\n",
      "epoch[108] : loss=0.984772 accuracy=0.913200\n",
      "epoch[109] : loss=0.983393 accuracy=0.914000\n",
      "epoch[110] : loss=0.978324 accuracy=0.912200\n",
      "epoch[111] : loss=0.970535 accuracy=0.915600\n",
      "epoch[112] : loss=0.983977 accuracy=0.915000\n",
      "epoch[113] : loss=0.989779 accuracy=0.909300\n",
      "epoch[114] : loss=0.993053 accuracy=0.902900\n",
      "epoch[115] : loss=0.989127 accuracy=0.909400\n",
      "epoch[116] : loss=0.979446 accuracy=0.916100\n",
      "epoch[117] : loss=0.984898 accuracy=0.914200\n",
      "epoch[118] : loss=0.991251 accuracy=0.904100\n",
      "epoch[119] : loss=0.994396 accuracy=0.907600\n",
      "epoch[120] : loss=0.984732 accuracy=0.911000\n",
      "epoch[121] : loss=0.970961 accuracy=0.920200\n",
      "epoch[122] : loss=0.987159 accuracy=0.916700\n",
      "epoch[123] : loss=0.982783 accuracy=0.912200\n",
      "epoch[124] : loss=0.975425 accuracy=0.916900\n",
      "epoch[125] : loss=1.003961 accuracy=0.903600\n",
      "epoch[126] : loss=0.996385 accuracy=0.904600\n",
      "epoch[127] : loss=0.979277 accuracy=0.909900\n",
      "epoch[128] : loss=0.984823 accuracy=0.908300\n",
      "epoch[129] : loss=0.993422 accuracy=0.913800\n",
      "epoch[130] : loss=0.997491 accuracy=0.906300\n",
      "epoch[131] : loss=0.983671 accuracy=0.912400\n",
      "epoch[132] : loss=0.999810 accuracy=0.901900\n",
      "epoch[133] : loss=0.987957 accuracy=0.913800\n",
      "epoch[134] : loss=0.978885 accuracy=0.917000\n",
      "epoch[135] : loss=0.977029 accuracy=0.916200\n",
      "epoch[136] : loss=0.989832 accuracy=0.907700\n",
      "epoch[137] : loss=0.979418 accuracy=0.914100\n",
      "epoch[138] : loss=0.977957 accuracy=0.918400\n",
      "epoch[139] : loss=0.967699 accuracy=0.917300\n",
      "epoch[140] : loss=0.987108 accuracy=0.908200\n",
      "epoch[141] : loss=0.983966 accuracy=0.908400\n",
      "epoch[142] : loss=0.981491 accuracy=0.913100\n",
      "epoch[143] : loss=0.984065 accuracy=0.915300\n",
      "epoch[144] : loss=0.976690 accuracy=0.917900\n",
      "epoch[145] : loss=0.973852 accuracy=0.920100\n",
      "epoch[146] : loss=0.986707 accuracy=0.911200\n",
      "epoch[147] : loss=0.970408 accuracy=0.919900\n",
      "epoch[148] : loss=0.991925 accuracy=0.908800\n",
      "epoch[149] : loss=0.997300 accuracy=0.907100\n",
      "epoch[150] : loss=0.971183 accuracy=0.917400\n",
      "epoch[151] : loss=0.979739 accuracy=0.913800\n",
      "epoch[152] : loss=0.984316 accuracy=0.910700\n",
      "epoch[153] : loss=0.989543 accuracy=0.910700\n",
      "epoch[154] : loss=0.978389 accuracy=0.912300\n",
      "epoch[155] : loss=0.995824 accuracy=0.903400\n",
      "epoch[156] : loss=0.971828 accuracy=0.917100\n",
      "epoch[157] : loss=0.983466 accuracy=0.914400\n",
      "epoch[158] : loss=0.974515 accuracy=0.912600\n",
      "epoch[159] : loss=0.997367 accuracy=0.904600\n",
      "epoch[160] : loss=0.980563 accuracy=0.915900\n",
      "epoch[161] : loss=0.976356 accuracy=0.910200\n",
      "epoch[162] : loss=0.964482 accuracy=0.919900\n",
      "epoch[163] : loss=0.977331 accuracy=0.910900\n",
      "epoch[164] : loss=0.998658 accuracy=0.901500\n",
      "epoch[165] : loss=0.972172 accuracy=0.917200\n",
      "epoch[166] : loss=0.986607 accuracy=0.915000\n",
      "epoch[167] : loss=0.986343 accuracy=0.903600\n",
      "epoch[168] : loss=0.983537 accuracy=0.910300\n",
      "epoch[169] : loss=0.976818 accuracy=0.917500\n",
      "epoch[170] : loss=0.984315 accuracy=0.916800\n",
      "epoch[171] : loss=0.989508 accuracy=0.911400\n",
      "epoch[172] : loss=0.983358 accuracy=0.915500\n",
      "epoch[173] : loss=0.994916 accuracy=0.906500\n",
      "epoch[174] : loss=0.979187 accuracy=0.918700\n",
      "epoch[175] : loss=0.972264 accuracy=0.917700\n",
      "epoch[176] : loss=0.979303 accuracy=0.912300\n",
      "epoch[177] : loss=0.975354 accuracy=0.918300\n",
      "epoch[178] : loss=0.974199 accuracy=0.917400\n",
      "epoch[179] : loss=0.987666 accuracy=0.909000\n",
      "epoch[180] : loss=0.987357 accuracy=0.915700\n",
      "epoch[181] : loss=0.988995 accuracy=0.907200\n",
      "epoch[182] : loss=0.978751 accuracy=0.912000\n",
      "epoch[183] : loss=1.007537 accuracy=0.902500\n",
      "epoch[184] : loss=0.985222 accuracy=0.909800\n",
      "epoch[185] : loss=0.978682 accuracy=0.911200\n",
      "epoch[186] : loss=0.968593 accuracy=0.919700\n",
      "epoch[187] : loss=0.991249 accuracy=0.913000\n",
      "epoch[188] : loss=0.991924 accuracy=0.905200\n",
      "epoch[189] : loss=0.987283 accuracy=0.911000\n",
      "epoch[190] : loss=0.999240 accuracy=0.904000\n",
      "epoch[191] : loss=0.986734 accuracy=0.905200\n",
      "epoch[192] : loss=0.982177 accuracy=0.908200\n",
      "epoch[193] : loss=0.974960 accuracy=0.918900\n",
      "epoch[194] : loss=0.969405 accuracy=0.920100\n",
      "epoch[195] : loss=0.996845 accuracy=0.903100\n",
      "epoch[196] : loss=0.974750 accuracy=0.910700\n",
      "epoch[197] : loss=0.989163 accuracy=0.910800\n",
      "epoch[198] : loss=0.987879 accuracy=0.910400\n",
      "epoch[199] : loss=0.989240 accuracy=0.903900\n",
      "epoch[200] : loss=0.975060 accuracy=0.915800\n",
      "epoch[201] : loss=0.980059 accuracy=0.915700\n",
      "epoch[202] : loss=0.989573 accuracy=0.902700\n",
      "epoch[203] : loss=0.989901 accuracy=0.906400\n",
      "epoch[204] : loss=1.005164 accuracy=0.899300\n",
      "epoch[205] : loss=0.973410 accuracy=0.917200\n",
      "epoch[206] : loss=0.972471 accuracy=0.917200\n",
      "epoch[207] : loss=0.983056 accuracy=0.914300\n",
      "epoch[208] : loss=0.974368 accuracy=0.919300\n",
      "epoch[209] : loss=0.980056 accuracy=0.918900\n",
      "epoch[210] : loss=0.999236 accuracy=0.900300\n",
      "epoch[211] : loss=0.992071 accuracy=0.906900\n",
      "epoch[212] : loss=0.980812 accuracy=0.918000\n",
      "epoch[213] : loss=0.984548 accuracy=0.911700\n",
      "epoch[214] : loss=0.995211 accuracy=0.901100\n",
      "epoch[215] : loss=0.975663 accuracy=0.914200\n",
      "epoch[216] : loss=0.974102 accuracy=0.922100\n",
      "epoch[217] : loss=0.986380 accuracy=0.906000\n",
      "epoch[218] : loss=0.989815 accuracy=0.913700\n",
      "epoch[219] : loss=1.002705 accuracy=0.900000\n",
      "epoch[220] : loss=0.975273 accuracy=0.919600\n",
      "epoch[221] : loss=0.974326 accuracy=0.913900\n",
      "epoch[222] : loss=0.987603 accuracy=0.908100\n",
      "epoch[223] : loss=0.992416 accuracy=0.905500\n",
      "epoch[224] : loss=0.969237 accuracy=0.920100\n",
      "epoch[225] : loss=0.988247 accuracy=0.910900\n",
      "epoch[226] : loss=0.971929 accuracy=0.918200\n",
      "epoch[227] : loss=0.993024 accuracy=0.908700\n",
      "epoch[228] : loss=0.995937 accuracy=0.905000\n",
      "epoch[229] : loss=0.972873 accuracy=0.916100\n",
      "epoch[230] : loss=1.007338 accuracy=0.898300\n",
      "epoch[231] : loss=0.983890 accuracy=0.914600\n",
      "epoch[232] : loss=0.972880 accuracy=0.912800\n",
      "epoch[233] : loss=0.971171 accuracy=0.922500\n",
      "epoch[234] : loss=0.993079 accuracy=0.912000\n",
      "epoch[235] : loss=0.989669 accuracy=0.906400\n",
      "epoch[236] : loss=0.985661 accuracy=0.912900\n",
      "epoch[237] : loss=0.975062 accuracy=0.912400\n",
      "epoch[238] : loss=1.005848 accuracy=0.904500\n",
      "epoch[239] : loss=0.973656 accuracy=0.919300\n",
      "epoch[240] : loss=0.989580 accuracy=0.905800\n",
      "epoch[241] : loss=0.974639 accuracy=0.915100\n",
      "epoch[242] : loss=0.972156 accuracy=0.919600\n",
      "epoch[243] : loss=0.976978 accuracy=0.914700\n",
      "epoch[244] : loss=0.972868 accuracy=0.913600\n",
      "epoch[245] : loss=0.974852 accuracy=0.914700\n",
      "epoch[246] : loss=0.978108 accuracy=0.916200\n",
      "epoch[247] : loss=0.976307 accuracy=0.914300\n",
      "epoch[248] : loss=0.989118 accuracy=0.909200\n",
      "epoch[249] : loss=1.004291 accuracy=0.894500\n",
      "epoch[250] : loss=0.987013 accuracy=0.910600\n",
      "epoch[251] : loss=0.981835 accuracy=0.915000\n",
      "epoch[252] : loss=0.986602 accuracy=0.910200\n",
      "epoch[253] : loss=0.982314 accuracy=0.914700\n",
      "epoch[254] : loss=0.990285 accuracy=0.904100\n",
      "epoch[255] : loss=0.986375 accuracy=0.911800\n"
     ]
    }
   ],
   "source": [
    "#bb.load_networks(data_path, net)\n",
    "\n",
    "# learning\n",
    "optimizer.set_variables(net.get_parameters(), net.get_gradients())\n",
    "for epoch in range(epochs):\n",
    "    # learning\n",
    "    loss.clear()\n",
    "    metrics.clear()\n",
    "#   with tqdm(loader_train) as t:\n",
    "#       for images, labels in t:\n",
    "    for images, labels in loader_train:\n",
    "            x_buf = bb.FrameBuffer.from_numpy(np.array(images).astype(np.float32))\n",
    "            t_buf = bb.FrameBuffer.from_numpy(np.identity(10)[np.array(labels)].astype(np.float32))\n",
    "\n",
    "            y_buf = net.forward(x_buf, train=True)\n",
    "\n",
    "            dy_buf = loss.calculate(y_buf, t_buf)\n",
    "            metrics.calculate(y_buf, t_buf)\n",
    "\n",
    "            net.backward(dy_buf)\n",
    "\n",
    "            optimizer.update()\n",
    "        \n",
    "#           t.set_postfix(loss=loss.get(), acc=metrics.get())\n",
    "\n",
    "    # test\n",
    "    loss.clear()\n",
    "    metrics.clear()\n",
    "    for images, labels in loader_test:\n",
    "        x_buf = bb.FrameBuffer.from_numpy(np.array(images).astype(np.float32))\n",
    "        t_buf = bb.FrameBuffer.from_numpy(np.identity(10)[np.array(labels)].astype(np.float32))\n",
    "\n",
    "        y_buf = net.forward(x_buf, train=False)\n",
    "\n",
    "        loss.calculate(y_buf, t_buf)\n",
    "        metrics.calculate(y_buf, t_buf)\n",
    "    print('epoch[%d] : loss=%f accuracy=%f' % (epoch, loss.get(), metrics.get()))\n",
    "    \n",
    "    bb.save_networks(data_path, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2069451464.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [10]\u001b[0;36m\u001b[0m\n\u001b[0;31m    ----------------\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FPGA用HLS(C言語高位合成)で使う為の出力\n",
    "\n",
    "内部データを取得する例としてHSL(C言語高位合成)用の出力を作ってみます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lut_func_name(name, node):\n",
    "    return \"%s_%d\"%(name, node)\n",
    "\n",
    "\n",
    "def dump_hls_lut_node5(f, name, lut, node):\n",
    "    n = lut.get_node_connection_size(node)\n",
    "    s = lut.get_lut_table_size(node)\n",
    "    tbl = 0\n",
    "    for i in range(s):\n",
    "        if lut.get_lut_table(node ,i):\n",
    "            tbl += (1 << i)\n",
    "    f.write(\"Q(%s,0x%016xLL)\\n\"%(make_lut_func_name(name, node), tbl))\n",
    "#   f.write(\"LF(%s,0x%016x)\\n\"%(make_lut_func_name(name, node), tbl))\n",
    "\n",
    "def dump_hls_lut_node4(f, name, lut, node):\n",
    "#    f.write(\"\\ninline ap_uint<1> %s(\\n\"%(make_lut_func_name(name, node)))\n",
    "    f.write(\"\\nap_uint<1> %s(\\n\"%(make_lut_func_name(name, node)))\n",
    "    n = lut.get_node_connection_size(node)\n",
    "    s = lut.get_lut_table_size(node)\n",
    "    \n",
    "    tbl = 0\n",
    "    for i in range(s):\n",
    "        if lut.get_lut_table(node ,i):\n",
    "            tbl += (1 << i)\n",
    "    \n",
    "    for i in range(n):\n",
    "        f.write(\"        ap_uint<1> in_data%d\"%(i))\n",
    "        if i < n-1:\n",
    "            f.write(\",\\n\")\n",
    "        else:\n",
    "            f.write(\")\\n\")\n",
    "    f.write(\"{\\n\")\n",
    "#   f.write(\"#pragma HLS inline\\n\")\n",
    "    f.write(\"    ap_uint<%d> index;\\n\"%(n))\n",
    "    for i in range(n):\n",
    "        f.write(\"    index[%d] = in_data%d;\\n\"%(i, i))\n",
    "    f.write(\"    return ((0x%016xLL >> index) & 1);\\n\"%tbl)\n",
    "    f.write(\"}\\n\\n\")\n",
    "\n",
    "def dump_hls_lut_node3(f, name, lut, node):\n",
    "    f.write(\"\\ninline ap_uint<1> %s(\\n\"%(make_lut_func_name(name, node)))\n",
    "#    f.write(\"\\nap_uint<1> %s(\\n\"%(make_lut_func_name(name, node)))\n",
    "    n = lut.get_node_connection_size(node)\n",
    "    s = lut.get_lut_table_size(node)\n",
    "    \n",
    "    tbl = 0\n",
    "    for i in range(s):\n",
    "        if lut.get_lut_table(node ,i):\n",
    "            tbl += (1 << i)\n",
    "    \n",
    "    for i in range(n):\n",
    "        f.write(\"        ap_uint<1> in_data%d\"%(i))\n",
    "        if i < n-1:\n",
    "            f.write(\",\\n\")\n",
    "        else:\n",
    "            f.write(\")\\n\")\n",
    "    f.write(\"{\\n\")\n",
    "#   f.write(\"#pragma HLS inline\\n\")\n",
    "    f.write(\"    ap_uint<%d> index;\\n\"%(n))\n",
    "    for i in range(n):\n",
    "        f.write(\"    index[%d] = in_data%d;\\n\"%(i, i))\n",
    "    f.write(\"    static Lut6Model table(0x%016xLL);\\n\"%(tbl))\n",
    "    f.write(\"    return table.Get(index);\\n\")\n",
    "    f.write(\"}\\n\\n\")\n",
    "\n",
    "def dump_hls_lut_node2(f, name, lut, node):\n",
    "    f.write(\"\\ninline ap_uint<1> %s(\\n\"%(make_lut_func_name(name, node)))\n",
    "    n = lut.get_node_connection_size(node)\n",
    "    s = lut.get_lut_table_size(node)\n",
    "    for i in range(n):\n",
    "        f.write(\"        ap_uint<1> in_data%d\"%(i))\n",
    "        if i < n-1:\n",
    "            f.write(\",\\n\")\n",
    "        else:\n",
    "            f.write(\")\\n\")\n",
    "    f.write(\"{\\n\")\n",
    "    f.write(\"#pragma HLS inline\\n\\n\")\n",
    "    f.write(\"    ap_uint<%d> index;\\n\"%(n))\n",
    "    for i in range(n):\n",
    "        f.write(\"    index[%d] = in_data%d;\\n\"%(i, i))\n",
    "    f.write(\"    \\n\")\n",
    "    f.write(\"    const ap_uint<1> table[%d] = {\"%(s))\n",
    "    for i in range(s):\n",
    "        f.write(\"%d,\"%(lut.get_lut_table(node ,i)))\n",
    "    f.write(\"};\\n\")\n",
    "#    for i in range(s):\n",
    "#        f.write(\"    table[%d] = %d;\\n\"%(i, lut.get_lut_table(node ,i)))\n",
    "#    f.write(\"    \\n\")\n",
    "#   f.write(\"    #pragma HLS resource variable=table core=ROM_1P_LUTRAM\\n\")\n",
    "    f.write(\"    #pragma HLS bind_storage variable=table type=ROM_1P impl=LUTRAM\\n\")\n",
    "    f.write(\"    return table[index];\\n\")\n",
    "    f.write(\"}\\n\\n\")\n",
    "\n",
    "def dump_hls_lut_node1(f, name, lut, node):\n",
    "    f.write(\"\\ninline ap_uint<1> %s(\\n\"%(make_lut_func_name(name, node)))\n",
    "    n = lut.get_node_connection_size(node)\n",
    "    s = lut.get_lut_table_size(node)\n",
    "    \n",
    "    tbl = 0\n",
    "    for i in range(s):\n",
    "        if lut.get_lut_table(node ,i):\n",
    "            tbl += (1 << i)\n",
    "    \n",
    "    for i in range(n):\n",
    "        f.write(\"        ap_uint<1> in_data%d\"%(i))\n",
    "        if i < n-1:\n",
    "            f.write(\",\\n\")\n",
    "        else:\n",
    "            f.write(\")\\n\")\n",
    "    f.write(\"{\\n\")\n",
    "    f.write(\"#pragma HLS inline\\n\")\n",
    "    f.write(\"    ap_uint<%d> index;\\n\"%(n))\n",
    "    for i in range(n):\n",
    "        f.write(\"    index[%d] = in_data%d;\\n\"%(i, i))\n",
    "    f.write(\"    const ap_uint<%d> table= 0x%016xLL;\\n\"%(s, tbl))\n",
    "    f.write(\"    return table[index];\\n\")\n",
    "    f.write(\"}\\n\\n\")\n",
    "\n",
    "def dump_hls_lut(f, name, lut):\n",
    "    ins  = lut.get_input_node_size()\n",
    "    outs = lut.get_output_node_size()\n",
    "    for node in range(outs):\n",
    "        dump_hls_lut_node5(f, name, lut, node)\n",
    "    \n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"inline ap_uint<%d> %s(ap_uint<%d> i)\\n\"%(outs, name, ins))\n",
    "    f.write(\"{\\n\")\n",
    "    f.write(\"ap_uint<%d>  o;\\n\"%(outs))\n",
    "    for node in range(outs):\n",
    "        f.write(\"o[%d]=%s(\"%(node, make_lut_func_name(name, node)))\n",
    "        n = lut.get_node_connection_size(node)\n",
    "        for i in range(n):\n",
    "            f.write(\"i[%d]\"%(lut.get_node_connection_index(node, i)))\n",
    "            if i < n-1: \n",
    "                f.write(\",\")\n",
    "            else:\n",
    "                f.write(\");\\n\")\n",
    "    f.write(\"return o;\\n\")   \n",
    "    f.write(\"}\\n\\n\")\n",
    "\n",
    "# 学習済みを読みなおす\n",
    "#bb.load_networks(data_path, net)\n",
    "with open(\"MnistDifferentiableLutSimpleHls_.h\", \"w\") as f:\n",
    "#   f.write('#include \"ap_int.h\"\\n\\n')\n",
    "    for i in range(1, 4):\n",
    "        dump_hls_lut(f, \"l%d\"%i, net[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = (net[4].W().quantize(16, 1/256).numpy() * 256).astype(np.int32)\n",
    "b = (net[4].b().quantize(16, 1/256).numpy() * 256).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(W))\n",
    "print(np.min(W))\n",
    "print(np.max(b))\n",
    "print(np.min(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"MnistDifferentiableLutSimpleHls2_.h\", \"w\") as f:\n",
    "    f.write('\\n\\n')\n",
    "    f.write('#define WLEN %d\\n\\n'%W.shape[1])    \n",
    "    f.write('const ap_int<WBITS> W_tbl[10][WLEN] =\\n')\n",
    "    f.write('\\t{\\n')\n",
    "    for i in range(10):\n",
    "        f.write('\\t\\t{')\n",
    "        for j in range(W.shape[1]):\n",
    "            f.write('%5d, '%W[i][j])\n",
    "        f.write('\\t\\t},\\n')\n",
    "    f.write('\\t};\\n\\n')\n",
    "    \n",
    "    f.write('const ap_int<BBITS> b_tbl[10] =\\n')\n",
    "    f.write('\\t{')\n",
    "    for i in range(10):\n",
    "        f.write('%5d, '%b[i])\n",
    "    f.write('};\\n\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "with open('mnist_hls_test_.txt', 'w') as f:\n",
    "    for images, labels in loader_test:\n",
    "        x_buf = np.array(images).astype(np.float32)\n",
    "        t_buf = np.array(labels)\n",
    "        for i in range(x_buf.shape[0]):\n",
    "            f.write(\"%d\"%t_buf[i])\n",
    "            for y in range(x_buf.shape[2]):\n",
    "                for x in range(x_buf.shape[3]):\n",
    "                    f.write(\" %d\"%(x_buf[i, 0, y, x] > 0.5))\n",
    "            f.write(\"\\n\")\n",
    "            num += 1\n",
    "        if num > 1024:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp MnistDifferentiableLutSimpleHls_.h ../../../_work/mnist6-free/\n",
    "!cp MnistDifferentiableLutSimpleHls2_.h ../../../_work/mnist6-free/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e42ac7cce52f856a953029bf8d6268c151b6ce75ee0dd17c7a9f0cf75b5e0010"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
