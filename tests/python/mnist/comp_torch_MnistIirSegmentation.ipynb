{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ff49c-32b3-4d05-88fe-65f6fc5a154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Function\n",
    "\n",
    "import binarybrain as bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95e14dd-c6a6-4746-ae8e-51779b49c5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c48d334-fb03-434b-b164-21389176a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.get_version_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45079310-59c4-4bb5-8b40-a607f37dace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_mode = True\n",
    "frame_modulation_size = 3\n",
    "\n",
    "verbose = 0\n",
    "\n",
    "epochs = 8\n",
    "\n",
    "loops = 3\n",
    "depth = 2\n",
    "ch = 32\n",
    "\n",
    "# 並べるタイル数\n",
    "rows=2\n",
    "cols=2\n",
    "img_h = 32\n",
    "img_w = 32\n",
    "\n",
    "data_path = './data/cmp_torch_mnist_iir_segmentation'\n",
    "mini_batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fece6b51-4175-40bb-ab8c-a2e6a18b34f1",
   "metadata": {},
   "source": [
    "## 学習データ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a0c62b-5fc3-47e2-9a40-c6beb585b085",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset\n",
    "transform = transforms.Compose([\n",
    "                transforms.Resize((img_w, img_h)),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "\n",
    "dataset_path = './data/'\n",
    "dataset_train = torchvision.datasets.MNIST(root=dataset_path, train=True, transform=transform, download=True)\n",
    "dataset_test  = torchvision.datasets.MNIST(root=dataset_path, train=False, transform=transform, download=True)\n",
    "\n",
    "\n",
    "def make_teacher_image(gen, rows, cols, margin=0):\n",
    "    source_img  = np.zeros((1, rows*img_h, cols*img_w), dtype=np.float32)\n",
    "    teaching_img = np.zeros((11, rows*img_h, cols*img_w), dtype=np.float32)\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            x = col*img_w\n",
    "            y = row*img_h\n",
    "            img, label = gen.__next__()\n",
    "            source_img[0,y:y+img_h,x:x+img_w] = img\n",
    "            teaching_img[label,y:y+img_h,x:x+img_w] = img\n",
    "            teaching_img[10,y:y+img_h,x:x+img_w] = (1.0-img)\n",
    "    teaching_img = (teaching_img > 0.5).astype(np.float32)\n",
    "    \n",
    "    # 面積で重みを載せる\n",
    "    for i in range(11):\n",
    "        teaching_img[i] *= weight[i]\n",
    "    \n",
    "    # ランダムに反転\n",
    "    if random.random() > 0.5:\n",
    "        source_img = 1.0 - source_img\n",
    "\n",
    "    if margin > 0:\n",
    "        return source_img, teaching_img[:,margin:-margin,margin:-margin]\n",
    "    return source_img, teaching_img        \n",
    "\n",
    "def transform_data(dataset, n, rows, cols, margin):\n",
    "    def data_gen():\n",
    "        l = len(dataset)\n",
    "        i = 0\n",
    "        while True:\n",
    "            yield dataset[i%l]\n",
    "            i += 1\n",
    "    \n",
    "    gen = data_gen()\n",
    "    source_imgs = []\n",
    "    teaching_imgs = []\n",
    "    for _ in range(n):\n",
    "        x, t = make_teacher_image(gen, rows, cols, margin)\n",
    "        source_imgs.append(x)\n",
    "        teaching_imgs.append(t)\n",
    "    return source_imgs, teaching_imgs\n",
    "\n",
    "class MyDatasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, source_imgs, teaching_imgs, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.source_imgs = source_imgs\n",
    "        self.teaching_imgs = teaching_imgs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.source_imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        source_img = self.source_imgs[index]\n",
    "        teaching_img = self.teaching_imgs[index]\n",
    "        if self.transforms:\n",
    "            source_img, teaching_img = self.transforms(source_img, teaching_img)\n",
    "        return source_img, teaching_img\n",
    "\n",
    "# フィルタ処理用にタイル化する\n",
    "dataset_fname = os.path.join(data_path, 'dataset.pickle')\n",
    "if os.path.exists(dataset_fname):\n",
    "#if False:\n",
    "    with open(dataset_fname, 'rb') as f:\n",
    "        source_imgs_train = pickle.load(f)\n",
    "        teaching_imgs_train = pickle.load(f)\n",
    "        source_imgs_test = pickle.load(f)\n",
    "        teaching_imgs_test = pickle.load(f)\n",
    "        weight = pickle.load(f)\n",
    "else:\n",
    "    # 面積の比率で重み作成\n",
    "    areas = np.zeros((11))\n",
    "    for img, label in dataset_train:\n",
    "        img = img.numpy()\n",
    "        areas[label] += np.mean(img)\n",
    "        areas[10] += np.mean(1.0-img)\n",
    "    areas /= len(dataset_train)\n",
    "    \n",
    "    weight = 1 / areas\n",
    "    weight /= np.sum(weight)\n",
    "    \n",
    "    source_imgs_train, teaching_imgs_train = transform_data(dataset_train, 4096, rows, cols, 0) #29)\n",
    "    source_imgs_test, teaching_imgs_test = transform_data(dataset_test, 128, rows, cols, 0) #, 29)\n",
    "    \n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "    with open(dataset_fname, 'wb') as f:\n",
    "        pickle.dump(source_imgs_train, f)\n",
    "        pickle.dump(teaching_imgs_train, f)\n",
    "        pickle.dump(source_imgs_test, f)\n",
    "        pickle.dump(teaching_imgs_test, f)\n",
    "        pickle.dump(weight, f)\n",
    "\n",
    "my_dataset_train = MyDatasets(source_imgs_train, teaching_imgs_train)\n",
    "my_dataset_test = MyDatasets(source_imgs_test, teaching_imgs_test)\n",
    "\n",
    "loader_train = torch.utils.data.DataLoader(dataset=my_dataset_train, batch_size=mini_batch_size, shuffle=True)\n",
    "loader_test = torch.utils.data.DataLoader(dataset=my_dataset_test, batch_size=mini_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c9d49-d7e9-4ac9-a7e3-f0fd26d64658",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_data(x, y, n=2):\n",
    "    \"\"\"データ表示確認\"\"\"\n",
    "    n = min(x.shape[0], n)\n",
    "    plt.figure(figsize=(18,2*n))\n",
    "    for i in range(n):\n",
    "        plt.subplot(n,12,i*12+1)\n",
    "        plt.title('sorce')\n",
    "        plt.imshow(x[i][0], 'gray')\n",
    "        for j in range(11):\n",
    "            plt.subplot(n,12,i*12+2+j)\n",
    "            if j < 10:\n",
    "                plt.title('class=%d'%j)\n",
    "                plt.imshow(y[i][j], 'gray')\n",
    "            else:\n",
    "                plt.title('background')\n",
    "                plt.imshow(y[i][j], 'gray')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c98ba22-6fef-408e-8c45-e03a1894024b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 学習データ表示確認\n",
    "if False:\n",
    "    plt.figure(figsize=(16,8))\n",
    "    for x, t in loader_test:\n",
    "        break\n",
    "\n",
    "    plot_data(x, t, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf28925c-6a6c-4a06-b000-e215143b60ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_numpy(x):\n",
    "    if type(x) == np.ndarray:\n",
    "        return x\n",
    "    if type(x) == bb.FrameBuffer or type(x) == bb.Tensor:\n",
    "        return x.numpy()\n",
    "    if type(x) == torch.Tensor:\n",
    "        return x.to('cpu').detach().clone().numpy()\n",
    "    return x.to('cpu').detach().clone().numpy()\n",
    "\n",
    "def calc_corrcoef(a, b):\n",
    "    a = to_numpy(a).reshape(-1)\n",
    "    b = to_numpy(b).reshape(-1)\n",
    "    return np.corrcoef(a, b)[0][1]\n",
    "\n",
    "def print_summary(x, text=\"\"):\n",
    "    x = to_numpy(x)\n",
    "    print(\"[%s] mean:%1.8f std:%1.8f min:%1.8f max:%1.8f isnan:%d\"%(text, np.mean(x), np.std(x), np.min(x), np.max(x), np.isnan(x).any()))\n",
    "\n",
    "def print_diff(a, b, text=\"\"):\n",
    "    a = to_numpy(a)\n",
    "    b = to_numpy(b).reshape(a.shape)\n",
    "    print_summary(a - b, text=text)\n",
    "\n",
    "def print_diff_summary(a_bb, a_torch, text=\"\"):\n",
    "    a_bb    = to_numpy(a_bb)\n",
    "    a_torch = to_numpy(a_torch).reshape(a_bb.shape)\n",
    "    r = calc_corrcoef(a_bb, a_torch)\n",
    "    print('[corrcoef:%f]'%r)\n",
    "    print_summary(a_bb,           text=text+\" bb   \")\n",
    "    print_summary(a_torch,        text=text+\" torch\")\n",
    "    print_summary(a_bb - a_torch, text=text+\" diff\")\n",
    "\n",
    "def print_param_status(param, name=\"\"):\n",
    "    print('[%s] mean:%f std:%f min:%f max:%f nan:'%(name, np.nanmean(param), np.nanstd(param), np.nanmin(param), np.nanmax(param)), np.isnan(param).any())\n",
    "\n",
    "def print_param_affine_bb(affine_bb, name=\"\"):\n",
    "    print_param_status(affine_bb.W().numpy(), name+'.W')\n",
    "    print_param_status(affine_bb.b().numpy(), name+'.b')\n",
    "    print_param_status(affine_bb.dW().numpy(), name+'.dW')\n",
    "    print_param_status(affine_bb.db().numpy(), name+'.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc0be0-dc10-4c4a-bec6-27b05f2d6f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_affine_param(model_bb, model_torch):\n",
    "    model_bb.W().set_numpy(to_numpy(model_torch.weight).reshape(model_bb.W().get_shape()))\n",
    "    model_bb.b().set_numpy(to_numpy(model_torch.bias).reshape(model_bb.b().get_shape()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8d3db5-d9b4-4e2e-9646-d19d59497ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_numpy_info(x, name=\"\"):\n",
    "    print('[%s] std:%f, min:%f, max:%f, nan:'%(name, np.std(x), np.min(x), np.max(x)), np.isnan(x).any(), x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27119e65-a3c8-4e69-9939-fd6c8dd6753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_object(obj, file):\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_object(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c887fd-b20c-49e8-8bca-a26db62daf70",
   "metadata": {},
   "source": [
    "## ネットワーク定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a04fe2b-b29b-45b1-922f-b916d5594a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "class Binarize(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        ctx.save_for_backward(x)\n",
    "        y = x.new(x.size())\n",
    "        y[x >= 0] = 1.0\n",
    "        y[x < 0] = -1.0\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dy):\n",
    "        x, = ctx.saved_tensors\n",
    "        dx = dy.clone()\n",
    "        dx[x.ge(1)]=0\n",
    "        dx[x.le(-1)]=0\n",
    "        return dx\n",
    "binarize = Binarize.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b117620-6170-4463-912a-0bb2d2e340a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# バイナリ時は BIT型を使えばメモリ削減可能\n",
    "#bin_dtype = bb.DType.BIT if bin_mode else bb.DType.FP32\n",
    "bin_dtype = bb.DType.FP32\n",
    "\n",
    "class AffineBlock(bb.Sequential):\n",
    "    def __init__(self, out_ch, batch_norm=False, activation=True, name=\"\"):\n",
    "        self.batch_norm = batch_norm\n",
    "        self.activation = activation\n",
    "        self.affine = bb.DenseAffine([out_ch, 1, 1], name=name+'_affine')\n",
    "        self.bn     = bb.BatchNormalization(name=name+'_bn')\n",
    "        self.act    = bb.Binarize(name=name+'_act')\n",
    "        layers = [self.affine]\n",
    "        if batch_norm: layers.append(self.bn)\n",
    "        if activation: layers.append(self.act)\n",
    "        super(AffineBlock, self).__init__(layers, name=name)\n",
    "    \n",
    "    def forward(self, x, train=True):\n",
    "        x = self.affine.forward(x, train=True)\n",
    "        if self.batch_norm:\n",
    "            x = self.bn.forward(x, train=True)\n",
    "        if self.activation:\n",
    "            x = self.act.forward(x, train=True)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, dy):\n",
    "        if self.activation:\n",
    "            dy = self.act.backward(dy)\n",
    "        if self.batch_norm:\n",
    "            dy = self.bn.backward(dy)\n",
    "        dy = self.affine.backward(dy)\n",
    "        return dy\n",
    "\n",
    "class Convolution(bb.Sequential):\n",
    "    def __init__(self, in_ch, out_ch, batch_norm=False, activation=True, name=\"\"):\n",
    "        self.batch_norm = batch_norm\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.cnv_torch = nn.Conv2d(in_ch, out_ch, 3, padding=1, padding_mode='reflect').to(device) # 'replicate'\n",
    "        self.bn_torch  = nn.BatchNorm2d(out_ch).to(device)\n",
    "        \n",
    "        self.blk_bb = AffineBlock(out_ch, name=name+'_blk')\n",
    "        self.cnv_bb    = bb.Convolution2d(\n",
    "                                self.blk_bb,\n",
    "                                filter_size=(3, 3),\n",
    "                                padding='same',\n",
    "                                name=name+'_cnv',\n",
    "                                fw_dtype=bin_dtype)\n",
    "        super(Convolution, self).__init__([self.cnv_bb], name=name)\n",
    "    \n",
    "    def parameters(self):\n",
    "        if self.batch_norm:\n",
    "            return list(self.cnv_torch.parameters()) + list(self.bn_torch.parameters())\n",
    "        else:\n",
    "            return list(self.cnv_torch.parameters())\n",
    "    \n",
    "    def set_input_shape(self, shape):\n",
    "        shape = self.cnv_bb.set_input_shape(shape)\n",
    "        copy_affine_param(self.blk_bb.affine, self.cnv_torch)\n",
    "        return shape\n",
    "    \n",
    "    def forward(self, x, train=True):\n",
    "        if verbose > 10:\n",
    "            print_diff_summary(x[1], x[0], text=self.name+\" fw cnv x\")\n",
    "#       print((to_numpy(x[0]) == 0).sum(), (to_numpy(x[1]) == 0).sum())\n",
    "#       print_diff_summary(self.affine_bb.W(), self.cnv_torch.weight, text=self.name+\".W\")\n",
    "#       print_diff_summary(self.affine_bb.b(), self.cnv_torch.bias, text=self.name+\".b\")\n",
    "        \n",
    "        y_torch = self.cnv_torch(x[0])\n",
    "        if self.batch_norm:\n",
    "            y_torch = self.bn_torch(y_torch)\n",
    "        if self.activation:\n",
    "            y_torch = binarize(y_torch)\n",
    "            \n",
    "        y_bb = self.cnv_bb.forward(x[1], train=train)\n",
    "        \n",
    "#        a = to_numpy(y_torch)\n",
    "#        b = to_numpy(y_bb)\n",
    "#        m = ((a*b)<0)\n",
    "#        print('minus:', m.sum())\n",
    "#        print('a:', a[m])\n",
    "#        print('b:', b[m])\n",
    "#        print_diff_summary(y_bb, y_torch, text=self.name+\" fw minus\")\n",
    "        \n",
    "        \n",
    "#       print_diff_summary(y_bb, y_torch, text=self.name+\" fw cnv y\")\n",
    "        return (y_torch, y_bb)\n",
    "    \n",
    "    def backward(self, dy):\n",
    "        dx = self.cnv_bb.backward(dy)\n",
    "        return dx\n",
    "\n",
    "class UpSampling(bb.Sequential):\n",
    "    def __init__(self, name=\"\"):\n",
    "        self.up_torch = nn.Upsample(scale_factor=2, mode='nearest').to(device)\n",
    "        self.up_bb    = bb.UpSampling((2, 2), fw_dtype=bin_dtype)\n",
    "        super(UpSampling, self).__init__([self.up_bb], name=name)\n",
    "\n",
    "    def parameters(self):\n",
    "        return list()\n",
    "        \n",
    "    def forward(self, x, train=True):\n",
    "        if verbose > 10:\n",
    "            print_diff_summary(x[1], x[0], text=self.name+\" fw up x\")\n",
    "        y_torch = self.up_torch(x[0])\n",
    "        y_bb    = self.up_bb.forward(x[1], train=train)\n",
    "        if verbose > 10:\n",
    "            print_diff_summary(y_bb, y_torch, text=self.name+\" fw up y\")\n",
    "        return (y_torch, y_bb)\n",
    "\n",
    "    \n",
    "class MaxPooling(bb.Sequential):\n",
    "    def __init__(self, name=\"\"):\n",
    "        self.pool_torch = nn.MaxPool2d(2, 2).to(device)\n",
    "        self.pool_bb    = bb.MaxPooling((2, 2), fw_dtype=bin_dtype)\n",
    "        super(MaxPooling, self).__init__([self.pool_bb], name=name)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return list()\n",
    "    \n",
    "    def forward(self, x, train=True):\n",
    "        if verbose > 10:\n",
    "            print_diff_summary(x[1], x[0], text=self.name+\" fw pool x\")\n",
    "        y_torch = self.pool_torch(x[0])\n",
    "        y_bb    = self.pool_bb.forward(x[1], train=train)\n",
    "        if verbose > 10:\n",
    "            print_diff_summary(y_bb, y_torch, text=self.name+\" fw pool y\")\n",
    "        return (y_torch, y_bb)\n",
    "\n",
    "class Concatenate(bb.Sequential):\n",
    "    def __init__(self, name=\"\"):\n",
    "        self.cat_bb = bb.Concatenate()\n",
    "        super(Concatenate, self).__init__([self.cat_bb], name=name)\n",
    "\n",
    "    def parameters(self):\n",
    "        return list()\n",
    "\n",
    "    def set_input_shape(self, shape):\n",
    "        return self.cat_bb.set_input_shape(shape)\n",
    "    \n",
    "    def forward(self, x, train=True):\n",
    "        y_torch = torch.cat([x[0][0], x[1][0]], 1)\n",
    "        y_bb    = self.cat_bb.forward([x[0][1], x[1][1]], train=train)\n",
    "        return (y_torch, y_bb)\n",
    "    \n",
    "    def backward(self, dy):\n",
    "        dy = self.cat_bb.backward(dy)\n",
    "        return dy\n",
    "\n",
    "\n",
    "class ConvBlock(bb.Sequential):\n",
    "    \"\"\"基本ブロック\"\"\"\n",
    "    def __init__(self, in_ch=32, hid_ch=32, out_ch=32, name=\"\"):\n",
    "        self.cnv0  = Convolution(in_ch, hid_ch, name=name+\"_cnv0\")\n",
    "        self.cnv1  = Convolution(hid_ch, out_ch, name=name+\"_cnv1\")\n",
    "        super(ConvBlock, self).__init__([self.cnv0, self.cnv1], name=name)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.cnv0.parameters() + self.cnv1.parameters()\n",
    "\n",
    "    def set_input_shape(self, shape):\n",
    "        shape = self.cnv0.set_input_shape(shape)\n",
    "        shape = self.cnv1.set_input_shape(shape)\n",
    "        return shape\n",
    "    \n",
    "    def forward(self, x, train=True):\n",
    "        x = self.cnv0.forward(x, train=train)\n",
    "        x = self.cnv1.forward(x, train=train)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, dy):\n",
    "        dy = self.cnv1.backward(dy)\n",
    "        dy = self.cnv0.backward(dy)\n",
    "        return dy\n",
    "\n",
    "class ScaledNetwork(bb.Sequential):\n",
    "    \"\"\"スケール階層モデル\"\"\"\n",
    "    def __init__(self, ch=32, top=False):\n",
    "        self.top = top\n",
    "        self.ch  = ch\n",
    "        \n",
    "        self.up   = UpSampling()\n",
    "        self.pool = MaxPooling()\n",
    "        self.cat0 = Concatenate()\n",
    "        self.cat1 = Concatenate()\n",
    "        if self.top:\n",
    "            self.cnv0 = ConvBlock(1+self.ch, self.ch, self.ch, name=\"m_blk0\")\n",
    "            self.cnv1 = ConvBlock(self.ch,   self.ch, 11,      name=\"m_blk1\")\n",
    "        else:\n",
    "            self.cnv0 = ConvBlock(self.ch*2, self.ch, self.ch, name=\"s_blk0\")\n",
    "            self.cnv1 = ConvBlock(self.ch*2, self.ch, self.ch, name=\"s_blk1\")\n",
    "        \n",
    "        super(ScaledNetwork, self).__init__([self.up, self.pool, self.cnv0, self.cnv1])\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.cnv0.parameters() + self.cnv1.parameters()\n",
    "    \n",
    "    def set_input_shape(self, x0_shape, x1_shape, u_shape):\n",
    "        x1_shape = self.up.set_input_shape(x1_shape)        \n",
    "        x_shape = self.cat0.set_input_shape([x0_shape, x1_shape])\n",
    "        x_shape = self.cnv0.set_input_shape(x_shape)\n",
    "        v_shape = self.pool.set_input_shape(x_shape)\n",
    "        if not self.top:\n",
    "            x_shape = self.cat1.set_input_shape([u_shape, x_shape])\n",
    "        y_shape = self.cnv1.set_input_shape(x_shape)\n",
    "        return y_shape, v_shape\n",
    "    \n",
    "    def forward(self, x0, x1, u, train=True):\n",
    "        x1 = self.up.forward(x1, train=train)\n",
    "        x  = self.cat0.forward([x0, x1], train=train)\n",
    "        x  = self.cnv0.forward(x, train=train)        \n",
    "        v = self.pool.forward(x, train=train)\n",
    "        if not self.top:\n",
    "            x = self.cat1.forward([u, x], train=train)\n",
    "        y = self.cnv1.forward(x, train=train)\n",
    "        return y, v\n",
    "    \n",
    "    def backward(self, dy, dv):\n",
    "        dy = self.cnv1.backward(dy)\n",
    "        if not self.top:\n",
    "            du, dy0 = self.cat1.backward([dy])\n",
    "        else:\n",
    "            du, dy0 = None, dy\n",
    "        dy1 = self.pool.backward(dv)\n",
    "        dy = self.cnv0.backward(dy0 + dy1)\n",
    "        dx0, dx1 = self.cat0.backward([dy])\n",
    "        dx1 = self.up.backward(dx1)\n",
    "        return dx0, dx1, du\n",
    "\n",
    "\n",
    "class MipmapNetwork(bb.Sequential):\n",
    "    \"\"\"ミップマップ型ネット\"\"\"\n",
    "    def __init__(self, loop=3, depth=4, ch=32):\n",
    "        self.loop    = loop\n",
    "        self.depth   = depth\n",
    "        self.ch      = ch\n",
    "        self.shape   = None\n",
    "#       self.r2b     = bb.RealToBinary(frame_modulation_size=frame_modulation_size, bin_dtype=bin_dtype)\n",
    "#       self.b2r     = bb.BinaryToReal(frame_integration_size=frame_modulation_size, bin_dtype=bin_dtype)\n",
    "        self.up      = UpSampling()\n",
    "        self.m_net = ScaledNetwork(ch, top=True)\n",
    "        self.s_net = ScaledNetwork(ch)\n",
    "        super(MipmapNetwork, self).__init__([self.m_net, self.s_net])\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.m_net.parameters() + self.s_net.parameters()\n",
    "\n",
    "    def set_input_shape(self, shape):\n",
    "        self.shape = copy.copy(shape)\n",
    "#       shape = self.r2b.set_input_shape(shape)\n",
    "        \n",
    "        x0_shape = copy.copy(shape)\n",
    "        x1_shape = copy.copy(shape)\n",
    "        x1_shape[0] = self.ch\n",
    "        x1_shape[1] //= 2\n",
    "        x1_shape[2] //= 2\n",
    "        u_shape = copy.copy(shape)\n",
    "        y_shape, v_shape = self.m_net.set_input_shape(x0_shape, x1_shape, u_shape)\n",
    "        \n",
    "        x0_shape = copy.copy(x1_shape)\n",
    "        x0_shape[0] = self.ch\n",
    "        x1_shape = copy.copy(x1_shape)\n",
    "        x1_shape[0] = self.ch\n",
    "        x1_shape[1] //= 2\n",
    "        x1_shape[2] //= 2\n",
    "        self.s_net.set_input_shape(x0_shape, x1_shape, v_shape)\n",
    "        \n",
    "#       y_shape = self.b2r.set_input_shape(y_shape)\n",
    "        return y_shape\n",
    "    \n",
    "    def make_mipmap(self, n, dtype=bin_dtype):\n",
    "        h = self.shape[1]\n",
    "        w = self.shape[2]\n",
    "        mipmap = []\n",
    "        for i in range(self.depth+1):\n",
    "            h //= 2\n",
    "            w //= 2\n",
    "#           buf = np.random.normal(0., 0.1, size=(n, self.ch, h, w)).astype(np.float32)\n",
    "#           buf[buf >0] =+1.0\n",
    "#           buf[buf<=0] =-1.0\n",
    "#           buf_bb    = bb.FrameBuffer.from_numpy(buf)\n",
    "#           buf_torch = torch.tensor(buf.copy()).to(device)\n",
    "            buf_torch = torch.zeros(n, self.ch, h, w).to(device)\n",
    "            buf_bb    = bb.FrameBuffer.zeros(n, (self.ch, h, w), dtype=dtype)\n",
    "            mipmap.append([buf_torch, buf_bb])\n",
    "        return mipmap\n",
    "    \n",
    "    def make_mipmap_bb(self, n, dtype=bin_dtype):\n",
    "        h = self.shape[1]\n",
    "        w = self.shape[2]\n",
    "        mipmap = []\n",
    "        for i in range(self.depth+1):\n",
    "            h //= 2\n",
    "            w //= 2\n",
    "            buf_bb = bb.FrameBuffer.zeros(n, (self.ch, h, w), dtype=dtype)\n",
    "            mipmap.append(buf_bb)\n",
    "        return mipmap\n",
    "    \n",
    "    def forward(self, x, train=True):\n",
    "        self.m_net.clear()\n",
    "        self.s_net.clear()\n",
    "        \n",
    "#       x = self.r2b.forward(x)\n",
    "\n",
    "        frame_size = x[1].get_frame_size()\n",
    "        self.shape = x[1].get_node_shape()\n",
    "        \n",
    "        y_list = []\n",
    "        mipmap = self.make_mipmap(frame_size)        \n",
    "        for i in range(self.loop):\n",
    "#           print('\\n------ %d -------\\n'%i)\n",
    "            y, v = self.m_net.forward(x, mipmap[0], None, train=train)\n",
    "            if i < self.loop-1:\n",
    "                for j in range(self.depth):\n",
    "                    mipmap[j], v = self.s_net.forward(mipmap[j], mipmap[j+1], v)\n",
    "                self.v_shape = v[1].get_node_shape()\n",
    "#           y = self.b2r.forward(y)\n",
    "            y_list.append(y)\n",
    "        return y_list\n",
    "    \n",
    "    def backward(self, dy_list):\n",
    "        frame_size = dy_list[0].get_frame_size() # * frame_modulation_size\n",
    "        \n",
    "        dv = bb.FrameBuffer.zeros(frame_size, self.v_shape, dtype=bb.DType.FP32)\n",
    "        \n",
    "        shape = dy_list[0].get_node_shape()\n",
    "        shape[0] = self.ch\n",
    "        shape[1] //=2\n",
    "        shape[2] //=2\n",
    "        du = bb.FrameBuffer.zeros(frame_size, shape, dtype=bb.DType.FP32)\n",
    "        \n",
    "        mipmap = self.make_mipmap_bb(frame_size, dtype=bb.DType.FP32)\n",
    "        for i in reversed(range(self.loop)):\n",
    "            if i < self.loop-1:\n",
    "                du = dv\n",
    "                for j in reversed(range(self.depth)):\n",
    "                    dx0, dx1, du = self.s_net.backward(mipmap[j], du)\n",
    "                    mipmap[j]    = dx0\n",
    "                    mipmap[j+1] += dx1\n",
    "            dy = dy_list[i]  # dy = self.b2r.backward(dy_list[i])\n",
    "            dx0, dx1, du = self.m_net.backward(dy, du)\n",
    "            mipmap[0] = dx1\n",
    "        return dx0\n",
    "\n",
    "def view(net, loader, n=2):\n",
    "    \"\"\"表示確認\"\"\"\n",
    "    for x, t in loader:\n",
    "        break\n",
    "    \n",
    "    x = bb.FrameBuffer.from_numpy(np.array(x).astype(np.float32))\n",
    "    yy = net.forward(x, train=False)\n",
    "    y = yy[-1]\n",
    "    \n",
    "    x = x.numpy()\n",
    "    y = y.numpy()\n",
    "    \n",
    "    plot_data(x, y, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96629d1-f327-41a5-855f-e2d8f6aa696a",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9626ab2-8b5f-48ba-8710-8890c9d1d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_param():\n",
    "    print_diff_summary(net.m_net.cnv0.cnv0.blk_bb.affine.W(), net.m_net.cnv0.cnv0.cnv_torch.weight)\n",
    "    print_diff_summary(net.m_net.cnv0.cnv0.blk_bb.affine.b(), net.m_net.cnv0.cnv0.cnv_torch.bias)\n",
    "    print_diff_summary(net.m_net.cnv0.cnv1.blk_bb.affine.W(), net.m_net.cnv0.cnv1.cnv_torch.weight)\n",
    "    print_diff_summary(net.m_net.cnv0.cnv1.blk_bb.affine.b(), net.m_net.cnv0.cnv1.cnv_torch.bias)\n",
    "    print_diff_summary(net.m_net.cnv1.cnv0.blk_bb.affine.W(), net.m_net.cnv1.cnv0.cnv_torch.weight)\n",
    "    print_diff_summary(net.m_net.cnv1.cnv0.blk_bb.affine.b(), net.m_net.cnv1.cnv0.cnv_torch.bias)\n",
    "    print_diff_summary(net.m_net.cnv1.cnv1.blk_bb.affine.W(), net.m_net.cnv1.cnv1.cnv_torch.weight)\n",
    "    print_diff_summary(net.m_net.cnv1.cnv1.blk_bb.affine.b(), net.m_net.cnv1.cnv1.cnv_torch.bias)\n",
    "\n",
    "    print_diff_summary(net.s_net.cnv0.cnv0.blk_bb.affine.W(), net.s_net.cnv0.cnv0.cnv_torch.weight)\n",
    "    print_diff_summary(net.s_net.cnv0.cnv0.blk_bb.affine.b(), net.s_net.cnv0.cnv0.cnv_torch.bias)\n",
    "    print_diff_summary(net.s_net.cnv0.cnv1.blk_bb.affine.W(), net.s_net.cnv0.cnv1.cnv_torch.weight)\n",
    "    print_diff_summary(net.s_net.cnv0.cnv1.blk_bb.affine.b(), net.s_net.cnv0.cnv1.cnv_torch.bias)\n",
    "    print_diff_summary(net.s_net.cnv1.cnv0.blk_bb.affine.W(), net.s_net.cnv1.cnv0.cnv_torch.weight)\n",
    "    print_diff_summary(net.s_net.cnv1.cnv0.blk_bb.affine.b(), net.s_net.cnv1.cnv0.cnv_torch.bias)\n",
    "    print_diff_summary(net.s_net.cnv1.cnv1.blk_bb.affine.W(), net.s_net.cnv1.cnv1.cnv_torch.weight)\n",
    "    print_diff_summary(net.s_net.cnv1.cnv1.blk_bb.affine.b(), net.s_net.cnv1.cnv1.cnv_torch.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f26542-fc9e-4272-b412-221901e651f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MipmapNetwork(loop=loops, depth=depth)\n",
    "net.set_input_shape([1, img_h*rows, img_w*cols])\n",
    "net.send_command(\"binary true\")\n",
    "\n",
    "\n",
    "weight_torch    = torch.from_numpy(weight.astype(np.float32)).clone().to(device)\n",
    "criterion_torch = nn.CrossEntropyLoss(weight=weight_torch)  # 面積に応じて重み付けする\n",
    "optimizer_torch = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "criterion_bb = bb.LossSoftmaxCrossEntropy()\n",
    "metrics_bb   = bb.MetricsCategoricalAccuracy()\n",
    "optimizer_bb = bb.OptimizerAdam(learning_rate=0.001)\n",
    "optimizer_bb.set_variables(net.get_parameters(), net.get_gradients())\n",
    "\n",
    "criterion_bb.clear()\n",
    "metrics_bb.clear()\n",
    "net.clear()\n",
    "\n",
    "loss_torch_sum = 0\n",
    "loss_torch_n   = 0\n",
    "\n",
    "epochs= 64\n",
    "for epoch in range(epochs):\n",
    "    # learning\n",
    "    criterion_bb.clear()\n",
    "    metrics_bb.clear()\n",
    "    net.clear()\n",
    "    with tqdm(loader_train) as tqdm_loadr:\n",
    "        for x_torch, t_torch in tqdm_loadr:\n",
    "            optimizer_torch.zero_grad()\n",
    "            net.clear()\n",
    "#           x_torch[x_torch>0.5] = +1\n",
    "#           x_torch[x_torch<=0.5] = -1\n",
    "            \n",
    "            x_bb = bb.FrameBuffer.from_numpy(np.array(x_torch).astype(np.float32))\n",
    "            t_bb = bb.FrameBuffer.from_numpy(np.array(t_torch).astype(np.float32))\n",
    "            \n",
    "            x_torch = x_torch.to(device)\n",
    "            t_torch = t_torch.to(device)\n",
    "            \n",
    "            y_list = net.forward([x_torch, x_bb], train=True)\n",
    "            \n",
    "            y_torch_list = []\n",
    "            for y in y_list:\n",
    "                y_torch_list.append(y[0])\n",
    "            yy_torch = torch.cat(y_torch_list, 0)\n",
    "            tt_torch = torch.cat([t_torch]*loops, 0)\n",
    "            loss_torch = criterion_torch(yy_torch, torch.argmax(tt_torch, dim=1))\n",
    "            loss_torch.backward()\n",
    "            \n",
    "            # 複数の出力それぞれ loss 計算\n",
    "            dy_list = []\n",
    "            for y in y_list:\n",
    "                dy = criterion_bb.calculate(y[1], t_bb)\n",
    "                dy_list.append(dy)\n",
    "            \n",
    "            # 最後の一個で精度確認\n",
    "#           metrics.calculate(y_list[-1], t)\n",
    "            \n",
    "            # backward\n",
    "            net.backward(dy_list)\n",
    "            \n",
    "            optimizer_torch.step()\n",
    "            optimizer_bb.update()\n",
    "            \n",
    "            loss_torch_sum += loss_torch.item()\n",
    "            loss_torch_n   += 1\n",
    "            \n",
    "            if verbose > 0:\n",
    "                print_param()\n",
    "            tqdm_loadr.set_postfix(loss_bb=criterion_bb.get(), loss_torch=loss_torch_sum/loss_torch_n)\n",
    "    \n",
    "#   bb.save_networks(data_path, net, backups=3)\n",
    "#   view(net, loader_test, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbb21ef-a7df-4732-842d-c63541c293ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_diff_summary(y_list[0][1], y_list[0][0], text='y0')\n",
    "print_diff_summary(y_list[1][1], y_list[1][0], text='y1')\n",
    "#print_diff_summary(y_list[2][1], y_list[2][0], text='y2')\n",
    "#print_diff_summary(y_list[3][1], y_list[3][0], text='y3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d7efff-7eab-4248-948d-daec800491e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_diff_summary(net.s_net.cnv0.cnv0.affine_bb.dW(), net.s_net.cnv0.cnv0.cnv_torch.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78666370-d66d-4b8e-8348-d7b50d5a8523",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_diff_summary(net.m_net.cnv0.cnv0.affine_bb.dW(), net.m_net.cnv0.cnv0.cnv_torch.weight.grad)\n",
    "print_diff_summary(net.m_net.cnv0.cnv0.affine_bb.db(), net.m_net.cnv0.cnv0.cnv_torch.bias.grad)\n",
    "print_diff_summary(net.m_net.cnv0.cnv1.affine_bb.dW(), net.m_net.cnv0.cnv1.cnv_torch.weight.grad)\n",
    "print_diff_summary(net.m_net.cnv0.cnv1.affine_bb.db(), net.m_net.cnv0.cnv1.cnv_torch.bias.grad)\n",
    "print_diff_summary(net.m_net.cnv1.cnv0.affine_bb.dW(), net.m_net.cnv1.cnv0.cnv_torch.weight.grad)\n",
    "print_diff_summary(net.m_net.cnv1.cnv0.affine_bb.db(), net.m_net.cnv1.cnv0.cnv_torch.bias.grad)\n",
    "print_diff_summary(net.m_net.cnv1.cnv1.affine_bb.dW(), net.m_net.cnv1.cnv1.cnv_torch.weight.grad)\n",
    "print_diff_summary(net.m_net.cnv1.cnv1.affine_bb.db(), net.m_net.cnv1.cnv1.cnv_torch.bias.grad)\n",
    "\n",
    "print_diff_summary(net.s_net.cnv0.cnv0.affine_bb.dW(), net.s_net.cnv0.cnv0.cnv_torch.weight.grad)\n",
    "print_diff_summary(net.s_net.cnv0.cnv0.affine_bb.db(), net.s_net.cnv0.cnv0.cnv_torch.bias.grad)\n",
    "print_diff_summary(net.s_net.cnv0.cnv1.affine_bb.dW(), net.s_net.cnv0.cnv1.cnv_torch.weight.grad)\n",
    "print_diff_summary(net.s_net.cnv0.cnv1.affine_bb.db(), net.s_net.cnv0.cnv1.cnv_torch.bias.grad)\n",
    "print_diff_summary(net.s_net.cnv1.cnv0.affine_bb.dW(), net.s_net.cnv1.cnv0.cnv_torch.weight.grad)\n",
    "print_diff_summary(net.s_net.cnv1.cnv0.affine_bb.db(), net.s_net.cnv1.cnv0.cnv_torch.bias.grad)\n",
    "print_diff_summary(net.s_net.cnv1.cnv1.affine_bb.dW(), net.s_net.cnv1.cnv1.cnv_torch.weight.grad)\n",
    "print_diff_summary(net.s_net.cnv1.cnv1.affine_bb.db(), net.s_net.cnv1.cnv1.cnv_torch.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6cef23-9511-4e69-9d79-66668d2757de",
   "metadata": {},
   "outputs": [],
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b299e2-505c-44ec-9676-0404e9a0d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_corrcoef(a, b):\n",
    "    a = to_numpy(a).reshape(-1)\n",
    "    b = to_numpy(b).reshape(-1)\n",
    "    return np.corrcoef(a, b)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb82a4c-f4ed-4f09-8830-bdbb44d873b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_corrcoef(net.m_net.cnv0.cnv0.affine_bb.dW(), net.m_net.cnv0.cnv0.cnv_torch.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15993ca4-b546-44fd-b024-65023ef0d328",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.m_net.cnv0.cnv0.affine_bb.dW().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86d2fee-69cc-4c71-a7d8-dfda312b94b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.m_net.cnv0.cnv0.cnv_torch.weight.grad.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285c9459-45d6-438a-ae0a-9913ce4aa654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f2d615-9445-4463-96a8-6bcc393981fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b60647-7af2-4f6c-848b-44f2dd698137",
   "metadata": {},
   "outputs": [],
   "source": [
    "view(net, loader_test, n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf7011c-f295-49d9-80f7-1a1281df265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.save_networks(data_path, net, 'bin_dense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72f2e9c-ff5f-407b-88c4-2ea4419570fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.load_networks(data_path, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4597084d-eb65-49dd-b69a-612d431f1d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
