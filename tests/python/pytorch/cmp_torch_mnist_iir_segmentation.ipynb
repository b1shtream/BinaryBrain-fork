{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ff49c-32b3-4d05-88fe-65f6fc5a154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Function\n",
    "\n",
    "import binarybrain as bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56977fd7-801d-4ac5-a8f9-6114c11ee3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c48d334-fb03-434b-b164-21389176a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.get_version_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45079310-59c4-4bb5-8b40-a607f37dace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "bb.set_device(0)\n",
    "\n",
    "verbose = 0\n",
    "\n",
    "net_name               = 'cmp_torch_mnist_iir_segmentation'\n",
    "data_path              = os.path.join('./data/', net_name)\n",
    "\n",
    "bin_mode               = False\n",
    "#frame_modulation_size  = 1\n",
    "#depth_integration_size = 1\n",
    "epochs                 = 16\n",
    "mini_batch_size        = 16\n",
    "\n",
    "loops = 3\n",
    "depth = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d88499f-e5d8-4718-8139-9a5610371f90",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 並べるタイル数\n",
    "rows=2\n",
    "cols=2\n",
    "\n",
    "img_h = 32\n",
    "img_w = 32\n",
    "\n",
    "# dataset\n",
    "transform = transforms.Compose([\n",
    "                transforms.Resize((img_w, img_h)),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "\n",
    "dataset_path = './data/'\n",
    "dataset_train = torchvision.datasets.MNIST(root=dataset_path, train=True, transform=transform, download=True)\n",
    "dataset_test  = torchvision.datasets.MNIST(root=dataset_path, train=False, transform=transform, download=True)\n",
    "\n",
    "\n",
    "def make_teacher_image(gen, rows, cols, margin=0):\n",
    "    source_img  = np.zeros((1, rows*img_h, cols*img_w), dtype=np.float32)\n",
    "    teaching_img = np.zeros((11, rows*img_h, cols*img_w), dtype=np.float32)\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            x = col*img_w\n",
    "            y = row*img_h\n",
    "            img, label = gen.__next__()\n",
    "            source_img[0,y:y+img_h,x:x+img_w] = img\n",
    "            teaching_img[label,y:y+img_h,x:x+img_w] = img\n",
    "            teaching_img[10,y:y+img_h,x:x+img_w] = (1.0-img)\n",
    "    teaching_img = (teaching_img > 0.5).astype(np.float32)\n",
    "    \n",
    "    # 面積で重みを載せる\n",
    "    for i in range(11):\n",
    "        teaching_img[i] *= weight[i]\n",
    "    \n",
    "    # ランダムに反転\n",
    "    if random.random() > 0.5:\n",
    "        source_img = 1.0 - source_img\n",
    "\n",
    "    if margin > 0:\n",
    "        return source_img, teaching_img[:,margin:-margin,margin:-margin]\n",
    "    return source_img, teaching_img\n",
    "\n",
    "def transform_data(dataset, n, rows, cols, margin):\n",
    "    def data_gen():\n",
    "        l = len(dataset)\n",
    "        i = 0\n",
    "        while True:\n",
    "            yield dataset[i%l]\n",
    "            i += 1\n",
    "    \n",
    "    gen = data_gen()\n",
    "    source_imgs = []\n",
    "    teaching_imgs = []\n",
    "    for _ in range(n):\n",
    "        x, t = make_teacher_image(gen, rows, cols, margin)\n",
    "        source_imgs.append(x)\n",
    "        teaching_imgs.append(t)\n",
    "    return source_imgs, teaching_imgs\n",
    "\n",
    "class MyDatasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, source_imgs, teaching_imgs, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.source_imgs = source_imgs\n",
    "        self.teaching_imgs = teaching_imgs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.source_imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        source_img = self.source_imgs[index]\n",
    "        teaching_img = self.teaching_imgs[index]\n",
    "        if self.transforms:\n",
    "            source_img, teaching_img = self.transforms(source_img, teaching_img)\n",
    "        return source_img, teaching_img\n",
    "\n",
    "# フィルタ処理用にタイル化する\n",
    "dataset_fname = os.path.join(data_path, 'dataset.pickle')\n",
    "if os.path.exists(dataset_fname):\n",
    "#if False:\n",
    "    with open(dataset_fname, 'rb') as f:\n",
    "        source_imgs_train = pickle.load(f)\n",
    "        teaching_imgs_train = pickle.load(f)\n",
    "        source_imgs_test = pickle.load(f)\n",
    "        teaching_imgs_test = pickle.load(f)\n",
    "        weight = pickle.load(f)\n",
    "else:\n",
    "    # 面積の比率で重み作成\n",
    "    areas = np.zeros((11))\n",
    "    for img, label in dataset_train:\n",
    "        img = img.numpy()\n",
    "        areas[label] += np.mean(img)\n",
    "        areas[10] += np.mean(1.0-img)\n",
    "    areas /= len(dataset_train)\n",
    "    \n",
    "    weight = 1 / areas\n",
    "    weight /= np.max(weight)\n",
    "    \n",
    "    source_imgs_train, teaching_imgs_train = transform_data(dataset_train, 4096, rows, cols, 0) #29)\n",
    "    source_imgs_test, teaching_imgs_test = transform_data(dataset_test, 128, rows, cols, 0) #, 29)\n",
    "    \n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "    with open(dataset_fname, 'wb') as f:\n",
    "        pickle.dump(source_imgs_train, f)\n",
    "        pickle.dump(teaching_imgs_train, f)\n",
    "        pickle.dump(source_imgs_test, f)\n",
    "        pickle.dump(teaching_imgs_test, f)\n",
    "        pickle.dump(weight, f)\n",
    "\n",
    "my_dataset_train = MyDatasets(source_imgs_train, teaching_imgs_train)\n",
    "my_dataset_test = MyDatasets(source_imgs_test, teaching_imgs_test)\n",
    "\n",
    "loader_train = torch.utils.data.DataLoader(dataset=my_dataset_train, batch_size=mini_batch_size, shuffle=True)\n",
    "loader_test = torch.utils.data.DataLoader(dataset=my_dataset_test, batch_size=mini_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d22819-df3d-45c5-80b2-d69681c72f37",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 学習データ表示確認\n",
    "def plt_data(x, y):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.subplot(1,12,1)\n",
    "    plt.title('sorce')\n",
    "    plt.imshow(x[0], 'gray')\n",
    "    for i in range(11):\n",
    "        plt.subplot(1,12,2+i)\n",
    "        if i < 10:\n",
    "            plt.title('class=%d'%i)\n",
    "            plt.imshow(y[i], 'gray')\n",
    "        else:\n",
    "            plt.title('background')\n",
    "            plt.imshow(y[i], 'gray')\n",
    "    plt.tight_layout()\n",
    "    _ = plt.show()\n",
    "\n",
    "if False:\n",
    "    plt.figure(figsize=(16,8))\n",
    "    for source_imgs, teaching_imgs in loader_test:\n",
    "        print(source_imgs[0].shape)\n",
    "        print(teaching_imgs[0].shape)\n",
    "        for i in range(min(mini_batch_size, 4)):\n",
    "            plt_data(source_imgs[i], teaching_imgs[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f85be27-e8a1-4fb7-a9b5-abb626bbee83",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def view(net, loader, num=2):\n",
    "    \"\"\"表示確認\"\"\"\n",
    "    n = 0\n",
    "    for x_imgs, t_imgs in loader:\n",
    "        plt.figure(figsize=(16,8))\n",
    "        x_buf = bb.FrameBuffer.from_numpy(np.array(x_imgs).astype(np.float32))\n",
    "#       t0_buf = bb.FrameBuffer.from_numpy(np.array(t_imgs[:,0:10,:,:]).astype(np.float32))\n",
    "#       t1_buf = bb.FrameBuffer.from_numpy(np.array(1.0 - t_imgs[:,10:11,:,:]).astype(np.float32)) \n",
    "        y_buf = net.forward(x_buf, train=False)\n",
    "        result_imgs = y_buf.numpy()\n",
    "        plt_data(x_imgs[0], result_imgs[0])\n",
    "        n += 1\n",
    "        if n >= num: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a659e8e4-0c63-47ec-964b-7b8208a9c8b0",
   "metadata": {},
   "source": [
    "## BinaryBrain版ネット定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614c80e1-0296-4da1-b601-21e91108e93b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dense_conv(output_ch, filter_size=(3, 3), padding='same'):\n",
    "    \"\"\"バイナリ化したDenseConv層生成\"\"\"\n",
    "    return bb.Convolution2d(\n",
    "                bb.Sequential([\n",
    "                    bb.DenseAffine([output_ch, 1, 1]),\n",
    "#                   bb.BatchNormalization(),\n",
    "                ]),\n",
    "                filter_size=filter_size,\n",
    "                padding=padding)\n",
    "\n",
    "class ConvBlock_bb(bb.Sequential):\n",
    "    \"\"\"基本ブロック\"\"\"\n",
    "    def __init__(self, in_ch=32, out_ch=32, last=False, log_name=\"\"):\n",
    "        self.log_name = log_name\n",
    "        self.cnv0  = create_dense_conv(out_ch)\n",
    "        self.relu0 = bb.ReLU()\n",
    "        self.cnv1  = create_dense_conv(out_ch)\n",
    "        if last:\n",
    "            self.relu1 = None\n",
    "            super(ConvBlock_bb, self).__init__([self.cnv0, self.relu0, self.cnv1])\n",
    "        else:\n",
    "            self.relu1 = bb.ReLU()\n",
    "            super(ConvBlock_bb, self).__init__([self.cnv0, self.relu0, self.cnv1, self.relu1])\n",
    "    \n",
    "    def backward(self, dy):\n",
    "        if self.relu1 is not None:\n",
    "            dy = self.relu1.backward(dy)\n",
    "        dy = self.cnv1.backward(dy)\n",
    "        dy = self.relu0.backward(dy)\n",
    "        if verbose >= 1:\n",
    "            print('[bb %s] min:%f max:%f'%(self.log_name, np.min(dy.numpy()), np.max(dy.numpy())))\n",
    "        dy = self.cnv0.backward(dy)\n",
    "        return dy\n",
    "\n",
    "class ScaledNetwork_bb(bb.Sequential):\n",
    "    def __init__(self, ch=32, top=False):\n",
    "        self.top = top\n",
    "        self.ch  = ch\n",
    "        \n",
    "        self.up   = bb.UpSampling((2, 2))\n",
    "        self.pool = bb.MaxPooling((2, 2))\n",
    "        self.cat0 = bb.Concatenate()\n",
    "        self.cat1 = bb.Concatenate()\n",
    "        if self.top:\n",
    "            self.cnv0 = ConvBlock_bb(self.ch+1, self.ch, log_name=\"m_cnv0\")\n",
    "            self.cnv1 = ConvBlock_bb(self.ch,   11, last=self.top, log_name=\"m_cnv1\")\n",
    "        else:\n",
    "            self.cnv0 = ConvBlock_bb(self.ch*2, self.ch, log_name=\"s_cnv0\")\n",
    "            self.cnv1 = ConvBlock_bb(self.ch*2, self.ch, log_name=\"s_cnv1\")\n",
    "        \n",
    "        super(ScaledNetwork_bb, self).__init__([self.up, self.pool, self.cnv0, self.cnv1])\n",
    "        \n",
    "    def set_input_shape(self, x0_shape, x1_shape, u_shape):\n",
    "        x1_shape = self.up.set_input_shape(x1_shape)\n",
    "        x_shape = self.cat0.set_input_shape([x0_shape, x1_shape])\n",
    "        x_shape = self.cnv0.set_input_shape(x_shape)\n",
    "        v_shape = self.pool.set_input_shape(x_shape)\n",
    "        if not self.top:\n",
    "            x_shape = self.cat1.set_input_shape([u_shape, x_shape])\n",
    "        y_shape = self.cnv1.set_input_shape(x_shape)\n",
    "        return y_shape, v_shape\n",
    "    \n",
    "    def forward(self, x0, x1, u, train=True):\n",
    "        x1 = self.up.forward(x1, train=train)\n",
    "        x = self.cat0.forward([x0, x1])\n",
    "        x = self.cnv0.forward(x, train=train)        \n",
    "        v = self.pool.forward(x, train=train)\n",
    "        if not self.top:\n",
    "            x = self.cat1.forward([u, x])\n",
    "        y = self.cnv1.forward(x, train=train)\n",
    "        return y, v\n",
    "    \n",
    "    def backward(self, dy, dv):\n",
    "        dy = self.cnv1.backward(dy)\n",
    "        if not self.top:\n",
    "            du, dy0 = self.cat1.backward([dy])\n",
    "        else:\n",
    "            du, dy0 = None, dy\n",
    "        dy1 = self.pool.backward(dv)\n",
    "        dy = self.cnv0.backward(dy0 + dy1)\n",
    "        dx0, dx1 = self.cat0.backward([dy])\n",
    "        dx1 = self.up.backward(dx1)\n",
    "        return dx0, dx1, du\n",
    "\n",
    "\n",
    "class MipmapNetwork_bb(bb.Sequential):\n",
    "    def __init__(self, loop=3, depth=4, ch=32):\n",
    "        self.loop    = loop\n",
    "        self.depth   = depth\n",
    "        self.ch      = ch\n",
    "        self.shape   = None\n",
    "        self.up      = bb.UpSampling((2, 2))\n",
    "        self.m_net = ScaledNetwork_bb(ch, top=True)\n",
    "        self.s_net = ScaledNetwork_bb(ch)\n",
    "        super(MipmapNetwork_bb, self).__init__([self.m_net, self.s_net])\n",
    "    \n",
    "    def set_input_shape(self, shape):\n",
    "        self.shape = copy.copy(shape)\n",
    "        \n",
    "        x0_shape = copy.copy(shape)\n",
    "        x1_shape = copy.copy(shape)\n",
    "        x1_shape[0] = self.ch\n",
    "        x1_shape[1] //= 2\n",
    "        x1_shape[2] //= 2\n",
    "        u_shape = copy.copy(shape)\n",
    "        y_shape, v_shape = self.m_net.set_input_shape(x0_shape, x1_shape, u_shape)\n",
    "        \n",
    "        x0_shape = copy.copy(x1_shape)\n",
    "        x0_shape[0] = self.ch\n",
    "        x1_shape = copy.copy(x1_shape)\n",
    "        x1_shape[0] = self.ch\n",
    "        x1_shape[1] //= 2\n",
    "        x1_shape[2] //= 2\n",
    "        self.s_net.set_input_shape(x0_shape, x1_shape, v_shape)\n",
    "        \n",
    "        return y_shape\n",
    "    \n",
    "    def make_mipmap(self, frame_size, dtype=bb.DType.FP32):\n",
    "        h = self.shape[1]\n",
    "        w = self.shape[2]\n",
    "        mipmap = []\n",
    "        for i in range(self.depth+1):\n",
    "            h //= 2\n",
    "            w //= 2\n",
    "            buf = bb.FrameBuffer(frame_size, (self.ch, h, w), dtype=dtype)\n",
    "            buf.fill_zero()\n",
    "            mipmap.append(buf)\n",
    "        return mipmap\n",
    "    \n",
    "    def forward(self, x, train=True):\n",
    "        self.m_net.clear()\n",
    "        self.s_net.clear()\n",
    "        \n",
    "        frame_size = x.get_frame_size()\n",
    "        self.shape = x.get_node_shape()\n",
    "        \n",
    "        mipmap = self.make_mipmap(frame_size)        \n",
    "        for _ in range(self.loop):\n",
    "            y, v = self.m_net.forward(x, mipmap[0], None, train=train)\n",
    "            for i in range(self.depth):\n",
    "                mipmap[i], v = self.s_net.forward(mipmap[i], mipmap[i+1], v)\n",
    "        \n",
    "        self.v_shape = v.get_node_shape()\n",
    "        return y\n",
    "    \n",
    "    def backward(self, dy):\n",
    "        frame_size = dy.get_frame_size()\n",
    "        dv = bb.FrameBuffer(frame_size, self.v_shape, dtype=bb.DType.FP32)\n",
    "        dv.fill_zero()\n",
    "        \n",
    "        mipmap = self.make_mipmap(frame_size, dtype=bb.DType.FP32)\n",
    "#        du_shape = du.get_node_shape()\n",
    "        for _ in range(self.loop):\n",
    "            du = dv\n",
    "            for i in reversed(range(self.depth)):\n",
    "                dx0, dx1, du = self.s_net.backward(mipmap[i], du)\n",
    "                mipmap[i]    = dx0\n",
    "                mipmap[i+1] += dx1\n",
    "            dx0, dx1, du = self.m_net.backward(dy, du)\n",
    "            mipmap[0] = dx1\n",
    "            dy = bb.FrameBuffer(frame_size, dy.get_node_shape(), dtype=bb.DType.FP32)\n",
    "            dy.fill_zero()\n",
    "#            du = bb.FrameBuffer(frame_size, du_shape, dtype=bb.DType.FP32)\n",
    "#            du.fill_zero()\n",
    "        return dx0\n",
    "\n",
    "def check_param_affine_bb(affine_bb):\n",
    "    assert(not np.isnan(affine_bb.W().numpy()).any())\n",
    "    assert(not np.isnan(affine_bb.b().numpy()).any())\n",
    "    assert(not np.isnan(affine_bb.dW().numpy()).any())\n",
    "    assert(not np.isnan(affine_bb.db().numpy()).any())\n",
    "\n",
    "def check_param_bb(net_bb):\n",
    "    check_param_affine_bb(net_bb.m_net.cnv0[0][1][0])\n",
    "    check_param_affine_bb(net_bb.m_net.cnv0[2][1][0])\n",
    "    check_param_affine_bb(net_bb.m_net.cnv1[0][1][0])\n",
    "    check_param_affine_bb(net_bb.m_net.cnv1[2][1][0])\n",
    "    check_param_affine_bb(net_bb.s_net.cnv0[0][1][0])\n",
    "    check_param_affine_bb(net_bb.s_net.cnv0[2][1][0])\n",
    "    check_param_affine_bb(net_bb.s_net.cnv1[0][1][0])\n",
    "    check_param_affine_bb(net_bb.s_net.cnv1[2][1][0])\n",
    "    \n",
    "def clamp_param_affine_bb(affine_bb, a, b, rate=1.0):\n",
    "    affine_bb.W().clamp_inplace(a, b)\n",
    "    W = affine_bb.W()\n",
    "    W *= rate\n",
    "    affine_bb.b().clamp_inplace(a, b)\n",
    "    b = affine_bb.b()\n",
    "    b *= rate\n",
    "#   affine_bb.dW().clamp_inplace(a, b, rate)\n",
    "#   affine_bb.db().clamp_inplace(a, b, rate)\n",
    "\n",
    "def clamp_param_bb(net_bb, a, b, rate=1.0):\n",
    "    clamp_param_affine_bb(net_bb.m_net.cnv0[0][1][0], a, b, rate)\n",
    "    clamp_param_affine_bb(net_bb.m_net.cnv0[2][1][0], a, b, rate)\n",
    "    clamp_param_affine_bb(net_bb.m_net.cnv1[0][1][0], a, b, rate)\n",
    "    clamp_param_affine_bb(net_bb.m_net.cnv1[2][1][0], a, b, rate)\n",
    "    clamp_param_affine_bb(net_bb.s_net.cnv0[0][1][0], a, b, rate)\n",
    "    clamp_param_affine_bb(net_bb.s_net.cnv0[2][1][0], a, b, rate)\n",
    "    clamp_param_affine_bb(net_bb.s_net.cnv1[0][1][0], a, b, rate)\n",
    "    clamp_param_affine_bb(net_bb.s_net.cnv1[2][1][0], a, b, rate)\n",
    "    \n",
    "#net_bb = MipmapNetwork_bb(loop=loops, depth=depth)\n",
    "#net_bb.set_input_shape([1, img_h*rows, img_w*cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69138a84-96ee-44ed-9397-8a0e75d82a55",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_param_status(param, name=\"\"):\n",
    "    print('[%s] mean:%f std:%f min:%f max:%f nan:'%(name, np.nanmean(param), np.nanstd(param), np.nanmin(param), np.nanmax(param)), np.isnan(param).any())\n",
    "\n",
    "def print_param_affine_bb(affine_bb, name=\"\"):\n",
    "    print_param_status(affine_bb.W().numpy(), name+'.W')\n",
    "    print_param_status(affine_bb.b().numpy(), name+'.b')\n",
    "    print_param_status(affine_bb.dW().numpy(), name+'.dW')\n",
    "    print_param_status(affine_bb.db().numpy(), name+'.db')\n",
    "\n",
    "def print_param_bb(net_bb):\n",
    "    print_param_affine_bb(net_bb.m_net.cnv0[0][1][0], 'm_cnv00')\n",
    "    print_param_affine_bb(net_bb.m_net.cnv0[2][1][0], 'm_cnv01')\n",
    "    print_param_affine_bb(net_bb.m_net.cnv1[0][1][0], 'm_cnv10')\n",
    "    print_param_affine_bb(net_bb.m_net.cnv1[2][1][0], 'm_cnv11')\n",
    "    print_param_affine_bb(net_bb.s_net.cnv0[0][1][0], 's_cnv00')\n",
    "    print_param_affine_bb(net_bb.s_net.cnv0[2][1][0], 's_cnv01')\n",
    "    print_param_affine_bb(net_bb.s_net.cnv1[0][1][0], 's_cnv10')\n",
    "    print_param_affine_bb(net_bb.s_net.cnv1[2][1][0], 's_cnv11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b03217-3569-407a-98ce-e3393ba156e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loops = 3\n",
    "depth = 4\n",
    "net_bb = MipmapNetwork_bb(loop=loops, depth=depth)\n",
    "net_bb.set_input_shape([1, img_h*rows, img_w*cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d3c868-968e-4aa1-8ac2-b1b53dddbbe3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    epochs = 32\n",
    "    \n",
    "    criterion_bb = bb.LossSoftmaxCrossEntropy()\n",
    "    metrics_bb   = bb.MetricsCategoricalAccuracy()\n",
    "    optimizer_bb = bb.OptimizerAdam(learning_rate=0.001)\n",
    "#   optimizer_bb = bb.OptimizerSgd(learning_rate=0.0001)\n",
    "\n",
    "    optimizer_bb.set_variables(net_bb.get_parameters(), net_bb.get_gradients())\n",
    "    \n",
    "    num = 0\n",
    "    for epoch in range(epochs):\n",
    "        # learning\n",
    "        criterion_bb.clear()\n",
    "        metrics_bb.clear()\n",
    "        net_bb.clear()\n",
    "        with tqdm(loader_train) as tqdm_loadr:\n",
    "            for x_torch, t_torch in tqdm_loadr:\n",
    "\n",
    "                x_bb = bb.FrameBuffer.from_numpy(np.array(x_torch).astype(np.float32))\n",
    "                t_bb = bb.FrameBuffer.from_numpy(np.array(t_torch).astype(np.float32))\n",
    "\n",
    "                y_bb = net_bb.forward(x_bb, train=True)\n",
    "\n",
    "                dy_bb = criterion_bb.calculate(y_bb, t_bb)\n",
    "                metrics_bb.calculate(y_bb, t_bb)\n",
    "                \n",
    "#                if np.isnan(criterion_bb.get()):\n",
    "#                    print('nan')\n",
    "#                    assert(0)\n",
    "                \n",
    "                net_bb.backward(dy_bb)\n",
    "#                print_param_status(y_bb.numpy(), name=\"y_bb\")\n",
    "#                print_param_bb(net_bb)\n",
    "\n",
    "                optimizer_bb.update()\n",
    "#               clamp_param_bb(net_bb, -1.0, +1.0, rate=0.9999)\n",
    "                \n",
    "                num += 1\n",
    "#                if num % 100 == 99:\n",
    "#                    print_param_status(y_bb.numpy(), name=\"y_bb\")\n",
    "#                    print_param_bb(net_bb)\n",
    "    \n",
    "                tqdm_loadr.set_postfix(loss=criterion_bb.get(), acc=metrics_bb.get())\n",
    "        if False:\n",
    "            print_param_status(y_bb.numpy(), name=\"y_bb\")\n",
    "            print_param_bb(net_bb)\n",
    "            check_param_bb(net_bb)\n",
    "        view(net_bb, loader_test, num=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0adcf4-0b1c-4842-8ef3-24db31e8eb9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "view(net_bb, loader_test, num=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656adb2e-7d9d-4c2f-8045-2c697a8c2f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.save_networks(data_path, net_bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b72a4df-410c-462f-8a36-cc375886975f",
   "metadata": {},
   "source": [
    "## PyTorch版ネット定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b9427a-69c4-4f7a-bcbc-5d6228f6d3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Through(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        y = x.clone()\n",
    "        return y\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, dy):\n",
    "        dx = dy.clone()\n",
    "        if verbose >= 1:\n",
    "            print('[torch] min:%f max:%f'%(np.min(dx.to('cpu').detach().numpy()), np.max(dx.to('cpu').detach().numpy())))\n",
    "        return dx\n",
    "\n",
    "through = Through.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abfe9fe-15bb-4ed6-b0c8-22e1a46ad871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvBlock_torch(nn.Module):\n",
    "    \"\"\"基本ブロック\"\"\"\n",
    "    def __init__(self, in_ch=32, out_ch=32, last=False):\n",
    "        super(ConvBlock_torch, self).__init__()\n",
    "        self.last  = last\n",
    "#        self.through = Through()\n",
    "        self.cnv0  = nn.Conv2d(in_ch, out_ch, 3, padding=1, padding_mode='replicate')\n",
    "#        self.bn0   = nn.BatchNorm2d(out_ch)\n",
    "        self.relu0 = nn.ReLU(inplace=True)\n",
    "        self.cnv1  = nn.Conv2d(out_ch, out_ch, 3, padding=1, padding_mode='replicate')\n",
    "#        self.bn1   = nn.BatchNorm2d(out_ch)\n",
    "        if self.last:\n",
    "            self.relu1 = None\n",
    "        else:\n",
    "            self.relu1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cnv0(x)\n",
    "        x = through(x)\n",
    "#        x = self.bn0(x)\n",
    "        x = self.relu0(x)\n",
    "        x = self.cnv1(x)\n",
    "#        x = self.bn0(x)\n",
    "        if self.relu1 is not None:\n",
    "            x = self.relu1(x)\n",
    "        return x\n",
    "\n",
    "class ScaledNetwork_torch(nn.Module):\n",
    "    def __init__(self, ch=32, top=False):\n",
    "        super(ScaledNetwork_torch, self).__init__()\n",
    "        \n",
    "        self.top  = top\n",
    "        self.ch   = ch\n",
    "        self.up   = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        if self.top:\n",
    "            self.cnv0 = ConvBlock_torch(self.ch+1, self.ch)\n",
    "            self.cnv1 = ConvBlock_torch(self.ch,   11, last=self.top)\n",
    "        else:\n",
    "            self.cnv0 = ConvBlock_torch(self.ch*2, self.ch)\n",
    "            self.cnv1 = ConvBlock_torch(self.ch*2, self.ch)\n",
    "    \n",
    "    def forward(self, x0, x1, u, train=True):\n",
    "        x1 = self.up(x1)\n",
    "        x = torch.cat([x0, x1], 1)\n",
    "        x = self.cnv0.forward(x)        \n",
    "        v = self.pool(x)\n",
    "        if not self.top:\n",
    "            x = torch.cat([u, x], 1)\n",
    "        y = self.cnv1.forward(x)\n",
    "        return y, v\n",
    "\n",
    "class MipmapNetwork_torch(nn.Module):\n",
    "    def __init__(self, loop=3, depth=4, ch=32):\n",
    "        super(MipmapNetwork_torch, self).__init__()\n",
    "        self.loop    = loop\n",
    "        self.depth   = depth\n",
    "        self.shape   = None\n",
    "        self.ch      = ch\n",
    "        self.up      = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.m_net = ScaledNetwork_torch(ch, top=True)\n",
    "        self.s_net = ScaledNetwork_torch(ch)\n",
    "    \n",
    "    def make_mipmap(self, n, h, w):\n",
    "        mipmap = []\n",
    "        for i in range(self.depth+1):\n",
    "            h //= 2\n",
    "            w //= 2\n",
    "            buf = torch.zeros(n, self.ch, h, w).to(device)\n",
    "            mipmap.append(buf)\n",
    "        return mipmap\n",
    "    \n",
    "    def forward(self, x):\n",
    "        n = x.shape[0]\n",
    "        c = x.shape[1]\n",
    "        h = x.shape[2]\n",
    "        w = x.shape[3]\n",
    "        \n",
    "        mipmap = self.make_mipmap(n, h, w)        \n",
    "        for _ in range(self.loop):\n",
    "            y, v = self.m_net.forward(x, mipmap[0], None)\n",
    "            for i in range(self.depth):\n",
    "                mipmap[i], v = self.s_net.forward(mipmap[i], mipmap[i+1], v)\n",
    "        return y\n",
    "    \n",
    "#net_torch = MipmapNetwork_torch().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38ad163-89f3-4020-a8e4-e012068182f7",
   "metadata": {},
   "source": [
    "## 比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8c4b23-284f-4165-8eb4-77300f255447",
   "metadata": {},
   "outputs": [],
   "source": [
    "loops = 4\n",
    "depth = 3\n",
    "\n",
    "net_torch = MipmapNetwork_torch(loop=loops, depth=depth).to(device)\n",
    "\n",
    "net_bb = MipmapNetwork_bb(loop=loops, depth=depth)\n",
    "net_bb.set_input_shape([1, img_h*rows, img_w*cols])\n",
    "\n",
    "def compare_param(param_bb, param_torch, name=\"\"):\n",
    "    pb = param_bb.numpy()\n",
    "    pt = param_torch.to('cpu').detach().numpy().reshape(pb.shape)\n",
    "    df = pb - pt\n",
    "#    print('[%s] diff:%f min:%f max:%f'%(name, np.std(df), np.min(df), np.max(df)))\n",
    "#    print('[%s] std bb:%f torch:%f'%(name, np.std(pb), np.std(pt)))\n",
    "    print('[%s] min bb:%f torch:%f'%(name, np.min(pb), np.min(pt)))\n",
    "    print('[%s] max bb:%f torch:%f'%(name, np.max(pb), np.max(pt)))\n",
    "\n",
    "def compare_affine_param(affine_bb, affine_torch, name=\"\"):\n",
    "#    compare_param(affine_bb.W(), affine_torch.weight, name=name+'.W')\n",
    "#    compare_param(affine_bb.b(), affine_torch.bias, name=name+'.b')\n",
    "    compare_param(affine_bb.dW(), affine_torch.weight.grad, name=name+'.dW')\n",
    "    compare_param(affine_bb.db(), affine_torch.bias.grad, name=name+'.db')   \n",
    "\n",
    "def compare_net_param(net_bb, net_torch):\n",
    "    compare_affine_param(net_bb.m_net.cnv0[0][1][0], net_torch.m_net.cnv0.cnv0, 'm_cnv00')\n",
    "    compare_affine_param(net_bb.m_net.cnv0[2][1][0], net_torch.m_net.cnv0.cnv1, 'm_cnv01')\n",
    "    compare_affine_param(net_bb.m_net.cnv1[0][1][0], net_torch.m_net.cnv1.cnv0, 'm_cnv10')\n",
    "    compare_affine_param(net_bb.m_net.cnv1[2][1][0], net_torch.m_net.cnv1.cnv1, 'm_cnv11')\n",
    "    compare_affine_param(net_bb.s_net.cnv0[0][1][0], net_torch.s_net.cnv0.cnv0, 's_cnv00')\n",
    "    compare_affine_param(net_bb.s_net.cnv0[2][1][0], net_torch.s_net.cnv0.cnv1, 's_cnv01')\n",
    "    compare_affine_param(net_bb.s_net.cnv1[0][1][0], net_torch.s_net.cnv1.cnv0, 's_cnv10')\n",
    "    compare_affine_param(net_bb.s_net.cnv1[2][1][0], net_torch.s_net.cnv1.cnv1, 's_cnv11')\n",
    "    \n",
    "def copy_affine_param(model_bb, model_torch):\n",
    "    model_bb.W().set_numpy(model_torch.weight.to('cpu').detach().numpy().reshape(model_bb.W().get_shape()))\n",
    "    model_bb.b().set_numpy(model_torch.bias.to('cpu').detach().numpy().reshape(model_bb.b().get_shape()))\n",
    "\n",
    "copy_affine_param(net_bb.m_net.cnv0[0][1][0], net_torch.m_net.cnv0.cnv0)\n",
    "copy_affine_param(net_bb.m_net.cnv0[2][1][0], net_torch.m_net.cnv0.cnv1)\n",
    "copy_affine_param(net_bb.m_net.cnv1[0][1][0], net_torch.m_net.cnv1.cnv0)\n",
    "copy_affine_param(net_bb.m_net.cnv1[2][1][0], net_torch.m_net.cnv1.cnv1)\n",
    "\n",
    "copy_affine_param(net_bb.s_net.cnv0[0][1][0], net_torch.s_net.cnv0.cnv0)\n",
    "copy_affine_param(net_bb.s_net.cnv0[2][1][0], net_torch.s_net.cnv0.cnv1)\n",
    "copy_affine_param(net_bb.s_net.cnv1[0][1][0], net_torch.s_net.cnv1.cnv0)\n",
    "copy_affine_param(net_bb.s_net.cnv1[2][1][0], net_torch.s_net.cnv1.cnv1)\n",
    "\n",
    "weight_torch = torch.from_numpy(weight.astype(np.float32)).clone().to(device)\n",
    "criterion_torch = nn.CrossEntropyLoss(weight=weight_torch)  # 面積に応じて重み付けする\n",
    "optimizer_torch = optim.Adam(net_torch.parameters(), lr=0.0001)\n",
    "\n",
    "criterion_bb = bb.LossSoftmaxCrossEntropy()\n",
    "metrics_bb   = bb.MetricsCategoricalAccuracy()\n",
    "optimizer_bb = bb.OptimizerAdam(learning_rate=0.0001)\n",
    "optimizer_bb.set_variables(net_bb.get_parameters(), net_bb.get_gradients())\n",
    "\n",
    "criterion_bb.clear()\n",
    "metrics_bb.clear()\n",
    "net_bb.clear()\n",
    "\n",
    "num = 0\n",
    "epochs = 4\n",
    "for epoch in range(epochs):\n",
    "    with tqdm(loader_train) as tqdm_loadr:\n",
    "        for x_torch, t_torch in tqdm_loadr:\n",
    "            \n",
    "            x = x_torch.detach().numpy()\n",
    "            t = t_torch.detach().numpy()\n",
    "            x_torch = x_torch.to(device)\n",
    "            t_torch = t_torch.to(device)\n",
    "            x_bb = bb.FrameBuffer.from_numpy(x)\n",
    "            t_bb = bb.FrameBuffer.from_numpy(t)\n",
    "\n",
    "            optimizer_torch.zero_grad()\n",
    "            y_torch = net_torch(x_torch)\n",
    "            loss_torch = criterion_torch(y_torch, torch.argmax(t_torch, dim=1))\n",
    "            loss_torch.backward()\n",
    "\n",
    "            y_bb = net_bb.forward(x_bb, train=True)\n",
    "            dy_bb = criterion_bb.calculate(y_bb, t_bb)\n",
    "            metrics_bb.calculate(y_bb, t_bb)\n",
    "            net_bb.backward(dy_bb)\n",
    "        #   break\n",
    "        \n",
    "            if verbose >= 1:\n",
    "                print('--------------')\n",
    "                compare_net_param(net_bb, net_torch)\n",
    "            \n",
    "            optimizer_torch.step()\n",
    "            optimizer_bb.update()\n",
    "            \n",
    "            num += 1\n",
    "#            if num % 10 == 9:\n",
    "#                print(num)\n",
    "\n",
    "#            print(loss_torch.item())\n",
    "#            print(criterion_bb.get())\n",
    "\n",
    "#            if num > 99:\n",
    "#                break\n",
    "            \n",
    "            tqdm_loadr.set_postfix(loss_bb=criterion_bb.get(), loss_torch=loss_torch.item())\n",
    "            criterion_bb.clear()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f92884a-bc7e-47ed-ad51-5dc2975edc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num)\n",
    "print(loss_torch.item())\n",
    "print(criterion_bb.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0178d7-7524-41d1-ab84-d2ac69583c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea917b6-a161-40ad-965c-b13f54d07e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    " compare_net_param(net_bb, net_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6031f4e-0387-4f55-96c5-60bfed8e6037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417196d8-386a-4a55-9508-c78a126f72ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3b09f3-df27-415f-ae22-4597e426e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_param(y_bb, y_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbd8c38-5456-410e-8c8f-62f9a1e512a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = y_torch.to('cpu').detach().numpy() - y_bb.numpy().reshape(y_torch.shape)\n",
    "print(np.unravel_index(np.argmax(diff), diff.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cae80fc-89ef-4535-aee9-078efbd87952",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bb.numpy()[13,:,63,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb11c1e-fe5b-4657-89f2-0ccfe58c6cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_torch.to('cpu').detach().numpy()[13,:,63,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb8edb2-eb95-4a8e-bffc-ebcb90a2fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673959fc-5255-4a74-9846-4a95ba07dfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_torch.m_net.cnv0.cnv0.bias.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aa334e-1ade-44f9-93a5-35de329e878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_bb.m_net.cnv0[2][1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5504ee71-bd29-4556-93a8-d59024d91e85",
   "metadata": {},
   "source": [
    "## PyTorch 版学習テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6a7be3-7201-481b-8677-6a75ac8b0757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 面積に応じて重み付けする\n",
    "weight_torch = torch.from_numpy(weight.astype(np.float32)).clone().to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=weight_torch)\n",
    "\n",
    "# 学習実施\n",
    "epochs = 16\n",
    "optimizer = optim.Adam(net_torch.parameters(), lr=0.0001)\n",
    "for epoch in range(epochs):\n",
    "    with tqdm(loader_train) as tqdm_loadr:\n",
    "        for x, t in tqdm_loadr:\n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y = net_torch(x)\n",
    "            loss = criterion(y, torch.argmax(t, dim=1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tqdm_loadr.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b366426d-d746-4a95-baa7-5886782cf87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果表示\n",
    "with torch.no_grad():\n",
    "    for x, t in loader_test:\n",
    "        x = x.to(device)\n",
    "        y = net_torch(x)\n",
    "#       y = F.softmax(net(x_torch), dim=1)\n",
    "        break\n",
    "\n",
    "x = x.to('cpu').detach().numpy()\n",
    "y = y.to('cpu').detach().numpy()\n",
    "for i in range(8):\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    plt.subplot(1,12,1)\n",
    "    plt.imshow(x[i][0], 'gray')\n",
    "    for j in range(11):\n",
    "        plt.subplot(1,12,j+2)\n",
    "        plt.title('class=%d'%j)\n",
    "#       print(np.min(x[i][j]), np.max(x[i][j]))\n",
    "        plt.imshow(y[i][j], 'gray')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
