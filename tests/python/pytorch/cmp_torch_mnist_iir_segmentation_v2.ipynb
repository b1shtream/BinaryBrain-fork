{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bd4bcf1-1bdf-4173-bbf2-8ddb92c803b3",
   "metadata": {},
   "source": [
    "# IIR型MNISTセマンティックセグメンテーション\n",
    "\n",
    "PyTorch との比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ff49c-32b3-4d05-88fe-65f6fc5a154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Function\n",
    "\n",
    "import binarybrain as bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45079310-59c4-4bb5-8b40-a607f37dace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_bb = True\n",
    "use_torch = False\n",
    "\n",
    "bin_mode = True\n",
    "lut_mode = False\n",
    "bin_modulation = False\n",
    "frame_modulation_size = 1\n",
    "\n",
    "if not bin_modulation:\n",
    "    frame_modulation_size = 1\n",
    "\n",
    "verbose = 0\n",
    "\n",
    "epochs = 16\n",
    "mini_batch_size = 32\n",
    "\n",
    "# ネット構造\n",
    "loops = 5\n",
    "depth = 3\n",
    "#ch = 32\n",
    "\n",
    "# 並べるタイル数\n",
    "rows=2\n",
    "cols=2\n",
    "img_h = 32\n",
    "img_w = 32\n",
    "\n",
    "data_path = './data/cmp_torch_mnist_iir_segmentation_v2'\n",
    "#if bin_mode:\n",
    "#    data_path += '_bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c48d334-fb03-434b-b164-21389176a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.get_version_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95e14dd-c6a6-4746-ae8e-51779b49c5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_torch:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fece6b51-4175-40bb-ab8c-a2e6a18b34f1",
   "metadata": {},
   "source": [
    "## 学習データ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a0c62b-5fc3-47e2-9a40-c6beb585b085",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset\n",
    "transform = transforms.Compose([\n",
    "                transforms.Resize((img_w, img_h)),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "\n",
    "dataset_path = './data/'\n",
    "dataset_train = torchvision.datasets.MNIST(root=dataset_path, train=True, transform=transform, download=True)\n",
    "dataset_test  = torchvision.datasets.MNIST(root=dataset_path, train=False, transform=transform, download=True)\n",
    "\n",
    "def make_teacher_image(gen, rows, cols, margin=0):\n",
    "    source_img  = np.zeros((1, rows*img_h, cols*img_w), dtype=np.float32)\n",
    "    teaching_img = np.zeros((11, rows*img_h, cols*img_w), dtype=np.float32)\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            x = col*img_w\n",
    "            y = row*img_h\n",
    "            img, label = gen.__next__()\n",
    "            source_img[0,y:y+img_h,x:x+img_w] = img\n",
    "            teaching_img[label,y:y+img_h,x:x+img_w] = img\n",
    "            teaching_img[10,y:y+img_h,x:x+img_w] = (1.0-img)\n",
    "    teaching_img = (teaching_img > 0.5).astype(np.float32)\n",
    "    \n",
    "    # 面積で重みを載せる\n",
    "    for i in range(11):\n",
    "        teaching_img[i] *= weight[i]\n",
    "    \n",
    "    # ランダムに反転\n",
    "    if random.random() > 0.5:\n",
    "        source_img = 1.0 - source_img\n",
    "\n",
    "    if margin > 0:\n",
    "        return source_img, teaching_img[:,margin:-margin,margin:-margin]\n",
    "    return source_img, teaching_img        \n",
    "\n",
    "def transform_data(dataset, n, rows, cols, margin):\n",
    "    def data_gen():\n",
    "        l = len(dataset)\n",
    "        i = 0\n",
    "        while True:\n",
    "            yield dataset[i%l]\n",
    "            i += 1\n",
    "    \n",
    "    gen = data_gen()\n",
    "    source_imgs = []\n",
    "    teaching_imgs = []\n",
    "    for _ in range(n):\n",
    "        x, t = make_teacher_image(gen, rows, cols, margin)\n",
    "        source_imgs.append(x)\n",
    "        teaching_imgs.append(t)\n",
    "    return source_imgs, teaching_imgs\n",
    "\n",
    "class MyDatasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, source_imgs, teaching_imgs, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.source_imgs = source_imgs\n",
    "        self.teaching_imgs = teaching_imgs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.source_imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        source_img = self.source_imgs[index]\n",
    "        teaching_img = self.teaching_imgs[index]\n",
    "        if self.transforms:\n",
    "            source_img, teaching_img = self.transforms(source_img, teaching_img)\n",
    "        return source_img, teaching_img\n",
    "\n",
    "# フィルタ処理用にタイル化する\n",
    "dataset_fname = os.path.join(data_path, 'dataset.pickle')\n",
    "if os.path.exists(dataset_fname):\n",
    "#if False:\n",
    "    with open(dataset_fname, 'rb') as f:\n",
    "        source_imgs_train = pickle.load(f)\n",
    "        teaching_imgs_train = pickle.load(f)\n",
    "        source_imgs_test = pickle.load(f)\n",
    "        teaching_imgs_test = pickle.load(f)\n",
    "        weight = pickle.load(f)\n",
    "else:\n",
    "    # 面積の比率で重み作成\n",
    "    areas = np.zeros((11))\n",
    "    for img, label in dataset_train:\n",
    "        img = img.numpy()\n",
    "        areas[label] += np.mean(img)\n",
    "        areas[10] += np.mean(1.0-img)\n",
    "    areas /= len(dataset_train)\n",
    "    \n",
    "    weight = 1 / areas\n",
    "    weight /= np.sum(weight)\n",
    "    \n",
    "    source_imgs_train, teaching_imgs_train = transform_data(dataset_train, 4096, rows, cols, 0) #29)\n",
    "    source_imgs_test, teaching_imgs_test = transform_data(dataset_test, 128, rows, cols, 0) #, 29)\n",
    "    \n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "    with open(dataset_fname, 'wb') as f:\n",
    "        pickle.dump(source_imgs_train, f)\n",
    "        pickle.dump(teaching_imgs_train, f)\n",
    "        pickle.dump(source_imgs_test, f)\n",
    "        pickle.dump(teaching_imgs_test, f)\n",
    "        pickle.dump(weight, f)\n",
    "\n",
    "my_dataset_train = MyDatasets(source_imgs_train, teaching_imgs_train)\n",
    "my_dataset_test = MyDatasets(source_imgs_test, teaching_imgs_test)\n",
    "\n",
    "loader_train = torch.utils.data.DataLoader(dataset=my_dataset_train, batch_size=mini_batch_size, shuffle=True)\n",
    "loader_test = torch.utils.data.DataLoader(dataset=my_dataset_test, batch_size=mini_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5a5dc6-4718-42fa-ad6e-8da1a87d8ff1",
   "metadata": {},
   "source": [
    "## アシスト関数定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c9d49-d7e9-4ac9-a7e3-f0fd26d64658",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_data(x, y, n=2):\n",
    "    \"\"\"データ表示確認\"\"\"\n",
    "    n = min(x.shape[0], n)\n",
    "    plt.figure(figsize=(18,2*n))\n",
    "    for i in range(n):\n",
    "        plt.subplot(n,12,i*12+1)\n",
    "        plt.title('sorce')\n",
    "        plt.imshow(x[i][0], 'gray')\n",
    "        for j in range(11):\n",
    "            plt.subplot(n,12,i*12+2+j)\n",
    "            if j < 10:\n",
    "                plt.title('class=%d'%j)\n",
    "                plt.imshow(y[i][j], 'gray')\n",
    "            else:\n",
    "                plt.title('background')\n",
    "                plt.imshow(y[i][j], 'gray')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c98ba22-6fef-408e-8c45-e03a1894024b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 学習データ表示確認\n",
    "if False:\n",
    "    plt.figure(figsize=(16,8))\n",
    "    for x, t in loader_test:\n",
    "        break\n",
    "\n",
    "    plot_data(x, t, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf28925c-6a6c-4a06-b000-e215143b60ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_numpy(x):\n",
    "    if type(x) == np.ndarray:\n",
    "        return x\n",
    "    if type(x) == bb.FrameBuffer or type(x) == bb.Tensor:\n",
    "        return x.numpy()\n",
    "    if type(x) == torch.Tensor:\n",
    "        return x.to('cpu').detach().clone().numpy()\n",
    "    return x.to('cpu').detach().clone().numpy()\n",
    "\n",
    "def calc_corrcoef(a, b):\n",
    "    a = to_numpy(a).reshape(-1)\n",
    "    b = to_numpy(b).reshape(-1)\n",
    "    return np.corrcoef(a, b)[0][1]\n",
    "\n",
    "def print_summary(x, text=\"\"):\n",
    "    if x is None:\n",
    "        print(\"[%s] None\"%(text))\n",
    "        return\n",
    "    x = to_numpy(x)\n",
    "    print(\"[%s] mean:%1.8f std:%1.8f min:%1.8f max:%1.8f isnan:%d\"%(text, np.mean(x), np.std(x), np.min(x), np.max(x), np.isnan(x).any()))\n",
    "\n",
    "def print_diff(a, b, text=\"\"):\n",
    "    a = to_numpy(a)\n",
    "    b = to_numpy(b).reshape(a.shape)\n",
    "    print_summary(a - b, text=text)\n",
    "\n",
    "def print_diff_summary(a_bb, a_torch, text=\"\"):\n",
    "    a_bb    = to_numpy(a_bb)\n",
    "    a_torch = to_numpy(a_torch).reshape(a_bb.shape)\n",
    "    r = calc_corrcoef(a_bb, a_torch)\n",
    "    print('[corrcoef:%f]'%r)\n",
    "    print_summary(a_bb,           text=text+\" bb   \")\n",
    "    print_summary(a_torch,        text=text+\" torch\")\n",
    "    print_summary(a_bb - a_torch, text=text+\" diff\")\n",
    "\n",
    "def print_shape(x, text=\"\"):\n",
    "    if x is None:\n",
    "        print(\"[%s] None\"%text)\n",
    "    else:\n",
    "        print(\"[%s]\"%text, x.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27119e65-a3c8-4e69-9939-fd6c8dd6753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_object(obj, file):\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_object(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c887fd-b20c-49e8-8bca-a26db62daf70",
   "metadata": {},
   "source": [
    "## ネットワーク定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806ae230-6523-4e52-bbfc-b056451d3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# バイナリ時は BIT型を使えばメモリ削減可能\n",
    "bin_dtype = bb.DType.BIT if bin_mode else bb.DType.FP32\n",
    "# bin_dtype = bb.DType.FP32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723f81cf-110d-4ea6-a609-d477324f2fc4",
   "metadata": {},
   "source": [
    "### 汎用バッファ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c51a6d7-4998-4587-a839-9b5677dbd054",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer():\n",
    "    \"\"\"PyTorch/BinaryBrain共用バッファ\"\"\"\n",
    "    def __init__(self, shape=None, dtype=bb.DType.FP32):\n",
    "        self.torch = None\n",
    "        self.bb    = None\n",
    "        if shape is not None:\n",
    "            if use_torch:\n",
    "                self.torch = torch.zeros(shape).to(device)\n",
    "            if use_bb:\n",
    "                self.bb = bb.FrameBuffer(shape[0]*frame_modulation_size, shape[1:], dtype=dtype)\n",
    "    \n",
    "    def get_shape(self):\n",
    "        if use_torch and self.torch is not None:\n",
    "            return list(self.torch.shape)\n",
    "        if use_bb and self.bb is not None:\n",
    "            return [self.bb.get_frame_size()//frame_modulation_size] + self.bb.get_node_shape()\n",
    "        return None\n",
    "    \n",
    "    def numpy(self):\n",
    "        if use_torch and self.torch is not None:\n",
    "            return to_numpy(self.torch)\n",
    "        if use_bb and self.bb is not None:\n",
    "            return to_numpy(self.bb)\n",
    "        return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def zeros(shape, dtype=bb.DType.FP32):\n",
    "        x = Buffer()\n",
    "        if use_torch:\n",
    "            x.torch = torch.zeros(shape).to(device)\n",
    "        if use_bb:\n",
    "            x.bb = bb.FrameBuffer.zeros(shape[0]*frame_modulation_size, shape[1:], dtype=dtype)\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def zeros_like(x, dtype=bb.DType.FP32):\n",
    "        return Buffer.zeros(x.get_shape(), dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967cd6c4-c1fb-4d0c-8492-c733e051f0ed",
   "metadata": {},
   "source": [
    "### 基本ブロック定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a04fe2b-b29b-45b1-922f-b916d5594a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "class Binarize(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        ctx.save_for_backward(x)\n",
    "        y = x.new(x.size())\n",
    "        y[x >  0] = +1.0\n",
    "        y[x <= 0] = -1.0\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dy):\n",
    "        x, = ctx.saved_tensors\n",
    "        dx = dy.clone()\n",
    "        dx[x.ge(1)]=0\n",
    "        dx[x.le(-1)]=0\n",
    "        return dx\n",
    "binarize = Binarize.apply\n",
    "\n",
    "class Through(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        y = x.clone()\n",
    "        return y\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, dy):\n",
    "        dx = dy.clone()\n",
    "        return dx\n",
    "\n",
    "through = Through.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ea39a-cab0-4941-8f89-9d0d170539a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSampling(bb.Sequential):\n",
    "    def __init__(self, name=\"\"):\n",
    "        if use_torch:\n",
    "            self.up_torch = nn.Upsample(scale_factor=2, mode='nearest').to(device)\n",
    "        \n",
    "        if use_bb:\n",
    "            self.up_bb    = bb.UpSampling((2, 2), fw_dtype=bin_dtype)\n",
    "            super(UpSampling, self).__init__([self.up_bb], name=name)\n",
    "        else:\n",
    "            super(UpSampling, self).__init__([], name=name)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return list()\n",
    "        \n",
    "    def forward(self, x, train=True):\n",
    "        y = Buffer()\n",
    "        if use_torch:\n",
    "            y.torch = self.up_torch(x.torch)\n",
    "        if use_bb:\n",
    "            y.bb = self.up_bb.forward(x.bb, train=train)\n",
    "        return y\n",
    "\n",
    "class MaxPooling(bb.Sequential):\n",
    "    def __init__(self, name=\"\"):\n",
    "        if use_torch:\n",
    "            self.pool_torch = nn.MaxPool2d(2, 2).to(device)\n",
    "        if use_bb:\n",
    "            self.pool_bb    = bb.MaxPooling((2, 2), fw_dtype=bin_dtype)\n",
    "            super(MaxPooling, self).__init__([self.pool_bb], name=name)\n",
    "        else:\n",
    "            super(MaxPooling, self).__init__([], name=name)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return list()\n",
    "    \n",
    "    def forward(self, x, train=True):\n",
    "        y = Buffer()\n",
    "        if use_torch:\n",
    "            y.torch = self.pool_torch(x.torch)\n",
    "        if use_bb:\n",
    "            y.bb = self.pool_bb.forward(x.bb, train=train)\n",
    "        return y\n",
    "\n",
    "class Concatenate(bb.Sequential):\n",
    "    def __init__(self, name=\"\"):\n",
    "        self.cat_bb = bb.Concatenate()\n",
    "        super(Concatenate, self).__init__([self.cat_bb], name=name)\n",
    "\n",
    "    def parameters(self):\n",
    "        return list()\n",
    "\n",
    "    def set_input_shape(self, shape):\n",
    "        return self.cat_bb.set_input_shape(shape)\n",
    "    \n",
    "    def forward(self, x, train=True):\n",
    "        y = Buffer()\n",
    "        if use_torch:\n",
    "            y.torch = torch.cat([x[0].torch, x[1].torch], 1)\n",
    "        if use_bb:\n",
    "            y.bb    = self.cat_bb.forward([x[0].bb, x[1].bb], train=train)\n",
    "        return y\n",
    "    \n",
    "    def backward(self, dy):\n",
    "        dy = self.cat_bb.backward(dy)\n",
    "        return dy\n",
    "\n",
    "\n",
    "class ConvBlock(bb.Sequential):\n",
    "    \"\"\"基本ブロック\"\"\"\n",
    "    def __init__(self, in_ch=32, hid_ch=32, out_ch=32, name=\"\"):\n",
    "        self.cnv0  = Convolution(in_ch, hid_ch, name=name+\"_cnv0\")\n",
    "        self.cnv1  = Convolution(hid_ch, out_ch, name=name+\"_cnv1\")\n",
    "        super(ConvBlock, self).__init__([self.cnv0, self.cnv1], name=name)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.cnv0.parameters() + self.cnv1.parameters()\n",
    "    \n",
    "    def copy_param_torch_to_bb(self):\n",
    "        self.cnv0.copy_param_torch_to_bb()\n",
    "        self.cnv1.copy_param_torch_to_bb()\n",
    "        \n",
    "    def copy_param_bb_to_torch(self):\n",
    "        self.cnv0.copy_param_bb_to_torch()\n",
    "        self.cnv1.copy_param_bb_to_torch()\n",
    "\n",
    "    def set_input_shape(self, shape):\n",
    "        shape = self.cnv0.set_input_shape(shape)\n",
    "        shape = self.cnv1.set_input_shape(shape)\n",
    "        return shape\n",
    "    \n",
    "    def forward(self, x, train=True):\n",
    "        x = self.cnv0.forward(x, train=train)\n",
    "        x = self.cnv1.forward(x, train=train)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, dy):\n",
    "        dy = self.cnv1.backward(dy)\n",
    "        dy = self.cnv0.backward(dy)\n",
    "        return dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c71d261-6993-4a87-93c1-41a1d76b97a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distillation(bb.Sequential):\n",
    "    def __init__(self, model_list, name=\"\"):\n",
    "        super(Distillation, self).__init__(model_list, name=name)\n",
    "    \n",
    "    def send_command(self, command, send_to='all'):\n",
    "        super(BinaryConvolution, self).send_command(command, send_to)\n",
    "        if send_to != \"all\" and send_to != self.get_name():\n",
    "            return\n",
    "        \n",
    "        args = command.split()\n",
    "        if len(args) == 2 and args[0] == 'log':\n",
    "            if args[1] == 'start':\n",
    "                print(\"[%s] log start\"%self.get_name())\n",
    "                self.log_file_x = open(self.log_x_name, 'wb')\n",
    "                self.log_file_y = open(self.log_y_name, 'wb')\n",
    "            if args[1] == 'stop':\n",
    "                print(\"[%s] log stop\"%self.get_name())\n",
    "                if self.log_file_x is not None:\n",
    "                    self.log_file_x.close()\n",
    "                    self.log_file_x = None\n",
    "                if self.log_file_y is not None:\n",
    "                    self.log_file_y.close()\n",
    "                    self.log_file_y = None\n",
    "        \n",
    "        if len(args) == 2 and args[0] == 'distillation':\n",
    "            if args[1] == 'start':\n",
    "                print(\"[%s] distillation start\"%self.get_name())\n",
    "                self.distillation_bb = True\n",
    "                self.criterion_bb.clear()\n",
    "                self.optimizer_bb.set_variables(self.lut_bb.get_parameters(), self.lut_bb.get_gradients())\n",
    "            if args[1] == 'stop':\n",
    "                self.distillation_bb = False                \n",
    "                print(\"[%s] distillation stop loss=%f\"%(self.get_name(), self.criterion_bb.get()))\n",
    "            if args[1] == 'info':\n",
    "                print(\"[%s] distillation loss=%f\"%(self.get_name(), self.criterion_bb.get()))\n",
    "    \n",
    "    def forward(self, x, train=True):\n",
    "        if verbose > 2:\n",
    "            print(\"[%s] forward\"%self.name)\n",
    "            print_summary(x.torch,                    text='in torch')\n",
    "            print_summary(x.bb.astype(bb.DType.FP32), text='in bb   ')\n",
    "        \n",
    "        if self.log_file_x is not None:\n",
    "            pickle.dump(x.bb.astype(bb.DType.FP32).numpy(), self.log_file_x)\n",
    "        \n",
    "        if self.distillation:\n",
    "            # 蒸留\n",
    "            self.send_command(\"switch_model dense\")                \n",
    "            y = self._forward(x, train=train)\n",
    "            self.send_command(\"switch_model lut\")\n",
    "            y_lut = self._forward(x, train=True)\n",
    "            dy_lut = Buffer()\n",
    "            dy_lut.bb = self.criterion_bb.calculate(y_lut.bb.astype(bb.DType.FP32), y.bb.astype(bb.DType.FP32))\n",
    "            self.backward(dy_lut)\n",
    "            self.optimizer_bb.update()\n",
    "            self.send_command(\"switch_model dense\")                \n",
    "        else:\n",
    "            y = self._forward(x, train=Train)\n",
    "            \n",
    "        if self.log_file_y is not None:\n",
    "            pickle.dump(y.bb.astype(bb.DType.FP32).numpy(), self.log_file_y)\n",
    "        \n",
    "        if verbose > 2:\n",
    "            print_summary(y.torch,                    text='out torch')\n",
    "            print_summary(y.bb.astype(bb.DType.FP32), text='out bb   ')\n",
    "        return y\n",
    "    \n",
    "    def backward(self, dy):\n",
    "        if use_bb:\n",
    "            dy = self.cnv_bb.backward(dy)\n",
    "        return dy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1794bb-61f2-4e2b-8916-4a8bd420aec4",
   "metadata": {},
   "source": [
    "### BinaryConvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359eae0f-dd6c-43e5-8f57-a5be4eee37cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDenseAffineBb(bb.Sequential):\n",
    "    def __init__(self, out_ch, batch_norm=True, binarize=True, depthwise=False, name=\"\"):\n",
    "        self.batch_norm = batch_norm\n",
    "        self.binarize   = binarize\n",
    "        if depthwise:\n",
    "            self.affine = bb.DepthwiseDenseAffine([out_ch, 1, 1], name=name+'_affine', initializer=\"\")\n",
    "        else:\n",
    "            self.affine = bb.DenseAffine([out_ch, 1, 1], name=name+'_affine', initializer=\"\")\n",
    "        self.bn     = bb.BatchNormalization(name=name+'_bn')\n",
    "        self.act    = bb.Binarize(name=name+'_act', bin_dtype=bin_dtype)\n",
    "        layers = [self.affine]\n",
    "        if batch_norm: layers.append(self.bn)\n",
    "        if binarize:   layers.append(self.act)\n",
    "        super(BinaryDenseAffineBb, self).__init__(layers, name=name)\n",
    "    \n",
    "    def forward(self, x, train=True):\n",
    "        x = self.affine.forward(x, train=True)\n",
    "        if self.batch_norm:\n",
    "            x = self.bn.forward(x, train=True)\n",
    "        if self.binarize:\n",
    "            x = self.act.forward(x, train=True)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, dy):\n",
    "        if self.binarize:\n",
    "            dy = self.act.backward(dy)\n",
    "        if self.batch_norm:\n",
    "            dy = self.bn.backward(dy)\n",
    "        dy = self.affine.backward(dy)\n",
    "        if verbose > 2:\n",
    "            print_summary(dy)\n",
    "        return dy\n",
    "\n",
    "class BinaryDenseConvolutionBb(bb.Sequential):\n",
    "    def __init__(self, out_ch, kernel_size=3, depthwise=False, batch_norm=True, binarize=True, name=\"\"):\n",
    "        self.cnv = bb.Convolution2d(\n",
    "                        BinaryDenseAffineBb(out_ch, name=name+'_affine', depthwise=depthwise, batch_norm=batch_norm, binarize=binarize),\n",
    "                        filter_size=(kernel_size, kernel_size),\n",
    "                        padding='same',\n",
    "                        name=name+'_cnv',\n",
    "                        fw_dtype=bin_dtype)\n",
    "        \n",
    "        super(BinaryDenseConvolutionBb, self).__init__([self.cnv], name=name)\n",
    "\n",
    "class LutConvolutionBb(bb.Sequential):\n",
    "    def __init__(self, ch, kernel_size=3, depthwise=False, batch_norm=True, binarize=True, name=\"\"):\n",
    "        if depthwise:\n",
    "            self.luts = bb.Sequential([\n",
    "                            bb.DifferentiableLut([ch, 1, 1], connection='depthwise', name=name+'_lut', batch_norm=batch_norm, binarize=binarize, bin_dtype=bin_dtype),\n",
    "                        ])\n",
    "        else:\n",
    "            self.luts = bb.Sequential([\n",
    "                            bb.DifferentiableLut([ch*6*6, 1, 1], connection='random', name=name+'_lut2', momentum=0.9, batch_norm=batch_norm, binarize=binarize, bin_dtype=bin_dtype),\n",
    "                            bb.DifferentiableLut([ch*6,   1, 1], connection='serial', name=name+'_lut1', momentum=0.9, batch_norm=batch_norm, binarize=binarize, bin_dtype=bin_dtype),\n",
    "                            bb.DifferentiableLut([ch,     1, 1], connection='serial', name=name+'_lut0', momentum=0.9, batch_norm=batch_norm, binarize=binarize, bin_dtype=bin_dtype),\n",
    "                        ])\n",
    "        \n",
    "        self.cnv = bb.Convolution2d(\n",
    "                        self.luts,\n",
    "                        filter_size=(kernel_size, kernel_size),\n",
    "                        padding='same',\n",
    "                        name=name+'_cnv',\n",
    "                        fw_dtype=bin_dtype)\n",
    "        super(LutConvolutionBb, self).__init__([self.cnv], name=name)\n",
    "\n",
    "class BinaryConvolution(bb.Sequential):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size=3, depthwise=False, batch_norm=True, binarize=True, name=\"\"):\n",
    "        self.batch_norm = batch_norm\n",
    "        self.binarize   = binarize\n",
    "        \n",
    "        self.log_file_x = None\n",
    "        self.log_file_y = None\n",
    "        self.log_x_name = os.path.join(data_path, \"%s_x.pickle\"%name)\n",
    "        self.log_y_name = os.path.join(data_path, \"%s_y.pickle\"%name)\n",
    "        \n",
    "        self.distillation_bb = False\n",
    "        self.criterion_bb = bb.LossMeanSquaredError()\n",
    "        self.optimizer_bb = bb.OptimizerAdam(learning_rate=0.001)\n",
    "        \n",
    "        if use_torch:\n",
    "            if kernel_size == 1:\n",
    "                self.cnv_torch = nn.Conv2d(in_ch, out_ch, 1).to(device) # pointwise\n",
    "            else:\n",
    "                if depthwise:\n",
    "                    self.cnv_torch = nn.Conv2d(in_ch, out_ch, kernel_size, padding=1, groups=in_ch, padding_mode='reflect').to(device)\n",
    "                else:\n",
    "                    self.cnv_torch = nn.Conv2d(in_ch, out_ch, kernel_size, padding=1, padding_mode='reflect').to(device) # 'replicate'\n",
    "            self.bn_torch  = nn.BatchNorm2d(out_ch, eps=1e-07).to(device)\n",
    "        \n",
    "        if use_bb:\n",
    "            self.dense_bb = BinaryDenseConvolutionBb(out_ch, name=name+'_cnv', depthwise=depthwise, batch_norm=batch_norm, binarize=binarize)\n",
    "            self.lut_bb   = LutConvolutionBb(out_ch, name=name+'_lut', depthwise=depthwise, batch_norm=batch_norm, binarize=binarize)\n",
    "            self.cnv_bb   = bb.Switcher({'lut': self.lut_bb, 'dense': self.dense_bb}, init_model_name = 'dense')\n",
    "            super(BinaryConvolution, self).__init__([self.cnv_bb], name=name)\n",
    "        else:\n",
    "            super(BinaryConvolution, self).__init__([], name=name)\n",
    "    \n",
    "    def send_command(self, command, send_to='all'):\n",
    "        super(BinaryConvolution, self).send_command(command, send_to)\n",
    "        if send_to != \"all\" and send_to != self.get_name():\n",
    "            return\n",
    "        \n",
    "        args = command.split()\n",
    "        if len(args) == 2 and args[0] == 'log':\n",
    "            if args[1] == 'start':\n",
    "                print(\"[%s] log start\"%self.get_name())\n",
    "                self.log_file_x = open(self.log_x_name, 'wb')\n",
    "                self.log_file_y = open(self.log_y_name, 'wb')\n",
    "            if args[1] == 'stop':\n",
    "                print(\"[%s] log stop\"%self.get_name())\n",
    "                if self.log_file_x is not None:\n",
    "                    self.log_file_x.close()\n",
    "                    self.log_file_x = None\n",
    "                if self.log_file_y is not None:\n",
    "                    self.log_file_y.close()\n",
    "                    self.log_file_y = None\n",
    "        \n",
    "        if len(args) == 2 and args[0] == 'distillation':\n",
    "            if args[1] == 'start':\n",
    "                print(\"[%s] distillation start\"%self.get_name())\n",
    "                self.distillation_bb = True\n",
    "                self.criterion_bb.clear()\n",
    "                self.optimizer_bb.set_variables(self.lut_bb.get_parameters(), self.lut_bb.get_gradients())\n",
    "            if args[1] == 'stop':\n",
    "                self.distillation_bb = False                \n",
    "                print(\"[%s] distillation stop loss=%f\"%(self.get_name(), self.criterion_bb.get()))\n",
    "            if args[1] == 'info':\n",
    "                print(\"[%s] distillation loss=%f\"%(self.get_name(), self.criterion_bb.get()))\n",
    "                \n",
    "    def parameters(self):\n",
    "        if self.batch_norm:\n",
    "            return list(self.cnv_torch.parameters()) + list(self.bn_torch.parameters())\n",
    "        else:\n",
    "            return list(self.cnv_torch.parameters())\n",
    "    \n",
    "    def copy_param_torch_to_bb(self):\n",
    "        affine_bb    = self.cnv_bb['dense'].cnv[1].affine\n",
    "        bn_bb        = self.cnv_bb['dense'].cnv[1].bn\n",
    "        affine_torch = self.cnv_torch\n",
    "        bn_torch     = self.bn_torch\n",
    "        affine_bb.W().set_numpy(to_numpy(affine_torch.weight).reshape(affine_bb.W().get_shape()))\n",
    "        affine_bb.b().set_numpy(to_numpy(affine_torch.bias).reshape(affine_bb.b().get_shape()))\n",
    "        bn_bb.gamma().set_numpy(to_numpy(bn_torch.weight).reshape(bn_bb.gamma().get_shape()))\n",
    "        bn_bb.beta().set_numpy(to_numpy(bn_torch.bias).reshape(bn_bb.beta().get_shape()))\n",
    "        bn_bb.running_mean().set_numpy(to_numpy(bn_torch.running_mean).reshape(bn_bb.running_mean().get_shape()))\n",
    "        bn_bb.running_var().set_numpy(to_numpy(bn_torch.running_var).reshape(bn_bb.running_var().get_shape()))\n",
    "\n",
    "    def copy_param_bb_to_torch(self):\n",
    "        affine_bb    = self.cnv_bb['dense'].cnv[1].affine\n",
    "        bn_bb        = self.cnv_bb['dense'].cnv[1].bn\n",
    "        affine_torch = self.cnv_torch\n",
    "        bn_torch     = self.bn_torch\n",
    "        affine_torch.weight = nn.Parameter(torch.tensor(affine_bb.W().numpy().reshape(list(affine_torch.weight.shape))).to(device))\n",
    "        affine_torch.bias   = nn.Parameter(torch.tensor(affine_bb.b().numpy().reshape(list(affine_torch.bias.shape))).to(device))\n",
    "        bn_torch.weight = nn.Parameter(torch.tensor(bn_bb.gamma().numpy().reshape(list(bn_torch.weight.shape))).to(device))\n",
    "        bn_torch.bias = nn.Parameter(torch.tensor(bn_bb.beta().numpy().reshape(list(bn_torch.bias.shape))).to(device))\n",
    "        bn_torch.running_mean = torch.tensor(bn_bb.running_mean().numpy().reshape(list(bn_torch.running_mean.shape))).to(device)\n",
    "        bn_torch.running_var = torch.tensor(bn_bb.running_var().numpy().reshape(list(bn_torch.running_var.shape))).to(device)\n",
    "        \n",
    "    def set_input_shape(self, shape):\n",
    "        shape = self.cnv_bb.set_input_shape(shape)\n",
    "        return shape\n",
    "    \n",
    "    def forward(self, x, train=True):\n",
    "        if verbose > 2:\n",
    "            print(\"[%s] forward\"%self.name)\n",
    "            print_summary(x.torch,                    text='in torch')\n",
    "            print_summary(x.bb.astype(bb.DType.FP32), text='in bb   ')\n",
    "        \n",
    "        if self.log_file_x is not None:\n",
    "            pickle.dump(x.bb.astype(bb.DType.FP32).numpy(), self.log_file_x)\n",
    "            \n",
    "        y = Buffer()\n",
    "        if use_torch:\n",
    "            y.torch = self.cnv_torch(x.torch)\n",
    "            if self.batch_norm:\n",
    "                y.torch = self.bn_torch(y.torch)\n",
    "            if self.binarize:\n",
    "                y.torch = binarize(y.torch)\n",
    "            y.torch = through(y.torch)\n",
    "            \n",
    "        if use_bb:\n",
    "            if self.distillation_bb:\n",
    "                # 蒸留\n",
    "                self.send_command(\"switch_model dense\")                \n",
    "                y.bb = self.cnv_bb.forward(x.bb, train=train)\n",
    "                self.send_command(\"switch_model lut\")\n",
    "                y_lut  = self.cnv_bb.forward(x.bb, train=True)\n",
    "                dy_lut = self.criterion_bb.calculate(y_lut.astype(bb.DType.FP32), y.bb.astype(bb.DType.FP32))\n",
    "                self.cnv_bb.backward(dy_lut)\n",
    "                self.optimizer_bb.update()\n",
    "                self.send_command(\"switch_model dense\")                \n",
    "            else:\n",
    "                y.bb = self.cnv_bb.forward(x.bb, train=train)\n",
    "        \n",
    "        if self.log_file_y is not None:\n",
    "            pickle.dump(y.bb.astype(bb.DType.FP32).numpy(), self.log_file_y)\n",
    "        \n",
    "        if verbose > 2:\n",
    "            print_summary(y.torch,                    text='out torch')\n",
    "            print_summary(y.bb.astype(bb.DType.FP32), text='out bb   ')\n",
    "        return y\n",
    "    \n",
    "    def backward(self, dy):\n",
    "        if use_bb:\n",
    "            dy = self.cnv_bb.backward(dy)\n",
    "        return dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43c33b7-8aa0-4566-9c99-d8a12f750f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileBlock(bb.Sequential):\n",
    "    \"\"\"MobileNet風モデル\"\"\"\n",
    "    def __init__(self, in_ch=36, hid_ch=36, out_ch=36, top=False, name=\"\"):\n",
    "        self.cnv0 = BinaryConvolution(in_ch,  hid_ch, 1, name=name+\"_pw0\")\n",
    "        self.cnv1 = BinaryConvolution(hid_ch, hid_ch, 3, name=name+\"_dw\", depthwise=True, )\n",
    "        self.cnv2 = BinaryConvolution(hid_ch, out_ch, 1, name=name+\"_pw1\")\n",
    "        super(MobileBlock, self).__init__([self.cnv0, self.cnv1, self.cnv2], name=name)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.cnv0.parameters() + self.cnv1.parameters() + self.cnv2.parameters()\n",
    "    \n",
    "    def copy_param_torch_to_bb(self):\n",
    "        self.cnv0.copy_param_torch_to_bb()\n",
    "        self.cnv1.copy_param_torch_to_bb()\n",
    "        self.cnv2.copy_param_torch_to_bb()\n",
    "        \n",
    "    def copy_param_bb_to_torch(self):\n",
    "        self.cnv0.copy_param_bb_to_torch()\n",
    "        self.cnv1.copy_param_bb_to_torch()\n",
    "        self.cnv2.copy_param_bb_to_torch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec32212-5493-4323-95b5-3cff179be94f",
   "metadata": {},
   "source": [
    "### サブブロック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f9f819-a852-41fe-b86d-5541a24f253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainBlock(bb.Sequential):\n",
    "    \"\"\"最上位(1/1スケール)階層モデル\"\"\"\n",
    "    def __init__(self, top=False):\n",
    "        self.up   = UpSampling()\n",
    "        self.cat  = Concatenate()\n",
    "        self.cnv0 = BinaryConvolution(1,  18, 3, name=\"m_cnv0\")\n",
    "        self.cnv1 = BinaryConvolution(32, 18, 1, name=\"m_cnv1\")\n",
    "        self.blk0 = MobileBlock(36, 36, 32, name=\"m_blk0\")\n",
    "        self.blk1 = MobileBlock(32, 36, 11, name=\"m_blk1\")\n",
    "        self.pool = MaxPooling()\n",
    "        super(MainBlock, self).__init__([self.cnv0, self.cnv1, self.blk0, self.blk1])\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.cnv0.parameters() + self.cnv1.parameters() + self.blk0.parameters() + self.blk1.parameters()\n",
    "    \n",
    "    def copy_param_torch_to_bb(self):\n",
    "        self.cnv0.copy_param_torch_to_bb()\n",
    "        self.cnv1.copy_param_torch_to_bb()\n",
    "        self.blk0.copy_param_torch_to_bb()\n",
    "        self.blk1.copy_param_torch_to_bb()\n",
    "        \n",
    "    def copy_param_bb_to_torch(self):\n",
    "        self.cnv0.copy_param_bb_to_torch()\n",
    "        self.cnv1.copy_param_bb_to_torch()\n",
    "        self.blk0.copy_param_bb_to_torch()\n",
    "        self.blk1.copy_param_bb_to_torch()\n",
    "    \n",
    "    def set_input_shape(self, x0_shape, x1_shape):\n",
    "        x0_shape = self.cnv0.set_input_shape(x0_shape)\n",
    "        \n",
    "        x1_shape = self.up.set_input_shape(x1_shape)\n",
    "        x1_shape = self.cnv1.set_input_shape(x1_shape)\n",
    "        \n",
    "        x_shape = self.cat.set_input_shape([x0_shape, x1_shape])\n",
    "        print(x_shape)\n",
    "        x_shape = self.blk0.set_input_shape(x_shape)\n",
    "        y_shape = self.blk1.set_input_shape(x_shape)\n",
    "        v_shape = self.pool.set_input_shape(x_shape)\n",
    "        return y_shape, v_shape\n",
    "    \n",
    "    def forward(self, x0, x1, first, last, train=True):\n",
    "        x0 = self.cnv0.forward(x0, train=train)\n",
    "        \n",
    "        if first:\n",
    "            shape = x0.get_shape()\n",
    "            shape[1] = 18\n",
    "            x1 = Buffer.zeros(shape, dtype=bin_dtype)\n",
    "        else:\n",
    "            x1 = self.up.forward(x1, train=train)\n",
    "            x1 = self.cnv1.forward(x1, train=train)\n",
    "        \n",
    "        x = self.cat.forward([x0, x1], train=train)\n",
    "        x = self.blk0.forward(x, train=train)\n",
    "        y = self.blk1.forward(x, train=train)\n",
    "        if last:\n",
    "            v = None\n",
    "        else:\n",
    "            v = self.pool.forward(x, train=train)\n",
    "        return y, v\n",
    "    \n",
    "    def backward(self, dy, dv, first, last):\n",
    "        dy = self.blk1.backward(dy)\n",
    "        if last:\n",
    "            dx = self.blk0.backward(dy)\n",
    "        else:\n",
    "            dv = self.pool.backward(dv)\n",
    "            dx = self.blk0.backward(dy + dv)\n",
    "        dx0, dx1 = self.cat.backward([dx])\n",
    "        if first:\n",
    "            dx1 = None\n",
    "        else:\n",
    "            dx1 = self.cnv1.backward(dx1)\n",
    "            dx1 = self.up.backward(dx1)\n",
    "        \n",
    "        dx0 = self.cnv0.backward(dx0)        \n",
    "        return dx0, dx1\n",
    "\n",
    "\n",
    "class ScaleBlock(bb.Sequential):\n",
    "    \"\"\"下位層(1/4スケール以下)階層モデル\"\"\"\n",
    "    def __init__(self, top=False):\n",
    "        self.up   = UpSampling()\n",
    "        self.cat0 = Concatenate()\n",
    "        self.cat1 = Concatenate()\n",
    "        self.cnv0  = BinaryConvolution(32, 12, 1, name=\"s_cnv0\")\n",
    "        self.cnv1  = BinaryConvolution(32, 12, 1, name=\"s_cnv1\")\n",
    "        self.cnv2  = BinaryConvolution(32, 12, 1, name=\"s_cnv2\")\n",
    "        self.blk  = MobileBlock(36, 36, 32, name=\"s_blk\")\n",
    "        self.pool = MaxPooling()\n",
    "        super(ScaleBlock, self).__init__([self.cnv0, self.cnv1, self.cnv2, self.blk])\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.cnv0.parameters() + self.cnv1.parameters() + self.cnv2.parameters() + self.blk.parameters()\n",
    "\n",
    "    def copy_param_torch_to_bb(self):\n",
    "        self.cnv.copy_param_torch_to_bb()\n",
    "    \n",
    "    def copy_param_bb_to_torch(self):\n",
    "        self.cnv.copy_param_bb_to_torch()\n",
    "\n",
    "    def set_input_shape(self, x0_shape, x1_shape, u_shape):\n",
    "        x0_shape = self.cnv0.set_input_shape(x0_shape)\n",
    "        x1_shape = self.up.set_input_shape(x1_shape)\n",
    "        x1_shape = self.cnv1.set_input_shape(x1_shape)\n",
    "        u_shape = self.cnv2.set_input_shape(u_shape)\n",
    "        x_shape = self.cat0.set_input_shape([x0_shape, x1_shape])\n",
    "        x_shape = self.cat1.set_input_shape([x_shape, u_shape])\n",
    "        y_shape = self.blk.set_input_shape(x_shape)\n",
    "        v_shape = self.pool.set_input_shape(y_shape)\n",
    "        return y_shape, v_shape\n",
    "    \n",
    "    def forward(self, x0, x1, u, bottom, first, last, train=True):\n",
    "        if first:\n",
    "            u_shape = u.get_shape()\n",
    "            u_shape[1] = 12\n",
    "            x0 = Buffer.zeros(u_shape, dtype=bin_dtype)\n",
    "        else:\n",
    "            x0 = self.cnv0.forward(x0, train=train)\n",
    "            \n",
    "        if first or bottom:\n",
    "            u_shape = u.get_shape()\n",
    "            u_shape[1] = 12\n",
    "            x1 = Buffer.zeros(u_shape, dtype=bin_dtype)\n",
    "        else:\n",
    "            x1 = self.up.forward(x1, train=train)\n",
    "            x1 = self.cnv1.forward(x1, train=train)\n",
    "        u = self.cnv2.forward(u, train=train)\n",
    "        \n",
    "        x = self.cat0.forward([x0, x1], train=train)\n",
    "        x = self.cat1.forward([x, u], train=train)\n",
    "        y = self.blk.forward(x, train=train)\n",
    "        if last:\n",
    "            v = None\n",
    "        else:\n",
    "            v = self.pool.forward(y, train=train)\n",
    "        return y, v\n",
    "       \n",
    "    def backward(self, dy, dv, bottom, first, last):\n",
    "        if last:\n",
    "            dx = self.blk.backward(dy)\n",
    "        else:\n",
    "            dv = self.pool.backward(dv)\n",
    "            dx = self.blk.backward(dy + dv)\n",
    "        dx, du = self.cat1.backward([dx])\n",
    "        dx0, dx1 = self.cat0.backward([dx])\n",
    "        if first:\n",
    "            dx0 = None\n",
    "        else:\n",
    "            dx0 = self.cnv0.backward(dx0)\n",
    "        \n",
    "        if first or bottom:\n",
    "            dx1 = None\n",
    "        else:\n",
    "            dx1 = self.cnv1.backward(dx1)\n",
    "            dx1 = self.up.backward(dx1)\n",
    "        du = self.cnv2.backward(du)\n",
    "        return dx0, dx1, du"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184d7bb5-2ef3-44e1-803a-f1618c17f6fa",
   "metadata": {},
   "source": [
    "### Mipmap型ネット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6621c5d-d2b4-4a57-8de5-6ad9990b77fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MipmapNetwork(bb.Sequential):\n",
    "    \"\"\"ミップマップ型ネット\"\"\"\n",
    "    def __init__(self, loops=2, depth=4):\n",
    "        self.loops = loops\n",
    "        self.depth = min(depth, loops-2)\n",
    "        self.r2b   = bb.RealToBinary(frame_modulation_size=frame_modulation_size, bin_dtype=bin_dtype)\n",
    "        self.b2r   = bb.BinaryToReal(frame_integration_size=frame_modulation_size, bin_dtype=bin_dtype)\n",
    "        self.up    = UpSampling()\n",
    "        self.m_blk = MainBlock()\n",
    "        self.s_blk = ScaleBlock()\n",
    "        super(MipmapNetwork, self).__init__([self.m_blk, self.s_blk])\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.m_blk.parameters() + self.s_blk.parameters()\n",
    "    \n",
    "    def copy_param_torch_to_bb(self):\n",
    "        self.m_blk.copy_param_torch_to_bb()\n",
    "        self.s_blk.copy_param_torch_to_bb()\n",
    "    \n",
    "    def copy_param_bb_to_torch(self):\n",
    "        self.m_blk.copy_param_bb_to_torch()\n",
    "        self.s_blk.copy_param_bb_to_torch()\n",
    "\n",
    "    def set_input_shape(self, shape):\n",
    "        self.shape = copy.copy(shape)\n",
    "        shape = self.r2b.set_input_shape(shape)\n",
    "        \n",
    "        x0_shape = copy.copy(shape)\n",
    "        x1_shape = copy.copy(shape)\n",
    "        x1_shape[0] = 32\n",
    "        x1_shape[1] //= 2\n",
    "        x1_shape[2] //= 2\n",
    "        y_shape, v_shape = self.m_blk.set_input_shape(x0_shape, x1_shape)\n",
    "        \n",
    "        x0_shape = copy.copy(v_shape)\n",
    "        x0_shape[0] = 32\n",
    "        x1_shape = copy.copy(v_shape)\n",
    "        x1_shape[0] = 32\n",
    "        x1_shape[1] //= 2\n",
    "        x1_shape[2] //= 2\n",
    "        self.s_blk.set_input_shape(x0_shape, x1_shape, v_shape)\n",
    "        \n",
    "        y_shape = self.b2r.set_input_shape(y_shape)\n",
    "        return y_shape\n",
    "    \n",
    "    def forward(self, x, train=True):\n",
    "        if use_bb:\n",
    "            if bin_modulation:\n",
    "                x.bb = self.r2b.forward(x.bb, train=train)\n",
    "            else:\n",
    "                x.bb = x.bb.astype(bin_dtype)\n",
    "        \n",
    "        mipmap = [None]*(self.depth+1)        \n",
    "        y_list = []\n",
    "        for i in range(self.loops):\n",
    "            depth = min(self.depth, self.loops-1 - i)\n",
    "            y, v = self.m_blk.forward(x, mipmap[0], first=(i<=1), last=(i==self.loops-1), train=train)\n",
    "            if i >= 1:\n",
    "                for j in range(depth):\n",
    "                    bottom = (j==self.depth-1)\n",
    "                    first  = (i==1)\n",
    "                    last   = (j==(depth-1))\n",
    "                    mipmap[j], v = self.s_blk.forward(mipmap[j], mipmap[j+1], v, bottom, first, last, train=train)\n",
    "            if use_bb:\n",
    "                if bin_modulation:\n",
    "                    y.bb = self.b2r.forward(y.bb, train=train)\n",
    "                else:\n",
    "                    y.bb = y.bb.astype(bb.DType.FP32)\n",
    "            y_list.append(y)\n",
    "        return y_list\n",
    "    \n",
    "    def backward(self, dy_list):\n",
    "        du = None\n",
    "        mipmap = [None]*(self.depth+1)        \n",
    "        for i in reversed(range(self.loops)):\n",
    "            depth = min(self.depth, self.loops-1 - i)\n",
    "            if i >= 1:\n",
    "                for j in reversed(range(depth)):\n",
    "                    bottom = (j==self.depth-1)\n",
    "                    first  = (i==1)\n",
    "                    last   = (j==(depth-1))\n",
    "                    dx0, dx1, du = self.s_blk.backward(mipmap[j], du, bottom, first, last)\n",
    "                    if last:\n",
    "                        mipmap[j] = dx0\n",
    "                        if not bottom:\n",
    "                            mipmap[j+1] = dx1\n",
    "                    elif not first:\n",
    "                        mipmap[j] += dx0\n",
    "                        mipmap[j+1] += dx1\n",
    "            dy = dy_list[i]\n",
    "            if use_bb and bin_modulation:\n",
    "                dy = self.b2r.backward(dy_list[i])\n",
    "            dx0, dx1 = self.m_blk.backward(dy, du, first=(i<=1), last=(i==self.loops-1))\n",
    "            mipmap[0] = dx1\n",
    "        return dx0\n",
    "        \n",
    "def view(net, loader, n=2):\n",
    "    \"\"\"表示確認\"\"\"\n",
    "    for x_torch, t_torch in loader:\n",
    "        break\n",
    "    \n",
    "    if not bin_modulation:\n",
    "        x_torch[x_torch >  0.5] = +1\n",
    "        x_torch[x_torch <= 0.5] = -1\n",
    "    \n",
    "    x_np = np.array(x_torch).astype(np.float32)\n",
    "    x = Buffer()\n",
    "    if use_bb:\n",
    "        x.bb = bb.FrameBuffer.from_numpy(x_np)\n",
    "    if use_torch:\n",
    "        x.torch = x_torch.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_list = net.forward(x, train=False)\n",
    "    \n",
    "    if use_torch:\n",
    "        print('PyTorch')\n",
    "        y_torch = to_numpy(y_list[-1].torch)\n",
    "        plot_data(x_np, y_torch, n)\n",
    "    if use_bb:\n",
    "        print('BinaryBrain')\n",
    "        y_bb = to_numpy(y_list[-1].bb)\n",
    "        plot_data(x_np, y_bb, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96629d1-f327-41a5-855f-e2d8f6aa696a",
   "metadata": {},
   "source": [
    "## 学習\n",
    "\n",
    "### ネット生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad757816-600b-4dec-a347-89424495af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ネット生成\n",
    "net = MipmapNetwork(loops=loops, depth=depth)\n",
    "if use_bb:\n",
    "    net.set_input_shape([1, img_h*rows, img_w*cols])\n",
    "    net.send_command(\"binary true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47af0b8-7bf4-45a6-be32-a7e30066268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期パラメータのヒストグラム比較\n",
    "if False:\n",
    "    W_bb    = to_numpy(net.m_blk.cnv0.cnv0.blk_bb.affine.W()).reshape(-1)\n",
    "    W_torch = to_numpy(net.m_blk.cnv0.cnv0.cnv_torch.weight).reshape(-1)\n",
    "    \n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(121)\n",
    "    plt.title('BinaryBrain')\n",
    "    plt.hist(W_bb, bins=30)\n",
    "    plt.subplot(122)\n",
    "    plt.title('PyTorch')\n",
    "    plt.hist(W_torch, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32d3217-e0b6-46a3-a13a-497dbbe6eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_bb:\n",
    "    bb.load_networks(data_path, net)\n",
    "#   bb.load_networks(data_path, net, name='dense_002_layers', read_layers=True)\n",
    "    pass\n",
    "\n",
    "net.send_command(\"switch_model dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e26a02f-50ad-4f5b-858a-b7565415846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期パラメータを揃える場合\n",
    "if False:\n",
    "    net.copy_param_torch_to_bb()\n",
    "#if True and use_torch and use_bb:\n",
    "#    net.copy_param_bb_to_torch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012ad418-b07b-4d6a-9d20-4254b6c55eb8",
   "metadata": {},
   "source": [
    "### 学習実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448616f9-feaa-45f2-a570-06f14bf9e79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning(data_path, net, epochs, learning_rate=0.001):\n",
    "    if use_torch:\n",
    "        weight_torch    = torch.from_numpy(weight.astype(np.float32)).clone().to(device)\n",
    "        criterion_torch = nn.CrossEntropyLoss(weight=weight_torch)  # 面積に応じて重み付けする\n",
    "        optimizer_torch = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "    if use_bb:\n",
    "        criterion_bb = bb.LossSoftmaxCrossEntropy()\n",
    "        metrics_bb   = bb.MetricsCategoricalAccuracy()\n",
    "        optimizer_bb = bb.OptimizerAdam(learning_rate=learning_rate)\n",
    "        optimizer_bb.set_variables(net.get_parameters(), net.get_gradients())\n",
    "\n",
    "        criterion_bb.clear()\n",
    "        metrics_bb.clear()\n",
    "        net.clear()\n",
    "\n",
    "    log_loss_bb    = []\n",
    "    log_loss_torch = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # learning\n",
    "        if use_bb:\n",
    "            criterion_bb.clear()\n",
    "            metrics_bb.clear()\n",
    "            net.clear()\n",
    "\n",
    "        with tqdm(loader_train) as tqdm_loadr:\n",
    "            for x_torch, t_torch in tqdm_loadr:\n",
    "                if use_torch:\n",
    "                    optimizer_torch.zero_grad()\n",
    "                net.clear()\n",
    "\n",
    "                if not bin_modulation:\n",
    "                    x_torch[x_torch >  0.5] = +1\n",
    "                    x_torch[x_torch <= 0.5] = -1\n",
    "\n",
    "                x = Buffer()\n",
    "                t = Buffer()\n",
    "                if use_bb:\n",
    "                    x.bb = bb.FrameBuffer.from_numpy(np.array(x_torch).astype(np.float32))\n",
    "                    t.bb = bb.FrameBuffer.from_numpy(np.array(t_torch).astype(np.float32))\n",
    "\n",
    "                if use_torch:\n",
    "                    x.torch = x_torch.to(device)\n",
    "                    t.torch = t_torch.to(device)\n",
    "\n",
    "                y_list = net.forward(x, train=True)\n",
    "\n",
    "                if use_torch:\n",
    "                    y_torch_list = []\n",
    "                    for y in y_list:\n",
    "                        y_torch_list.append(y.torch)\n",
    "                    yy_torch = torch.cat(y_torch_list, 0)\n",
    "                    tt_torch = torch.cat([t.torch]*loops, 0)\n",
    "                    loss_torch = criterion_torch(yy_torch, torch.argmax(tt_torch, dim=1))\n",
    "                    loss_torch.backward()\n",
    "\n",
    "                if use_bb:\n",
    "                    dy_list = []\n",
    "                    for y in y_list:\n",
    "                        dy = criterion_bb.calculate(y.bb, t.bb)\n",
    "                        dy /= len(y_list)\n",
    "                        dy_list.append(dy)\n",
    "                    net.backward(dy_list)\n",
    "\n",
    "                if use_torch:\n",
    "                    optimizer_torch.step()\n",
    "                if use_bb:\n",
    "                    optimizer_bb.update()\n",
    "\n",
    "                loss_val_torch = 0\n",
    "                loss_val_bb    = 0\n",
    "\n",
    "                if use_torch:\n",
    "                    loss_val_torch = loss_torch.item()\n",
    "                if use_bb:\n",
    "                    loss_val_bb    = criterion_bb.get()\n",
    "#                   criterion_bb.clear()\n",
    "\n",
    "                log_loss_torch.append(loss_val_torch)\n",
    "                log_loss_bb.append(loss_val_bb)\n",
    "\n",
    "                tqdm_loadr.set_postfix(loss_bb=loss_val_bb, loss_torch=loss_val_torch)\n",
    "        \n",
    "        if use_bb:\n",
    "            bb.save_networks(data_path, net, backups=3)\n",
    "        \n",
    "        if epoch % 10 == 9:\n",
    "            view(net, loader_test, n=2)\n",
    "    \n",
    "    if use_torch:\n",
    "        plt.plot(log_loss_torch, label='PyTorch')\n",
    "    if use_bb:\n",
    "        plt.plot(log_loss_bb, label='BinaryBrain')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "def inference(net, loader, n=0):\n",
    "    loops = 0\n",
    "    with torch.no_grad():\n",
    "        for x_torch, _ in tqdm(loader):\n",
    "            net.clear()\n",
    "            if not bin_modulation:\n",
    "                x_torch[x_torch >  0.5] = +1\n",
    "                x_torch[x_torch <= 0.5] = -1\n",
    "\n",
    "            x = Buffer()\n",
    "            if use_bb:\n",
    "                x.bb = bb.FrameBuffer.from_numpy(np.array(x_torch).astype(np.float32))\n",
    "            if use_torch:\n",
    "                x.torch = x_torch.to(device)\n",
    "\n",
    "            net.forward(x, train=False)\n",
    "            \n",
    "            loops += 1\n",
    "            if n > 0 and loops >= n:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9e17e2-c683-4231-a420-967d4397ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    net.send_command(\"switch_model dense\")\n",
    "    learning(data_path, net, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e95b6f5-f8fe-47d3-a442-e4347a3d1cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "#   bb.load_networks(data_path+'_distillation2', net)\n",
    "    net.send_command(\"switch_model lut\")\n",
    "    learning(data_path, net, epochs=8, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de329e7-46b8-407c-be26-01f585125786",
   "metadata": {},
   "outputs": [],
   "source": [
    "view(net, loader_test, n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf6b4c5-e586-44b6-99a3-39bc5a542ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351d7000-ce33-4e51-a368-68cda1a2dde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e31c4d4-cb34-488f-bf09-a378cd665595",
   "metadata": {},
   "outputs": [],
   "source": [
    "luts_list = [\n",
    "    net.s_blk.blk,\n",
    "    net.s_blk.cnv0,\n",
    "    net.s_blk.cnv1,\n",
    "    net.s_blk.cnv2,\n",
    "    net.m_blk.blk0,\n",
    "    net.m_blk.cnv0,\n",
    "    net.m_blk.cnv1,\n",
    "    net.m_blk.blk1,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263fc452-9d6d-4148-98b1-f10872d17989",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.send_command(\"switch_model dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b499881-1b7c-4f86-b9ad-21f7aa38ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(luts_list)):\n",
    "    print(i)\n",
    "    net.send_command(\"parameter_lock true\")\n",
    "    luts_list[i].send_command(\"switch_model lut\")\n",
    "    luts_list[i].send_command(\"parameter_lock false\")\n",
    "    learning(os.path.join(data_path, 'dist_s'), net, epochs=8, learning_rate=0.01)\n",
    "    learning(os.path.join(data_path, 'dist_s'), net, epochs=4, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eed99c-a04b-4c09-9230-924283b865fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning(os.path.join(data_path, 'dist_s'), net, epochs=4, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793ec03b-2b5a-41b6-ae74-e0c2678d6e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded7964f-29cd-4ccf-ace9-7de192d0fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.send_command(\"switch_model lut\")\n",
    "net.send_command(\"parameter_lock true\")\n",
    "net.m_blk.send_command(\"parameter_lock false\")\n",
    "learning(os.path.join(data_path, 'dist_m'), net, epochs=8, learning_rate=0.01)\n",
    "learning(os.path.join(data_path, 'dist_m'), net, epochs=4, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e982ba43-4e62-441c-9e5c-10859acb7068",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.send_command(\"switch_model lut\")\n",
    "net.send_command(\"parameter_lock true\")\n",
    "net.s_blk.send_command(\"parameter_lock false\")\n",
    "learning(os.path.join(data_path, 'dist_s'), net, epochs=8, learning_rate=0.01)\n",
    "learning(os.path.join(data_path, 'dist_s'), net, epochs=4, learning_rate=0.001)\n",
    "view(net, loader_test, n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5972e881-3976-4e79-a2e4-7b523cebb0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(8):\n",
    "    net.send_command(\"switch_model lut\")\n",
    "    net.send_command(\"parameter_lock true\")\n",
    "    net.m_blk.send_command(\"parameter_lock false\")\n",
    "    learning(os.path.join(data_path, 'dist_m'), net, epochs=2, learning_rate=0.001)\n",
    "    \n",
    "    net.send_command(\"switch_model lut\")\n",
    "    net.send_command(\"parameter_lock true\")\n",
    "    net.s_blk.send_command(\"parameter_lock false\")\n",
    "    learning(os.path.join(data_path, 'dist_s'), net, epochs=2, learning_rate=0.001)\n",
    "    view(net, loader_test, n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6bfc7f-bfff-439d-b3c5-97a4d888e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.send_command(\"switch_model lut\")\n",
    "net.send_command(\"parameter_lock false\")\n",
    "learning(os.path.join(data_path, 'lut'), net, epochs=20, learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7837c55d-6aff-44b8-b0ce-a7b5a9b05b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "view(net, loader_test, n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd121e71-a788-42db-9db1-0db07535ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.load_networks(os.path.join(data_path, 'dist_s'), net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e56e6a-7000-4512-90d5-af3b4da4265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.send_command(\"parameter_lock true\")\n",
    "net.s_blk.cnv0.send_command(\"switch_model lut\")\n",
    "net.s_blk.cnv1.send_command(\"switch_model lut\")\n",
    "net.s_blk.cnv2.send_command(\"switch_model lut\")\n",
    "net.s_blk.cnv0.send_command(\"parameter_lock true\")\n",
    "net.s_blk.cnv1.send_command(\"parameter_lock true\")\n",
    "net.s_blk.cnv2.send_command(\"parameter_lock false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ca3a61-491f-4169-9ac4-7f1a0ff754b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.save_networks(os.path.join(data_path, 'dist_indp'), net, backups=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db971b35-97ef-4819-8958-6fa8c3afa0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed3a01-b5ac-496e-86e8-9822b8ac5175",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.send_command('distillation start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479f888a-9ac2-493d-b4b3-c8eb33ebf6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bb.load_networks(data_path+'_distillation2', net)\n",
    "for _ in range(4):\n",
    "    inference(net, loader_train)\n",
    "    net.send_command('distillation info')\n",
    "    bb.save_networks(data_path+'_distillation2', net, backups=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9476647-90e5-4dc3-b49a-9478445c71f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c276d899-f6e6-4e56-b692-40ee6018603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.send_command('distillation info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd266c04-fe0b-4a88-a4d8-81fa1213c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.send_command('distillation stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bfcca6-f28d-48f9-ae5c-adf8fa075946",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.send_command(\"switch_model lut\")\n",
    "view(net, loader_test, n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b7e761-b1d6-40d9-a162-c0e1411f1f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0710488-a184-412a-b7fe-4279639ce907",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.save_networks(data_path, net, name='dense_001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bf77dd-c307-4431-b8d6-dfaaeb5e10dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.save_networks(data_path, net, name='dense_002_layers', write_layers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbdba3c-9487-4493-a79d-148779e35679",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    net.send_command('log start')\n",
    "#   learning(net, 1)\n",
    "    inference(net, loader_train)\n",
    "    net.send_command('log stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d610ee-794f-4999-a97e-24ed3befb261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_x(net, loader):\n",
    "    for x_torch, t_torch in loader:\n",
    "        x_np = np.array(x_torch).astype(np.float32)\n",
    "        x = Buffer()\n",
    "        if not bin_modulation:\n",
    "            x_torch[x_torch >  0.5] = +1\n",
    "            x_torch[x_torch <= 0.5] = -1\n",
    "        if use_bb:\n",
    "            x.bb = bb.FrameBuffer.from_numpy(x_np)\n",
    "        if use_torch:\n",
    "            x.torch = x_torch.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_list = net.forward(x, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a53fc5-6102-4061-8dc6-5a19b29984c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_list(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        x_list = []\n",
    "        while True:\n",
    "            try:\n",
    "                x = pickle.load(f)\n",
    "            except:\n",
    "                break\n",
    "            x_list.append(x)\n",
    "    return x_list\n",
    "\n",
    "def read_lists(cnv_blk):\n",
    "    x_list = read_list(cnv_blk.log_x_name)\n",
    "    y_list = read_list(cnv_blk.log_y_name)\n",
    "    return x_list, y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8245d37e-84a8-4120-951d-f2c995b401c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distilation_lut(model, xy, epochs=2, learning_rate=0.001):\n",
    "    print('----')\n",
    "    x_list, y_list = xy\n",
    "    criterion_bb = bb.LossMeanSquaredError()\n",
    "    optimizer_bb = bb.OptimizerAdam(learning_rate=learning_rate)\n",
    "    optimizer_bb.set_variables(model.get_parameters(), model.get_gradients())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        criterion_bb.clear()\n",
    "        model.clear()\n",
    "\n",
    "        with tqdm(range(len(x_list))) as tqdm_loadr:\n",
    "            for i in tqdm_loadr:\n",
    "                x = x_list[i]\n",
    "                t = y_list[i]\n",
    "                x = bb.FrameBuffer.from_numpy(x).astype(bin_dtype)\n",
    "                t = bb.FrameBuffer.from_numpy(t)\n",
    "\n",
    "                model.clear()\n",
    "\n",
    "                y = model.forward(x, train=True)\n",
    "\n",
    "                dy = criterion_bb.calculate(y.astype(bb.DType.FP32), t.astype(bb.DType.FP32))\n",
    "                model.backward(dy)\n",
    "                optimizer_bb.update()\n",
    "\n",
    "                tqdm_loadr.set_postfix(loss=criterion_bb.get())\n",
    "        bb.save_networks(data_path, net)\n",
    "\n",
    "def distilation(cnv_blk, model=None, epochs=2, learning_rate=0.001):\n",
    "    if model is None:\n",
    "        model = cnv_blk.cnv_bb['lut']\n",
    "    else:\n",
    "        model.set_input_shape(cnv_blk.cnv_bb['lut'].get_input_shape())\n",
    "    xy = read_lists(cnv_blk)\n",
    "    distilation_lut(model, xy, pochs=epochs, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de250d6a-2125-4a54-96e6-6d51efb2fdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = read_lists(net.s_blk.cnv.cnv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b33eda-c2a7-4432-a265-8fe587763d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LutConvBlock2(bb.Sequential):\n",
    "    def __init__(self, hid_ch, out_ch, batch_norm=True, activation=True, name=\"\"):\n",
    "        self.cnv0 = bb.Convolution2d(\n",
    "                        bb.Sequential([\n",
    "                            bb.DifferentiableLut([hid_ch*6, 1, 1], connection='random', name=name+'_lut0_0', batch_norm=batch_norm, binarize=activation, bin_dtype=bin_dtype),\n",
    "                            bb.DifferentiableLut([hid_ch,   1, 1], connection='serial', name=name+'_lut0_1', batch_norm=batch_norm, binarize=activation, bin_dtype=bin_dtype),\n",
    "                        ]),\n",
    "                        filter_size=(1, 1),\n",
    "                        padding='same',\n",
    "                        name=name+'_cnv0',\n",
    "                        fw_dtype=bin_dtype)\n",
    "        self.cnv1 = bb.Convolution2d(\n",
    "                        bb.Sequential([\n",
    "                            bb.DifferentiableLut([hid_ch,   1, 1], connection='depthwise', name=name+'_lut1_0', batch_norm=batch_norm, binarize=activation, bin_dtype=bin_dtype),\n",
    "                        ]),\n",
    "                        filter_size=(3, 3),\n",
    "                        padding='same',\n",
    "                        name=name+'_cnv1',\n",
    "                        fw_dtype=bin_dtype)\n",
    "        self.cnv2 = bb.Convolution2d(\n",
    "                        bb.Sequential([\n",
    "                            bb.DifferentiableLut([out_ch*6*6, 1, 1], connection='random', name=name+'_lut2_0', batch_norm=batch_norm, binarize=activation, bin_dtype=bin_dtype),\n",
    "                            bb.DifferentiableLut([out_ch*6,   1, 1], connection='serial', name=name+'_lut2_1', batch_norm=batch_norm, binarize=activation, bin_dtype=bin_dtype),\n",
    "                            bb.DifferentiableLut([out_ch,     1, 1], connection='serial', name=name+'_lut2_2', batch_norm=batch_norm, binarize=activation, bin_dtype=bin_dtype),\n",
    "                        ]),\n",
    "                        filter_size=(1, 1),\n",
    "                        padding='same',\n",
    "                        name=name+'_cnv2',\n",
    "                        fw_dtype=bin_dtype)\n",
    "        super(LutConvBlock2, self).__init__([self.cnv0, self.cnv1, self.cnv2], name=name)\n",
    "\n",
    "\n",
    "#lut_net = bb.Sequential([\n",
    "#                LutConvBlock2(36*4, 36),\n",
    "#                LutConvBlock2(36*2, 32),\n",
    "#             ])\n",
    "\n",
    "lut_net = LutConvBlock2(36*4, 32)\n",
    "\n",
    "lut_net.set_input_shape(net.s_blk.cnv.cnv1.cnv_bb['lut'].get_input_shape())\n",
    "distilation_lut(lut_net, xy, epochs=1, learning_rate=0.01)\n",
    "#distilation(net.s_blk.cnv.cnv1, net.s_blk.cnv.cnv1.cnv_bb['lut'])\n",
    "#distilation_lut(net.s_blk.cnv.cnv1, lut_net, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7c598a-a31b-43d8-9ac7-3058079a45b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "distilation_lut(lut_net, xy, epochs=8, learning_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f1f0da-57a4-436e-94b4-5f198d8c57c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lut_net.get_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397ce67f-a857-40fc-9623-8a937c2ad54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.send_command(\"switch_model lut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10be06f-6e86-44e3-b5f5-5dd7c9de8c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "distilation(net.s_blk.cnv.cnv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49b9da-6e8a-4085-b4db-53b31fcb0053",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lut_net.get_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e401f3-f6f5-42c2-93a7-9fb7ceb87c54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(net.s_blk.cnv.cnv1.cnv_bb['lut'].get_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099cff95-a18e-4424-836e-49aa1a76b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.s_blk.cnv.cnv1.cnv_bb['lut'].get_input_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508a12eb-b37f-4227-9bd1-3f55a6cca961",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "distilation(net.m_blk.cnv0.cnv0)\n",
    "distilation(net.m_blk.cnv0.cnv1)\n",
    "distilation(net.m_blk.cnv1.cnv0)\n",
    "distilation(net.m_blk.cnv1.cnv1)\n",
    "distilation(net.s_blk.cnv.cnv0)\n",
    "distilation(net.s_blk.cnv.cnv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d26bac-2fcf-455e-9a87-3fea57ed87b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "view(net, loader_test, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37d5667-10fa-4a3e-a7c2-f0ca94c526a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning(net, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a06a54d-e459-4b14-8dcd-9cd38dec4883",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edcb22e-3673-4517-a81d-bd925c81ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.get_frame_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1aa39d-085d-420e-aafd-f143e64c6b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15207b62-8add-41c7-a332-f32ba8ed22fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion_bb = bb.LossMeanSquaredError()\n",
    "optimizer_bb = bb.OptimizerAdam(learning_rate=0.01)\n",
    "optimizer_bb.set_variables(model.get_parameters(), model.get_gradients())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    criterion_bb.clear()\n",
    "    model.clear()\n",
    "    \n",
    "    with tqdm(range(len(x_list))) as tqdm_loadr:\n",
    "        for i in tqdm_loadr:\n",
    "            x = x_list[i]\n",
    "            t = y_list[i]\n",
    "            x = bb.FrameBuffer.from_numpy(x).astype(bin_dtype)\n",
    "            t = bb.FrameBuffer.from_numpy(t)\n",
    "            \n",
    "            model.clear()\n",
    "            \n",
    "            y = model.forward(x, train=True)\n",
    "\n",
    "            dy = criterion_bb.calculate(y.astype(bb.DType.FP32), t.astype(bb.DType.FP32))\n",
    "            model.backward(dy)\n",
    "            optimizer_bb.update()\n",
    "            \n",
    "            tqdm_loadr.set_postfix(loss=criterion_bb.get())\n",
    "    bb.save_networks(data_path, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849a0d7a-2bbc-4411-9e73-553a0f961065",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnv_blk = net.m_blk.cnv0.cnv0\n",
    "x_list = read_list(cnv_blk.log_x_name)\n",
    "y_list = read_list(cnv_blk.log_y_name)\n",
    "\n",
    "#dense = cnv_blk.cnv_bb['dense']\n",
    "model = cnv_blk.cnv_bb['lut']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4435bfc-3b8b-446c-8424-ef536ba1f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bb.save_networks(data_path, net, name='layers', write_layers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957fdc3a-bd3b-47ae-a05c-005fc532a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.save_networks(data_path + '_lut', net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd50f5f5-981f-4265-9ac8-fe88b51a6961",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
