{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c9a853-f4e2-4490-b830-b66598ef6a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a962bd85-a62a-42e5-8bc0-945abf81bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_mode = True\n",
    "epochs = 8\n",
    "\n",
    "loops = 4\n",
    "depth = 3\n",
    "ch = 64\n",
    "\n",
    "# 並べるタイル数\n",
    "rows=2\n",
    "cols=2\n",
    "img_h = 32\n",
    "img_w = 32\n",
    "\n",
    "data_path = './data/mnist_iir_segmentation'\n",
    "mini_batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6586906c-8132-4421-a4b2-51ccf6470b8c",
   "metadata": {},
   "source": [
    "## 学習データ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6f0813-47c0-4ed1-956f-826046b87594",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset\n",
    "transform = transforms.Compose([\n",
    "                transforms.Resize((img_w, img_h)),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "\n",
    "dataset_path = './data/'\n",
    "dataset_train = torchvision.datasets.MNIST(root=dataset_path, train=True, transform=transform, download=True)\n",
    "dataset_test  = torchvision.datasets.MNIST(root=dataset_path, train=False, transform=transform, download=True)\n",
    "\n",
    "\n",
    "def make_teacher_image(gen, rows, cols, margin=0):\n",
    "    source_img  = np.zeros((1, rows*img_h, cols*img_w), dtype=np.float32)\n",
    "    teaching_img = np.zeros((11, rows*img_h, cols*img_w), dtype=np.float32)\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            x = col*img_w\n",
    "            y = row*img_h\n",
    "            img, label = gen.__next__()\n",
    "            source_img[0,y:y+img_h,x:x+img_w] = img\n",
    "            teaching_img[label,y:y+img_h,x:x+img_w] = img\n",
    "            teaching_img[10,y:y+img_h,x:x+img_w] = (1.0-img)\n",
    "    teaching_img = (teaching_img > 0.5).astype(np.float32)\n",
    "    \n",
    "    # 面積で重みを載せる\n",
    "    for i in range(11):\n",
    "        teaching_img[i] *= weight[i]\n",
    "    \n",
    "    # ランダムに反転\n",
    "    if random.random() > 0.5:\n",
    "        source_img = 1.0 - source_img\n",
    "\n",
    "    if margin > 0:\n",
    "        return source_img, teaching_img[:,margin:-margin,margin:-margin]\n",
    "    return source_img, teaching_img        \n",
    "\n",
    "def transform_data(dataset, n, rows, cols, margin):\n",
    "    def data_gen():\n",
    "        l = len(dataset)\n",
    "        i = 0\n",
    "        while True:\n",
    "            yield dataset[i%l]\n",
    "            i += 1\n",
    "    \n",
    "    gen = data_gen()\n",
    "    source_imgs = []\n",
    "    teaching_imgs = []\n",
    "    for _ in range(n):\n",
    "        x, t = make_teacher_image(gen, rows, cols, margin)\n",
    "        source_imgs.append(x)\n",
    "        teaching_imgs.append(t)\n",
    "    return source_imgs, teaching_imgs\n",
    "\n",
    "class MyDatasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, source_imgs, teaching_imgs, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.source_imgs = source_imgs\n",
    "        self.teaching_imgs = teaching_imgs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.source_imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        source_img = self.source_imgs[index]\n",
    "        teaching_img = self.teaching_imgs[index]\n",
    "        if self.transforms:\n",
    "            source_img, teaching_img = self.transforms(source_img, teaching_img)\n",
    "        return source_img, teaching_img\n",
    "\n",
    "# フィルタ処理用にタイル化する\n",
    "dataset_fname = os.path.join(data_path, 'dataset.pickle')\n",
    "if os.path.exists(dataset_fname):\n",
    "#if False:\n",
    "    with open(dataset_fname, 'rb') as f:\n",
    "        source_imgs_train = pickle.load(f)\n",
    "        teaching_imgs_train = pickle.load(f)\n",
    "        source_imgs_test = pickle.load(f)\n",
    "        teaching_imgs_test = pickle.load(f)\n",
    "        weight = pickle.load(f)\n",
    "else:\n",
    "    # 面積の比率で重み作成\n",
    "    areas = np.zeros((11))\n",
    "    for img, label in dataset_train:\n",
    "        img = img.numpy()\n",
    "        areas[label] += np.mean(img)\n",
    "        areas[10] += np.mean(1.0-img)\n",
    "    areas /= len(dataset_train)\n",
    "    \n",
    "    weight = 1 / areas\n",
    "    weight /= np.max(weight)\n",
    "    \n",
    "    source_imgs_train, teaching_imgs_train = transform_data(dataset_train, 4096, rows, cols, 0) #29)\n",
    "    source_imgs_test, teaching_imgs_test = transform_data(dataset_test, 128, rows, cols, 0) #, 29)\n",
    "    \n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "    with open(dataset_fname, 'wb') as f:\n",
    "        pickle.dump(source_imgs_train, f)\n",
    "        pickle.dump(teaching_imgs_train, f)\n",
    "        pickle.dump(source_imgs_test, f)\n",
    "        pickle.dump(teaching_imgs_test, f)\n",
    "        pickle.dump(weight, f)\n",
    "\n",
    "my_dataset_train = MyDatasets(source_imgs_train, teaching_imgs_train)\n",
    "my_dataset_test = MyDatasets(source_imgs_test, teaching_imgs_test)\n",
    "\n",
    "loader_train = torch.utils.data.DataLoader(dataset=my_dataset_train, batch_size=mini_batch_size, shuffle=True)\n",
    "loader_test = torch.utils.data.DataLoader(dataset=my_dataset_test, batch_size=mini_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303fa631-7c03-43b2-9fda-fa3d3ce4b100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 学習データ表示確認\n",
    "plt.figure(figsize=(16,8))\n",
    "for x, t in loader_test:\n",
    "    break\n",
    "\n",
    "n = min(mini_batch_size, 4)\n",
    "plt.figure(figsize=(18,2*n))\n",
    "for i in range(n):\n",
    "    plt.subplot(n,12,i*12+1)\n",
    "    plt.title('sorce')\n",
    "    plt.imshow(x[i][0], 'gray')\n",
    "    for j in range(11):\n",
    "        plt.subplot(n,12,i*12+2+j)\n",
    "        if j < 10:\n",
    "            plt.title('class=%d'%i)\n",
    "            plt.imshow(t[i][j], 'gray')\n",
    "        else:\n",
    "            plt.title('background')\n",
    "            plt.imshow(t[i][j], 'gray')\n",
    "plt.tight_layout()\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c66ac39-9d3f-4cc5-8be6-642a49b2dac7",
   "metadata": {},
   "source": [
    "## ネットワーク定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fdad74-f81e-4db4-be02-cee71267ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "class Binarize(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        ctx.save_for_backward(x)\n",
    "        y = x.new(x.size())\n",
    "        y[x >= 0] = 1.0\n",
    "        y[x < 0] = -1.0\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dy):\n",
    "        x, = ctx.saved_tensors\n",
    "        dx = dy.clone()\n",
    "        dx[x.ge(1)]=0\n",
    "        dx[x.le(-1)]=0\n",
    "        return dx\n",
    "\n",
    "binarize = Binarize.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf1d8f9-fba7-4a7b-bb0e-69418f4af1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.autograd import Function\n",
    "#class Binarize(Function):\n",
    "#    @staticmethod\n",
    "#    def forward(ctx, x):\n",
    "#        ctx.save_for_backward(x)\n",
    "#        y = x.new(x.size())\n",
    "#        y[x >  0] = 1.0\n",
    "#        y[x <= 0] = 0\n",
    "#        return y\n",
    "#    \n",
    "#    @staticmethod\n",
    "#    def backward(ctx, dy):\n",
    "#        x, = ctx.saved_tensors\n",
    "#        dx = dy.clone()\n",
    "#        dx[x.ge(1)]=0\n",
    "#        dx[x.le(-1)]=0\n",
    "#        return dx\n",
    "#\n",
    "#binarize = Binarize.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9e1c43-7c62-4823-a9c6-7ff9eafa1605",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"基本ブロック\"\"\"\n",
    "    def __init__(self, in_ch=32, out_ch=32, last=False):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.last  = last\n",
    "        self.cnv0  = nn.Conv2d(in_ch, out_ch, 3, padding=1, padding_mode='replicate')\n",
    "        self.bn0   = nn.BatchNorm2d(out_ch)\n",
    "        self.cnv1  = nn.Conv2d(out_ch, out_ch, 3, padding=1, padding_mode='replicate')\n",
    "        self.bn1   = nn.BatchNorm2d(out_ch)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cnv0(x)\n",
    "        x = self.bn0(x)\n",
    "        if bin_mode:\n",
    "            x = binarize(x)\n",
    "        else:\n",
    "            x = F.relu(x)\n",
    "        \n",
    "        x = self.cnv1(x)\n",
    "        x = self.bn0(x)\n",
    "        if bin_mode:\n",
    "            x = binarize(x)\n",
    "        elif not self.last:\n",
    "            x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "class ScaledNetwork(nn.Module):\n",
    "    def __init__(self, ch=32, top=False):\n",
    "        super(ScaledNetwork, self).__init__()\n",
    "        \n",
    "        self.top  = top\n",
    "        self.ch   = ch\n",
    "        self.up   = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        if self.top:\n",
    "            self.cnv0 = ConvBlock(self.ch+1, self.ch)\n",
    "            self.cnv1 = ConvBlock(self.ch,   11, last=self.top)\n",
    "        else:\n",
    "            self.cnv0 = ConvBlock(self.ch*2, self.ch)\n",
    "            self.cnv1 = ConvBlock(self.ch*2, self.ch)\n",
    "    \n",
    "    def forward(self, x0, x1, u, train=True):\n",
    "        x1 = self.up(x1)\n",
    "        x = torch.cat([x0, x1], 1)\n",
    "        x = self.cnv0.forward(x)        \n",
    "        v = self.pool(x)\n",
    "        if not self.top:\n",
    "            x = torch.cat([u, x], 1)\n",
    "        y = self.cnv1.forward(x)\n",
    "        return y, v\n",
    "\n",
    "class MipmapNetwork(nn.Module):\n",
    "    def __init__(self, loop=4, depth=3, ch=32):\n",
    "        super(MipmapNetwork, self).__init__()\n",
    "        self.loop    = loop\n",
    "        self.depth   = depth\n",
    "        self.shape   = None\n",
    "        self.ch      = ch\n",
    "        self.up      = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.m_net = ScaledNetwork(ch, top=True)\n",
    "        self.s_net = ScaledNetwork(ch)\n",
    "    \n",
    "    def make_mipmap(self, n, h, w):\n",
    "        mipmap = []\n",
    "        for i in range(self.depth+1):\n",
    "            h //= 2\n",
    "            w //= 2\n",
    "            buf = torch.zeros(n, self.ch, h, w).to(device)\n",
    "            mipmap.append(buf)\n",
    "        return mipmap\n",
    "    \n",
    "    def forward(self, x):\n",
    "        n = x.shape[0]\n",
    "        c = x.shape[1]\n",
    "        h = x.shape[2]\n",
    "        w = x.shape[3]\n",
    "        \n",
    "        mipmap = self.make_mipmap(n, h, w)        \n",
    "        for i in range(self.loop):\n",
    "            y, v = self.m_net.forward(x, mipmap[0], None)\n",
    "            if i < self.loop-1:\n",
    "                for j in range(self.depth):\n",
    "                    mipmap[j], v = self.s_net.forward(mipmap[j], mipmap[j+1], v)\n",
    "            if i == 0:\n",
    "                yy = y\n",
    "            else:\n",
    "                yy = torch.cat([yy, y], 0)\n",
    "        return yy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3929bc-4df9-4e2f-947e-bc232e6747cb",
   "metadata": {},
   "source": [
    "## 学習実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb11fc48-8376-4b05-9f8f-23721af86715",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "net_torch = MipmapNetwork(loop=4, depth=3, ch=ch).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2374d6-e7e0-41fb-ac12-d0423ea3196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 面積に応じて重み付けする\n",
    "w = torch.from_numpy(weight.astype(np.float32)).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=w)\n",
    "\n",
    "\n",
    "# 学習実施\n",
    "epochs = 16\n",
    "optimizer = optim.Adam(net_torch.parameters(), lr=0.001)\n",
    "#optimizer = optim.SGD(net_torch.parameters(), lr=0.001)\n",
    "for epoch in range(epochs):\n",
    "    print('epoch:%d'%epoch)\n",
    "    with tqdm(loader_train) as tqdm_loadr:\n",
    "        for x, t in tqdm_loadr:\n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            yy = net_torch(x)\n",
    "            \n",
    "            tt = torch.cat([t, t, t, t], 0)           \n",
    "            loss = criterion(yy, torch.argmax(tt, dim=1))\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            tqdm_loadr.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1ccbdd-3b32-4b88-af4d-625f0c3c1cd5",
   "metadata": {},
   "source": [
    "## 結果表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2561fa29-9e4b-4c78-8dd4-5a1bf50afdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1ループだけ推論\n",
    "with torch.no_grad():\n",
    "    for x, t in loader_test:\n",
    "        x = x.to(device)\n",
    "        y = net_torch(x)\n",
    "#       y = F.softmax(y, dim=1)\n",
    "        break\n",
    "\n",
    "# 表示\n",
    "x = x.to('cpu').detach().numpy()\n",
    "y = y.to('cpu').detach().numpy()\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "n = 8\n",
    "plt.figure(figsize=(16, 2*n))\n",
    "for i in range(n):\n",
    "    plt.subplot(n,12,i*12+1)\n",
    "    plt.imshow(x[i][0], 'gray')\n",
    "    for j in range(11):\n",
    "        plt.subplot(n,12,i*12+j+2)\n",
    "        plt.title('class=%d'%j)\n",
    "        plt.imshow(y[32*3+i][j], 'gray')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d2753f-9321-4441-9bcb-94069acb1154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
