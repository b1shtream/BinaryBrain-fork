{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import binarybrain as bb\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST data\n",
    "td = bb.load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 元レイヤー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create layer\n",
    "layer0_affine  = bb.DenseAffine.create([32])\n",
    "layer0_norm    = bb.BatchNormalization.create()\n",
    "layer0_bin     = bb.Binarize.create()\n",
    "layer1_affine  = bb.DenseAffine.create([32])\n",
    "layer1_norm    = bb.BatchNormalization.create()\n",
    "layer1_bin     = bb.Binarize.create()\n",
    "layer2_affine  = bb.DenseAffine.create([64])\n",
    "layer2_norm    = bb.BatchNormalization.create()\n",
    "layer2_bin     = bb.Binarize.create()\n",
    "layer3_affine  = bb.DenseAffine.create([64])\n",
    "layer3_norm    = bb.BatchNormalization.create()\n",
    "layer3_bin     = bb.Binarize.create()\n",
    "layer4_affine  = bb.DenseAffine.create([512])\n",
    "layer4_norm    = bb.BatchNormalization.create()\n",
    "layer4_bin     = bb.Binarize.create()\n",
    "layer5_affine  = bb.DenseAffine.create([10])\n",
    "layer5_norm    = bb.BatchNormalization.create()\n",
    "layer5_bin     = bb.Binarize.create()\n",
    "\n",
    "# main network\n",
    "cnv0_sub = bb.Sequential.create()\n",
    "cnv0_sub.add(layer0_affine)\n",
    "cnv0_sub.add(layer0_norm)\n",
    "cnv0_sub.add(layer0_bin)\n",
    "layer0_cnv = bb.LoweringConvolution.create(cnv0_sub, 3, 3)\n",
    "\n",
    "cnv1_sub = bb.Sequential.create()\n",
    "cnv1_sub.add(layer1_affine)\n",
    "cnv1_sub.add(layer1_norm)\n",
    "cnv1_sub.add(layer1_bin)\n",
    "layer1_cnv = bb.LoweringConvolution.create(cnv1_sub, 3, 3)\n",
    "\n",
    "cnv2_sub = bb.Sequential.create()\n",
    "cnv2_sub.add(layer2_affine)\n",
    "cnv2_sub.add(layer2_norm)\n",
    "cnv2_sub.add(layer2_bin)\n",
    "layer2_cnv = bb.LoweringConvolution.create(cnv2_sub, 3, 3)\n",
    "\n",
    "cnv3_sub = bb.Sequential.create()\n",
    "cnv3_sub.add(layer3_affine)\n",
    "cnv3_sub.add(layer3_norm)\n",
    "cnv3_sub.add(layer3_bin)\n",
    "layer3_cnv = bb.LoweringConvolution.create(cnv3_sub, 3, 3)\n",
    "\n",
    "main_net = bb.Sequential.create()\n",
    "main_net.add(layer0_cnv)\n",
    "main_net.add(layer1_cnv)\n",
    "main_net.add(bb.MaxPooling.create(2, 2))\n",
    "main_net.add(layer2_cnv)\n",
    "main_net.add(layer3_cnv)\n",
    "main_net.add(bb.MaxPooling.create(2, 2))\n",
    "main_net.add(layer4_affine)\n",
    "main_net.add(layer4_norm)\n",
    "main_net.add(layer4_bin)\n",
    "main_net.add(layer5_affine)\n",
    "main_net.add(layer5_norm)\n",
    "main_net.add(layer5_bin)\n",
    "\n",
    "main_net.set_input_shape(td['x_shape'])\n",
    "\n",
    "# Load\n",
    "net_path = 'mnist-dense-cnn-binary'\n",
    "\n",
    "layer0_affine.load_json(os.path.join(net_path, 'layer0_affine.json'))\n",
    "layer1_affine.load_json(os.path.join(net_path, 'layer1_affine.json'))\n",
    "layer2_affine.load_json(os.path.join(net_path, 'layer2_affine.json'))\n",
    "layer3_affine.load_json(os.path.join(net_path, 'layer3_affine.json'))\n",
    "layer4_affine.load_json(os.path.join(net_path, 'layer4_affine.json'))\n",
    "layer5_affine.load_json(os.path.join(net_path, 'layer5_affine.json'))\n",
    "\n",
    "layer0_norm.load_json(os.path.join(net_path, 'layer0_norm.json'))\n",
    "layer1_norm.load_json(os.path.join(net_path, 'layer1_norm.json'))\n",
    "layer2_norm.load_json(os.path.join(net_path, 'layer2_norm.json'))\n",
    "layer3_norm.load_json(os.path.join(net_path, 'layer3_norm.json'))\n",
    "layer4_norm.load_json(os.path.join(net_path, 'layer4_norm.json'))\n",
    "layer5_norm.load_json(os.path.join(net_path, 'layer5_norm.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 蒸留先"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_cnv0_sl0 = bb.SparseLut6.create([192])\n",
    "layer_cnv0_sl1 = bb.SparseLut6.create([32])\n",
    "\n",
    "layer_cnv1_sl0 = bb.SparseLut6.create([192*6])\n",
    "layer_cnv1_sl1 = bb.SparseLut6.create([192])\n",
    "layer_cnv1_sl2 = bb.SparseLut6.create([192])\n",
    "layer_cnv1_sl3 = bb.SparseLut6.create([32])\n",
    "#layer_cnv1_sl0 = bb.SparseLut6.create([192])\n",
    "#layer_cnv1_sl1 = bb.SparseLut6.create([32])\n",
    "\n",
    "layer_cnv2_sl0 = bb.SparseLut6.create([384])\n",
    "layer_cnv2_sl1 = bb.SparseLut6.create([64])\n",
    "\n",
    "layer_cnv3_sl0 = bb.SparseLut6.create([384])\n",
    "layer_cnv3_sl1 = bb.SparseLut6.create([64])\n",
    "\n",
    "layer_sl4_0    = bb.SparseLut6.create([512*6])\n",
    "layer_sl4_1    = bb.SparseLut6.create([512])\n",
    "layer_sl5_0    = bb.SparseLut6.create([10*6*6])\n",
    "layer_sl5_1    = bb.SparseLut6.create([10*6])\n",
    "layer_sl5_2    = bb.SparseLut6.create([10])\n",
    "\n",
    "# main network\n",
    "target_cnv0_sub = bb.Sequential.create()\n",
    "target_cnv0_sub.add(layer_cnv0_sl0)\n",
    "target_cnv0_sub.add(layer_cnv0_sl1)\n",
    "target_layer0_cnv = bb.LoweringConvolution.create(target_cnv0_sub, 3, 3)\n",
    "\n",
    "target_cnv1_sub = bb.Sequential.create()\n",
    "target_cnv1_sub.add(layer_cnv1_sl0)\n",
    "target_cnv1_sub.add(layer_cnv1_sl1)\n",
    "target_cnv1_sub.add(layer_cnv1_sl2)\n",
    "target_cnv1_sub.add(layer_cnv1_sl3)\n",
    "target_layer1_cnv = bb.LoweringConvolution.create(target_cnv1_sub, 3, 3)\n",
    "\n",
    "target_cnv2_sub = bb.Sequential.create()\n",
    "target_cnv2_sub.add(layer_cnv2_sl0)\n",
    "target_cnv2_sub.add(layer_cnv2_sl1)\n",
    "target_layer2_cnv = bb.LoweringConvolution.create(target_cnv2_sub, 3, 3)\n",
    "\n",
    "target_cnv3_sub = bb.Sequential.create()\n",
    "target_cnv3_sub.add(layer_cnv3_sl0)\n",
    "target_cnv3_sub.add(layer_cnv3_sl1)\n",
    "target_layer3_cnv = bb.LoweringConvolution.create(target_cnv3_sub, 3, 3)\n",
    "\n",
    "target_layer4 = bb.Sequential.create()\n",
    "target_layer4.add(layer_sl4_0)\n",
    "target_layer4.add(layer_sl4_1)\n",
    "\n",
    "target_layer5 = bb.Sequential.create()\n",
    "target_layer5.add(layer_sl5_0)\n",
    "target_layer5.add(layer_sl5_1)\n",
    "target_layer5.add(layer_sl5_2)\n",
    "\n",
    "target_net = bb.Sequential.create()\n",
    "target_net.add(target_layer0_cnv)\n",
    "target_net.add(target_layer1_cnv)\n",
    "target_net.add(bb.MaxPooling.create(2, 2))\n",
    "target_net.add(target_layer0_cnv)\n",
    "target_net.add(target_layer1_cnv)\n",
    "target_net.add(bb.MaxPooling.create(2, 2))\n",
    "target_net.add(target_layer4)\n",
    "target_net.add(target_layer5)\n",
    "\n",
    "target_net.set_input_shape(td['x_shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tW = layer1_affine.W()\n",
    "W = np.array(tW.get_data()).reshape(tW.get_shape()[::-1])\n",
    "idx = np.argsort(-np.abs(W), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for i in range(32):\n",
    "        for j in range(6):\n",
    "            layer_cnv1_sl1.set_connection_index([i], j, i*6+j)\n",
    "\n",
    "    for i in range(32):\n",
    "        for j in range(6*6):\n",
    "            layer_cnv1_sl0.set_connection_index([i], j, idx[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for i in range(32):\n",
    "        for j in range(6):\n",
    "            layer_cnv1_sl3.set_connection_index([i], j, i*6+j)\n",
    "    \n",
    "    for i in range(32):\n",
    "        for j in range(6*6):\n",
    "            layer_cnv1_sl2.set_connection_index([i], j, i*6*6+j)\n",
    "            \n",
    "    for i in range(32):\n",
    "        for j in range(6*6):\n",
    "            layer_cnv1_sl1.set_connection_index([i], j, i*6*6+j)\n",
    "\n",
    "    for i in range(32):\n",
    "        for j in range(6*6*6):\n",
    "#            if j < len(idx[i]):\n",
    "            layer_cnv1_sl0.set_connection_index([i], j, idx[i][j % len(idx[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tW = layer1_affine.W()\n",
    "W = np.array(tW.get_data()).reshape(tW.get_shape()[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argsort(-np.abs(W), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_distillation(x, x_shape, target_net, ref_net, pre_net):\n",
    "    x_buf = bb.FrameBuffer()\n",
    "    t_buf = bb.FrameBuffer()\n",
    "\n",
    "    print(ref_net.get_input_shape())\n",
    "\n",
    "    target_net.set_input_shape(ref_net.get_input_shape())\n",
    "    target_net.send_command(\"binary true\")\n",
    "    \n",
    "    pre_net.set_input_shape(x_shape)\n",
    "\n",
    "    batch_size = len(x)\n",
    "    max_batch_size = 32\n",
    "    leave = True\n",
    "\n",
    "    loss = bb.LossMeanSquaredError.create()\n",
    "    optimizer = bb.OptimizerAdam.create()\n",
    "    optimizer.set_variables(target_net.get_parameters(), target_net.get_gradients())\n",
    "\n",
    "#   x_shape = td['x_shape']\n",
    "#   x_shape = td['x_shape']\n",
    "    \n",
    "    for epoch in range(8):\n",
    "    #   for index in tqdm(range(0, batch_size, max_batch_size)):\n",
    "        loss.clear()\n",
    "        with tqdm(range(0, batch_size, max_batch_size), leave=leave) as pbar:\n",
    "            for index in pbar:\n",
    "                # calc mini_batch_size\n",
    "                mini_batch_size = min(max_batch_size, batch_size-index)\n",
    "                \n",
    "                # setup x\n",
    "                x_buf.resize(mini_batch_size, x_shape)\n",
    "                x_buf.set_data(x[index:index+mini_batch_size])\n",
    "                \n",
    "                # forward\n",
    "                x_buf = pre_net.forward(x_buf, False)\n",
    "    #            print('\\n')\n",
    "    #            print(x_buf.get_node_shape())\n",
    "    #            print(ref_net.get_input_shape())\n",
    "    #            print(target_net.get_input_shape())\n",
    "\n",
    "                t_buf = ref_net.forward(x_buf, False)\n",
    "                y_buf = target_net.forward(x_buf, True)\n",
    "                \n",
    "                # calc loss\n",
    "                dy_buf = loss.calculate_loss(y_buf, t_buf, mini_batch_size)\n",
    "\n",
    "                # backward\n",
    "                target_net.backward(dy_buf)\n",
    "\n",
    "                # update\n",
    "                optimizer.update()\n",
    "                \n",
    "                # print progress\n",
    "                dict = OrderedDict()\n",
    "                dict['loss'] = loss.get_loss()\n",
    "                if len(dict) > 0:\n",
    "                    pbar.set_postfix(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_net = bb.Sequential.create()\n",
    "pre_net.add(bb.RealToBinary.create(4, framewise=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_net.add(layer0_cnv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26, 26, 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 1875/1875 [28:11<00:00,  1.11it/s, loss=0.283]\n",
      "100%|██████████████████████████████████████████████████████████████████| 1875/1875 [27:51<00:00,  1.12it/s, loss=0.251]\n",
      "100%|██████████████████████████████████████████████████████████████████| 1875/1875 [28:34<00:00,  1.09it/s, loss=0.234]\n",
      "100%|██████████████████████████████████████████████████████████████████| 1875/1875 [30:08<00:00,  1.04it/s, loss=0.234]\n",
      "100%|██████████████████████████████████████████████████████████████████| 1875/1875 [30:27<00:00,  1.03it/s, loss=0.223]\n",
      "100%|██████████████████████████████████████████████████████████████████| 1875/1875 [32:11<00:00,  1.03s/it, loss=0.217]\n",
      "100%|██████████████████████████████████████████████████████████████████| 1875/1875 [31:37<00:00,  1.01s/it, loss=0.215]\n",
      "100%|██████████████████████████████████████████████████████████████████| 1875/1875 [29:50<00:00,  1.05it/s, loss=0.215]\n"
     ]
    }
   ],
   "source": [
    "layer_distillation(td['x_train'], td['x_shape'], target_layer1_cnv, layer1_cnv, pre_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer_cnv1_sl0.save_json(os.path.join(net_path, 'layer1_cnv_sl0.json'))\n",
    "#layer_cnv1_sl1.save_json(os.path.join(net_path, 'layer1_cnv_sl1.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_cnv1_sl0 = bb.SparseLut6.create([192])\n",
    "layer_cnv1_sl1 = bb.SparseLut6.create([32])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_cnv1_sl1.set_input_shape([192])\n",
    "#layer_cnv1_sl1.set_connection_index([0], 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(32):\n",
    "    for j in range(6):\n",
    "        layer_cnv1_sl1.set_connection_index([i], j, i*6+j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#layer_cnv1_sl1.get_connection([0], 0)\n",
    "layer_cnv1_sl1.get_output_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[213 123  92 259 209  96 164 119  93 267 211 210 268 200 178 186 263  41\n",
      " 258 166 158 194 262 122 214 169 205  65 128  88  14  38  10   1 274  71\n",
      "   2 208 182  13  68  12 174 257  85 245   5 224 172  48  11 106  25 272\n",
      "  94 188 133 202  91 266 283  95 124 173  17 286 168  66 150 207 256 121\n",
      "  83 144 163 192 254 270 218 279  78  18 155  59 250  46 221  77 101 277\n",
      " 278 180 102 114 170 130 161  15 189  30 108 285  27 143 177 255  16 216\n",
      " 191 265 249  44 142  62 134 271 287  55 231 225 109  63  89 273  34 201\n",
      "  74   7  58  79  51 243 131  36 244 107 233 118 137 230  49  29 104 195\n",
      " 234 212 167 240  64 241  40  72 217 165  97  61  42 129  75 219 228  50\n",
      " 149 147 281 227 113  67 215 148 136 115   6 220 239  90  19 196 247 223\n",
      " 199 120 159 206 280 248 246 242  98  31 154 275 193 269 179 253   9 140\n",
      "  73 190  24  87 126 236 117 156 264  86 197 203 141 276 145 198  37  53\n",
      " 184 153 260  28 181  21 157 139  39   3 183 252  35 282  76 116  70 146\n",
      " 100 151  56 162 237 232 110 127 229  23  26 175 171 111 251 138 103  32\n",
      " 125  47  99   8  43 226 105 261 185 204   0  80 222 132   4  20  22  33\n",
      "  45 238 152  54  81 235 284 112  57  52  60  69  84 160 176 135 187  82]\n",
      "213  0.625557\n",
      "123  0.612855\n",
      "92  0.513268\n",
      "259  -0.431354\n",
      "209  0.425770\n",
      "96  0.417591\n",
      "164  -0.393381\n",
      "119  0.389183\n",
      "93  0.363127\n"
     ]
    }
   ],
   "source": [
    "M = W.copy()\n",
    "idx = np.argsort(-np.abs(M)[0])\n",
    "print(idx)\n",
    "for i in range(9):\n",
    "    print('%d  %f' % (idx[i], M[0][idx[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sortarg(M):\n",
    "    index = np.zeros_like(M, dtype=int)\n",
    "    for i in range(len(M)):\n",
    "        index[i] = np.argsort(-np.abs(M[i]))\n",
    "    return index\n",
    "\n",
    "idx = get_sortarg(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = get_sortarg(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213 0.625557\n",
      "123 0.612855\n",
      "92 0.513268\n",
      "259 -0.431354\n",
      "209 0.425770\n",
      "96 0.417591\n",
      "164 -0.393381\n",
      "119 0.389183\n",
      "93 0.363127\n",
      "267 0.346345\n",
      "211 0.341455\n",
      "210 0.329749\n",
      "268 0.324445\n",
      "200 0.323485\n",
      "178 0.321366\n",
      "186 -0.320791\n",
      "263 0.319501\n",
      "41 0.312180\n",
      "258 -0.304235\n",
      "166 -0.296559\n",
      "158 0.289072\n",
      "194 -0.288853\n",
      "262 -0.287436\n",
      "122 0.280644\n",
      "214 0.279326\n",
      "169 0.278695\n",
      "205 0.278291\n",
      "65 -0.273646\n",
      "128 0.270545\n",
      "88 0.268212\n",
      "14 0.258259\n",
      "38 0.251168\n",
      "10 0.251001\n",
      "1 0.250480\n",
      "274 0.247326\n",
      "71 -0.244706\n",
      "2 0.244142\n",
      "208 0.238619\n",
      "182 -0.236117\n",
      "13 0.232247\n",
      "68 -0.231580\n",
      "12 0.229702\n",
      "174 0.229211\n",
      "257 -0.226741\n",
      "85 -0.226691\n",
      "245 0.225787\n",
      "5 0.223860\n",
      "224 -0.221093\n",
      "172 -0.213886\n",
      "48 -0.212861\n",
      "11 0.212523\n",
      "106 -0.212507\n",
      "25 -0.211504\n",
      "272 0.209848\n",
      "94 0.209082\n",
      "188 0.206546\n",
      "133 0.206496\n",
      "202 0.204975\n",
      "91 0.204754\n",
      "266 0.199720\n",
      "283 0.198510\n",
      "95 0.198481\n",
      "124 0.193853\n",
      "173 -0.193404\n"
     ]
    }
   ],
   "source": [
    "for i in range(64):\n",
    "    print(\"%d %f\" % (idx[0][i], W[0][idx[0][i]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
