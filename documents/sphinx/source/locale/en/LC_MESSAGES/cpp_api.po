# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2019, Ryuji Fuchikami
# This file is distributed under the same license as the BinaryBrain
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2019.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: BinaryBrain \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2019-09-29 21:10+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.7.0\n"

#: ../../source/cpp_api.rst:3
msgid "C++ API"
msgstr ""

#: ../../source/cpp_api.rst:7
msgid "概要"
msgstr "Abstruct"

#: ../../source/cpp_api.rst:9
msgid "本章ではC++のAPIについて触れます。"
msgstr "This chapter describes the C++ API"

#: ../../source/cpp_api.rst:11
msgid "現時点では細かなドキュメントが用意できておらず、ソースを読み人のために 概要を掴む為の情報を記載します。"
msgstr ""
"There is no detailed documentation available at this time, and the "
"information to get an overview for readers is provided."

#: ../../source/cpp_api.rst:14
msgid "なお BinaryBrain のコードは namespace に bb という名称を持ちます。"
msgstr "The BinaryBrain code has the name bb in the namespace."

#: ../../source/cpp_api.rst:18
msgid "モデルクラス"
msgstr "Model class"

#: ../../source/cpp_api.rst:21
msgid "基本クラス"
msgstr "Basic class"

#: ../../source/cpp_api.rst:23
msgid "すべてのレイヤーはModelクラスからの派生で生成されます。"
msgstr "All layers are generated by deriving from the Model class."

#: ../../source/cpp_api.rst:26
msgid "Model(抽象クラス)"
msgstr "Model class"

#: ../../source/cpp_api.rst:28
msgid "抽象クラスは直接生成できませんが、各レイヤーの基礎となっており、操作を定義します。 以下のようなメソッドを備えます。"
msgstr ""
"Although abstract classes cannot be generated directly, they are the "
"basis for each layer and define operations. It has the following methods."

#: ../../source/cpp_api.rst:39
msgid "SendCommand()"
msgstr ""

#: ../../source/cpp_api.rst:33
msgid ""
"文字列によって汎用的に各レイヤーの属性変更などを行えます。 "
"階層的にサブレイヤーに伝播させることを目的としておりますが、送信先クラス名を指定することで、 特定のレイヤにのみコマンドを送ることも出来ます。 "
"現在の主な用途として \"binary true\" のようなコマンドで、バイナリ活性層を有効にしたり、 \"host_only\" "
"コマンドで、部分的に動作をCPU版に切り替えたりできます。 "
"将来的には、部分的に学習時のパラメータ学習を固定したりなど、いろいろな設定を追加していくことを考えています。 "
"文字列なので、自作レイヤーに独自コマンドを追加することも簡単です。"
msgstr "send command string to layer"

#: ../../source/cpp_api.rst:42
msgid "GetClassName()"
msgstr ""

#: ../../source/cpp_api.rst:42
msgid "クラス名を取得します。SendCommand() で、コマンド送付先をクラス名で指定することが出来ます。"
msgstr "get class name"

#: ../../source/cpp_api.rst:46
msgid "SetName()"
msgstr "set instance name."

#: ../../source/cpp_api.rst:45
msgid ""
"クラス名とは別にインスタンス個別に自由に名前設定が出来ます。生成時に固有の名前をつけておけば、 後から SendCommand() "
"で、個別に属性変更コマンドが送れます。"
msgstr "set instance name"

#: ../../source/cpp_api.rst:50
msgid "GetParameters()"
msgstr ""

#: ../../source/cpp_api.rst:49
msgid "内部パラメータの参照を取得します。重み係数などが取得対象です。 内部パラメータを持った自作レイヤーを作成する場合に実装が必要になります。"
msgstr "get parameters for optimizer"

#: ../../source/cpp_api.rst:54
msgid "GetGradients()"
msgstr ""

#: ../../source/cpp_api.rst:53
msgid ""
"内部パラメータの勾配への参照を取得します。Backward時に値が計算され、主に Optimizer が利用します。 "
"内部パラメータを持った自作レイヤーを作成する場合に実装が必要になります。"
msgstr "get gradients for optimizer"

#: ../../source/cpp_api.rst:59
msgid "SetInputShape()"
msgstr ""

#: ../../source/cpp_api.rst:57
msgid ""
"入力のデータ形状を指定します。戻り値は出力のデータ形状となります。 "
"階層的にサブレイヤーに伝播させることを目的としており、各レイヤーを連結後に呼びさすことで内部パラメータのサイズが決定され初期化されます。 "
"自作レイヤーを作成する場合には必ず実装が必要になります。"
msgstr "set shape of the input-data"

#: ../../source/cpp_api.rst:63
msgid "Forward()"
msgstr ""

#: ../../source/cpp_api.rst:62
msgid "前方伝播を行います。階層的にサブレイヤーも実行することを想定しています。 自作レイヤーを作成する場合には必ず実装が必要になります。"
msgstr "run forward"

#: ../../source/cpp_api.rst:67
msgid "Backward()"
msgstr ""

#: ../../source/cpp_api.rst:66
msgid "誤差逆伝播を行います。階層的にサブレイヤーも実行することを想定しています。 自作レイヤーを作成する場合には必ず実装が必要になります。"
msgstr "run backward"

#: ../../source/cpp_api.rst:72
msgid "PrintInfo()"
msgstr ""

#: ../../source/cpp_api.rst:70
msgid "レイヤーの情報を表示します。 自作レイヤーを作成する場合に実装しておけば独自の情報を出力できます。"
msgstr "print structure of network"

#: ../../source/cpp_api.rst:75
msgid "活性化層"
msgstr "Activation layers"

#: ../../source/cpp_api.rst:78
msgid "Binarize クラス"
msgstr "Binarize class"

#: ../../source/cpp_api.rst:79
msgid ""
"バイナライズ層です。 Forward では、0を閾値に出力を0と1に二値化します。 Backward では hard-tanh として動作します。"
" バイナリネットワークの基礎となります。"
msgstr ""
"forward operation is binarize."
"backward operation is hard-tanh."

#: ../../source/cpp_api.rst:85
msgid "ReLU クラス"
msgstr "ReLU class"

#: ../../source/cpp_api.rst:86
msgid ""
"普通のReLU です。 Binarize から派生しており、SendCommand() にて、\"binary true\" "
"を送ることでBinarize層として動作します。"
msgstr ""
"ReLU function.If you call SendCommand with \"binary true\", it behaves as"
" a Binarize layer"

#: ../../source/cpp_api.rst:90
msgid "Sigmoid クラス"
msgstr "Sigmoid class"

#: ../../source/cpp_api.rst:91
msgid ""
"普通のSigmoid です。 Binarize から派生しており、SendCommand() にて、\"binary true\" "
"を送ることでBinarize層として動作します。"
msgstr ""
"Sigmoid function.If you call SendCommand with \"binary true\", it behaves"
" as a Binarize layer"

#: ../../source/cpp_api.rst:97
msgid "演算層"
msgstr "Operation layers"

#: ../../source/cpp_api.rst:101
msgid "SparseLutN クラス"
msgstr "SparseLutN class"

#: ../../source/cpp_api.rst:103
msgid ""
"LUT-Network の LUT に相当する部分を独自のモデルで学習させるためのレイヤーです。 "
"パーセプトロンと異なる独自のモデルを用いており、単体でXORパターンを含めたLUTで 表現可能な空間すべてを効率的に学習可能です。"
msgstr "Layer to learn LUT using original model"

#: ../../source/cpp_api.rst:109
msgid "StochasticLutN クラス"
msgstr "StochasticLutN class"

#: ../../source/cpp_api.rst:111
msgid ""
"LUT-Network の LUT に相当する部分をStochasticモデルに基づいて学習させるためのレイヤーです。 "
"StochasticバイナリデータがStochastic性を持っている対象への学習に限定されますが、 "
"SparseLutもでるよりも高速に学習させることが可能です。"
msgstr ""
"This is a layer to train the part corresponding to LUT of LUT-Network based on Stochastic model."
"Although Stochastic binary data is limited to learning to objects that have Stochastic properties, "
"it is possible to train faster than SparseLut can."

#: ../../source/cpp_api.rst:117
msgid "MicroMlp クラス"
msgstr "MicroMlp class"

#: ../../source/cpp_api.rst:119
msgid ""
"LUT-Network の LUT に相当する部分をパーセプトロンを用いて学習させるレイヤーです。 内部は MicroMlpAffine + "
"BatchNormalization + 活性化層 の３層で構成されます。 活性化層 は デフォルトは ReLU "
"ですが、テンプレート引数で変更可能です。"
msgstr ""
"This is a layer that uses the perceptron to learn the part corresponding to the LUT of the LUT-Network. "
"The interior consists of three layers: MicroMlpAffine + BatchNormalization + Activation layer. "
"Activation layer defaults to ReLU However, it can be changed with the template argument."

#: ../../source/cpp_api.rst:125
msgid "MicroMlpAffine クラス"
msgstr "MicroMlpAffine class"

#: ../../source/cpp_api.rst:127
msgid ""
"MicroMlp の構成要素で、入力数を6などに限定した疎結合、且つ、内部に隠れ層を備えた 小さなMLP(Multi Layer "
"Perceptron)の集合体です。 入力数や隠れ層の数テンプレート引数で変更可能です。"
msgstr ""
"It is a component of MicroMlp, a small MLP (Multi Layer Perceptron) aggregate with loose coupling "
"with a limited number of inputs such as 6 and a hidden layer inside. "
"The number of inputs and the number of hidden layers can be changed with template arguments."

#: ../../source/cpp_api.rst:133
msgid "DenseAffine クラス"
msgstr "DenseAffine class"

#: ../../source/cpp_api.rst:135
msgid "いわゆる普通の浮動小数点による全結合のニューラルネットです。"
msgstr "Dense affine operation"

#: ../../source/cpp_api.rst:139
msgid "BatchNormalization クラス"
msgstr "BatchNormalization class"

#: ../../source/cpp_api.rst:141
msgid "BatchNormalization層です。 活性化層でバイナリ化を行う前段ほぼ必須となってくる層です。"
msgstr "BatchNormalization operation"

#: ../../source/cpp_api.rst:146
msgid "MaxPooling クラス"
msgstr "MaxPooling class"

#: ../../source/cpp_api.rst:148
msgid "MaxPooling層です。"
msgstr "MaxPooling operation"

#: ../../source/cpp_api.rst:152
msgid "LutLayer (抽象クラス)"
msgstr "LutLayer class"

#: ../../source/cpp_api.rst:154
msgid ""
"LUT-Network を記述する基本モデルです。 現在 ver2 の直接学習機能はまだ ver3 には未実装です。 MicroMlp "
"などで逆伝播で学習した内容をテーブル化して写し取ることを目的としています。 テーブル化取り込みに ImportLayer() メソッドを備えます。"
msgstr "LUT Layer"

#: ../../source/cpp_api.rst:161
msgid "BinaryLutN クラス"
msgstr "BinaryLutN class"

#: ../../source/cpp_api.rst:163
msgid ""
"各ノードの入力数を１つに固定したLUTモデルです。一般的なFPGAに適合します。 入力数はテンプレート引数で指定でき、FPGAでは 4 か 6 "
"のものが一般的と思われます。 入力数を固定することで演算を高速化できますが、ver3 への移植はまだ行えていません。"
msgstr "binary LUT operation (like FPGA)"

#: ../../source/cpp_api.rst:169
msgid "補助層"
msgstr "Utility classes"

#: ../../source/cpp_api.rst:172
msgid "Sequential クラス"
msgstr "Sequential class"

#: ../../source/cpp_api.rst:174
msgid "各種の層を直列に接続して１つの層として扱えるようにします。"
msgstr "constructer for sequential network"

#: ../../source/cpp_api.rst:178
msgid "LoweringConvolution クラス"
msgstr "LoweringConvolution class"

#: ../../source/cpp_api.rst:180
msgid "Lowering を行い畳こみ演算を行います。"
msgstr "Lowering layer"

#: ../../source/cpp_api.rst:182
msgid ""
"ConvolutionIm2Col + 引数で渡したモデル + ConvolutionCol2Im DenseAffine "
"を渡すと、通常のCNNになり、MicroMlp を用いたサブネットワークを渡すことで、"
msgstr "Lowering for convolution"

#: ../../source/cpp_api.rst:185
msgid "LUT-Network での畳込みが可能です。"
msgstr "Lowering for convolution"

#: ../../source/cpp_api.rst:189
msgid "ConvolutionIm2 クラス"
msgstr "ConvolutionIm2 class"

#: ../../source/cpp_api.rst:191
msgid ""
"畳み込みの為のLoweringを行います。通常、LoweringConvolutionクラス の中で利用されます。 "
"Loweringされたデータに対して BatchNormalization するのも LUT-Network 学習時の特徴の一つかもしれません。"
msgstr "Im2Col operation layer"

#: ../../source/cpp_api.rst:195
msgid "ConvolutionCol2Im クラス"
msgstr "ConvolutionCol2Im class"

#: ../../source/cpp_api.rst:197
msgid "畳み込みの為のLoweringの復元を行います。通常、LoweringConvolutionクラス の中で利用されます。"
msgstr "Col2Im operation layer"

#: ../../source/cpp_api.rst:201
msgid "BinaryModulation クラス"
msgstr "BinaryModulation class"

#: ../../source/cpp_api.rst:203
msgid "内部でRealToBinary クラスとBinaryToRealクラスを組み合わせて、多値データをバイナリ化して学習するのに利用できます。"
msgstr "Binary modulation wrapper. (add RealToBinary(preprocess) and BinaryToReal(postprocess))"

#: ../../source/cpp_api.rst:207
msgid "RealToBinary クラス"
msgstr "RealToBinary class"

#: ../../source/cpp_api.rst:209
msgid ""
"実数値をバイナライズします。 その際にframe方向に拡張して変調を掛ける(多重化)が可能です。 "
"現在、PWM変調と、乱数での変調を実装しており、デフォルトでPWM変調となります(将来⊿Σなどの誤差蓄積機能も検討中です)。 "
"変調を行うことで、入力値に対して確率的な0/1比率の値を生成できるため、出力も確率的なものとなります。"
msgstr "Binarize with modulation."

#: ../../source/cpp_api.rst:216
msgid "BinaryToReal クラス"
msgstr "BinaryToReal class"

#: ../../source/cpp_api.rst:218
msgid ""
"多重化された確率的な0と1をカウンティングして実数値を生成します。 RealToBinary "
"対応しますが、こちらは時間方向だけでなく、空間方向のカウントも可能です。 "
"オーバーサンプリングによる十分な多重化数が確保できれば、回路規模を増加させること無く回帰などの実数値へのフィッティング可能性が出てきます。"
msgstr ""
"Binary to Real with integration"

#: ../../source/cpp_api.rst:225
msgid "モデル以外のクラス"
msgstr "Other classes"

#: ../../source/cpp_api.rst:228
msgid "損失関数"
msgstr "Loss function classes"

#: ../../source/cpp_api.rst:231
msgid "LossSoftmaxCrossEntropy クラス"
msgstr "LossSoftmaxCrossEntropy class"

#: ../../source/cpp_api.rst:233
msgid "普通のSoftmax-CrossEntropyクラスです。"
msgstr "Softmax-CrossEntropy operation"

#: ../../source/cpp_api.rst:237
msgid "LossMeanSquaredError クラス"
msgstr "LossMeanSquaredError class"

#: ../../source/cpp_api.rst:239
msgid "平均二乗誤差を損失とするクラスです。"
msgstr "calclate Mean Squared Error"

#: ../../source/cpp_api.rst:243
msgid "評価関数"
msgstr "Metrics classes"

#: ../../source/cpp_api.rst:246
msgid "MetricsCategoricalAccuracy クラス"
msgstr "MetricsCategoricalAccuracy class"

#: ../../source/cpp_api.rst:248
msgid "Categorical Classification の精度を評価値とするクラスです。"
msgstr "calcrate CategoricalAccuracy for Metrics."

#: ../../source/cpp_api.rst:251
msgid "MetricsMeanSquaredError クラス"
msgstr "MetricsMeanSquaredError class"

#: ../../source/cpp_api.rst:253
msgid "MSE(平均二乗誤差)を評価値とするクラスです。"
msgstr "calclate Mean Squared Error"

#: ../../source/cpp_api.rst:257
msgid "最適化(Optimizer)"
msgstr "Optimizer"

#: ../../source/cpp_api.rst:260
msgid "OptimizerSgd クラス"
msgstr "OptimizerSgd class"

#: ../../source/cpp_api.rst:262
msgid "普通のSGDです。"
msgstr "stochastic gradient descent"

#: ../../source/cpp_api.rst:266
msgid "OptimizerAdam クラス"
msgstr "OptimizerAdam class"

#: ../../source/cpp_api.rst:268
msgid "普通のAdamです。"
msgstr "Adam"

#: ../../source/cpp_api.rst:272
msgid "実行補助"
msgstr "Assist for run"

#: ../../source/cpp_api.rst:275
msgid "Runner クラス"
msgstr "Runner class"

#: ../../source/cpp_api.rst:277
msgid "構築したモデルのフィッティングや評価などの実行を補助します。 論よりRUN。 Runner のソースが各種の使い方で、参考になるはずです。"
msgstr "Assists in executing fitting and evaluation of the built model."

#: ../../source/cpp_api.rst:283
msgid "データ保持"
msgstr "Containers"

#: ../../source/cpp_api.rst:286
msgid "Tensor クラス"
msgstr "Tensor class"

#: ../../source/cpp_api.rst:288
msgid "多次元のデータを保持できるクラスで、演算も可能です。 名前に反してまだ Tensor演算は実装できていません。"
msgstr "Container for N-dimensional array"

#: ../../source/cpp_api.rst:293
msgid "Variables クラス"
msgstr "Variables class"

#: ../../source/cpp_api.rst:295
msgid ""
"複数の Tensor を束ねる機能を持ったクラスです。 形状が同じなら Variables 間での演算も可能です。 "
"主にOptimizerでの利用を想定しています。"
msgstr "Container for Tensors"

#: ../../source/cpp_api.rst:300
msgid "FrameBuffer クラス"
msgstr "FrameBuffer class"

#: ../../source/cpp_api.rst:302
msgid ""
"１つの Tensor を 1 frame として、複数frame を保持できるクラスです。 ただし、内部では、NCHW や NHWC "
"ではなく、CHWN 形式になるように並び替えてデータを保持しています。 これは Lowering されて "
"frame数が十分増やされた疎行列に特化して性能を出すための配置で、BinaryBrainの特徴の一つです。 "
"一方で、一般的な算術ライブラリに適合しない(並び替えが必要)ので注意が必要です。"
msgstr "Container for Tensors with frames"

#: ../../source/cpp_api.rst:309
msgid "各種関数"
msgstr "functions"

#: ../../source/cpp_api.rst:312
msgid "FPGAへのエクスポート"
msgstr "export RTL for FPGA"

#: ../../source/cpp_api.rst:315
msgid "ExportVerilog_LutLayers 関数"
msgstr "ExportVerilog_LutLayers function"

#: ../../source/cpp_api.rst:317
msgid "LutLayer を Verilog-RTL で出力します。"
msgstr "output verilog-RTL from LutLayer"

#: ../../source/cpp_api.rst:321
msgid "ExportVerilog_LutCnnLayersAxi4s 関数"
msgstr "ExportVerilog_LutCnnLayersAxi4s function"

#: ../../source/cpp_api.rst:323
msgid ""
"畳み込み層を含む LutLayer を纏めて Verilog-RTL で出力します。 "
"MaxPoolingなどの入出力でデータが不連続になる層は最後に1つだけ指定することができます。"
msgstr "output verilog-RTL(AXI4-Stream I/F) from CNN-Layer""

